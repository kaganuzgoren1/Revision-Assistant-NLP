{"cells":[{"cell_type":"markdown","source":["#Library Install"],"metadata":{"id":"0FCsEMFQ7P6w"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"icvUZ1e0taqx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866363260,"user_tz":-60,"elapsed":38399,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"07806b4b-b9d0-4cd8-f445-a655c584eeb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.2.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (65.3.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (65.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m2022-08-30 13:32:33.864668: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.4.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (65.3.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["#SpaCy\n","!pip install -U pip setuptools wheel\n","!pip install -U spacy\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_TA8MDgetlBd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866370035,"user_tz":-60,"elapsed":6778,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"c6ca0bc8-b5c8-4c47-e6ec-bb8d030b42f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: python-pptx in /usr/local/lib/python3.7/dist-packages (0.6.21)\n","Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx) (7.1.2)\n","Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.7/dist-packages (from python-pptx) (3.0.3)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx) (4.9.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#PPTX document reader\n","!pip install python-pptx"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8249,"status":"ok","timestamp":1661866378280,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"},"user_tz":-60},"id":"OVnzoLHgt6dG","outputId":"b7587aa0-f5bc-40c6-e4c2-d340a933f2b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.97)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.21.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#Hugging face sentence transformers for MPNet based model\n","!pip install sentence-transformers"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8136,"status":"ok","timestamp":1661866386411,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"},"user_tz":-60},"id":"xRJo4Xmrtn3D","outputId":"b1040180-94d6-42e5-ea32-93dbd0a2cfbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keyphrase-vectorizers in /usr/local/lib/python3.7/dist-packages (0.0.10)\n","Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.7/dist-packages (from keyphrase-vectorizers) (1.0.2)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from keyphrase-vectorizers) (1.7.3)\n","Requirement already satisfied: spacy-transformers>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from keyphrase-vectorizers) (1.1.8)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keyphrase-vectorizers) (1.21.6)\n","Requirement already satisfied: nltk>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from keyphrase-vectorizers) (3.7)\n","Requirement already satisfied: spacy>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from keyphrase-vectorizers) (3.4.1)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.7/dist-packages (from keyphrase-vectorizers) (5.9.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (4.64.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (7.1.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.1->keyphrase-vectorizers) (2022.6.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->keyphrase-vectorizers) (3.1.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.10.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.9.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.10)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.23.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.8)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (1.0.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (65.3.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (8.1.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.0.8)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (21.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.6.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.11.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (2.4.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (3.0.7)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (4.1.1)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.1->keyphrase-vectorizers) (0.4.2)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers>=1.1.6->keyphrase-vectorizers) (1.12.1+cu113)\n","Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.8.5)\n","Requirement already satisfied: transformers<4.22.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers>=1.1.6->keyphrase-vectorizers) (4.21.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.1->keyphrase-vectorizers) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.1->keyphrase-vectorizers) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.1->keyphrase-vectorizers) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->keyphrase-vectorizers) (2.10)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.1->keyphrase-vectorizers) (0.7.8)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (3.8.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.9.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (0.12.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers>=1.1.6->keyphrase-vectorizers) (6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.1->keyphrase-vectorizers) (2.0.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#KPV for KeyBERT\n","!pip install keyphrase-vectorizers"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8640,"status":"ok","timestamp":1661866395046,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"},"user_tz":-60},"id":"47bBqowctqqQ","outputId":"7a9946fc-6a1b-4f8b-8759-a621304309b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keybert in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.7/dist-packages (from keybert) (2.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.0.2)\n","Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.7/dist-packages (from keybert) (12.5.1)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (2.6.1)\n","Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (4.1.1)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (0.9.1)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.1.97)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.12.1+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.64.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.7)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.21.2)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.9.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.13.1+cu113)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.12.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (7.1.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2022.6.15)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#KPE model\n","!pip install keybert"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33580,"status":"ok","timestamp":1661866324873,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"},"user_tz":-60},"id":"O3PLKWyRtsgF","outputId":"eaae8d6b-2b71-44c1-cdc7-dff408da16d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyLDAvis\n","  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n","Collecting funcy\n","  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (65.3.0)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n","Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.7.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n","Building wheels for collected packages: pyLDAvis, sklearn\n","  Building wheel for pyLDAvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136882 sha256=f6faf5ada90065d092934f0e31a297381b97ab8c23796470afc9e79cf2521178\n","  Stored in directory: /root/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1304 sha256=e1836ce599ff3b8b0825456549761e84a5b18ee0e040e36dc89e0813e4815798\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built pyLDAvis sklearn\n","Installing collected packages: funcy, sklearn, pyLDAvis\n","Successfully installed funcy-1.17 pyLDAvis-3.3.1 sklearn-0.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# for LDA model\n","!pip install pyLDAvis"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1303,"status":"ok","timestamp":1661866396345,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"},"user_tz":-60},"id":"0Fk98-I-uUac"},"outputs":[],"source":["import nltk"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"wkYD7WqnuD23","executionInfo":{"status":"ok","timestamp":1661866433664,"user_tz":-60,"elapsed":158,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#the pptx document is read by presenting its path\n","from pptx import Presentation\n","filename = \"/content/lec5_22_final.pptx\"\n","\n","prs = Presentation(filename)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"c5ArW9VvuR9b","executionInfo":{"status":"ok","timestamp":1661866434400,"user_tz":-60,"elapsed":22,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["# a dictionary where the titles are the keys and values are the slide texts is created\n","i=0\n","slidepp={}\n","for slide in prs.slides:\n","  \n","    if len(slide.shapes)==1:\n","    \n","        for shape in slide.shapes:\n","          if hasattr(shape, \"text\"):\n","            #print(shape.text)\n","            if slide.shapes.title.text in slidepp.keys():\n","              slidepp[slide.shapes.title.text]+=shape.text\n","            else:\n","              slidepp[slide.shapes.title.text] = shape.text\n","\n","\n","    elif len(slide.shapes)>1:\n","      if not slide.shapes[1].has_text_frame:\n","        for shape in slide.shapes:\n","          if hasattr(shape, \"text\"):\n","            \n","              if slide.shapes.title :\n","                  if slide.shapes.title.text in slidepp.keys():\n","                                               \n","                    slidepp[slide.shapes.title.text]+=shape.text\n","        \n","                  if slide.shapes.title.text not in slidepp.keys():\n","                    slidepp[slide.shapes.title.text] = shape.text\n","              \n","\n","        \n","      else: \n","      \n","        if slide.shapes.title :\n","          if slide.shapes.title.text in slidepp.keys():\n","            slidepp[slide.shapes.title.text]+=slide.shapes[1].text\n","          if slide.shapes.title.text not in slidepp.keys():\n","                slidepp[slide.shapes.title.text] = slide.shapes[1].text\n","              \n","        \n","        \n","  \n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"tsbDnS9xDnu4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866434401,"user_tz":-60,"elapsed":22,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"c95ce3f0-5967-4698-b9be-6dd361af0012"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{},"execution_count":24}],"source":["len(slidepp.keys())"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Z5vmM_Z7ub1D","executionInfo":{"status":"ok","timestamp":1661866434401,"user_tz":-60,"elapsed":20,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["slidepptexts=[]\n","slideppheadings_1=[]\n","for key,value in slidepp.items():\n","  slidepptexts.append(value)\n","  slideppheadings_1.append(key)\n"]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"DBw0v89A-dt-"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"3tXrYQiPuSBm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866434401,"user_tz":-60,"elapsed":20,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"76622b1f-1491-4259-baa2-71e665c706cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Named Entity Recognition',\n"," 'Previously',\n"," 'Week 5 overview',\n"," 'NLP Tasks',\n"," 'Named Entity Recognition ',\n"," 'Why Named Entity Recognition?',\n"," 'Sample Text',\n"," 'Types of Named Entity',\n"," 'Sequence Labelling – IOB encoding',\n"," 'Evaluation ',\n"," 'Features commonly used in NER',\n"," 'Typical Supervised Approach',\n"," 'Classification',\n"," 'Named Entity Recognition Part 2',\n"," 'NER Approaches',\n"," 'Rule-based',\n"," 'Generative models',\n"," 'Hidden Markov Model (HMM)',\n"," 'Discriminative models',\n"," 'Conditional Random Field (CRF)',\n"," 'Implementations of CRF',\n"," 'Applications of (Linear Chain) CRFs',\n"," 'Drawbacks of using CRFs',\n"," 'Neural Models',\n"," 'Ma and Hovy (2016)',\n"," 'Wang et al. (2021)',\n"," 'Transformer-based LMs',\n"," 'Week 5 lecture summary',\n"," 'Before the seminar ',\n"," 'Next time']"]},"metadata":{},"execution_count":26}],"source":["# the reagents are replace with a space\n","slideppheadings=[]\n","for sentences in slideppheadings_1:\n","  sentences=sentences.replace(\"\\n\",\". \")\n","  sentences=sentences.replace(\"\\t\",\" \")\n","  sentences=sentences.replace(\"\\x0b\",\" \")\n","  slideppheadings.append(sentences)\n","slideppheadings"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"j20uanJtuSFm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866434402,"user_tz":-60,"elapsed":17,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"8c7e8331-c952-4c95-aafa-0a8b1600d324"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['AdvNLP Week 5',\n"," 'Distributional Semantics. Bootstrapping semantics from context. Probabilistic language models . n-gram modelling, perplexity and generalization. Neural language models. Word-based and character-based. Word embeddings. Dimensionality reduction, neural language models, word2vec, GloVe',\n"," 'Part 1. Named Entity Recognition. What and why. Challenges. NE types, labelling, evaluation and features',\n"," 'Natural Language Generation. Chatbots, automatic content creation. Summarisation. Reduce to key points (abstractive), extract key points (extractive). Question Answering. Natural language q&a given a text passage. Machine Translation. Text, speech or any “language” translation (e.g. Q&A). Text Classification (Sequence Labelling). Part of speech (synactic), named entity recognition (semantic) and event extraction. Sentiment analysis, intent extraction. Language Modelling and Similarity. Can be applied to most tasks. . ',\n"," 'Assigning labels to a sequence of variables. The detection and classification of named entities in a text. A named entity is anything which can be referred to with a proper name e.g., “Boris Johnson”, “Pizza Hut”, “Brighton”, but may also include dates, times, prices and more. Often multi-word phrases. Semantic structured prediction. . . ',\n"," 'NER is the basis for downstream NLP tasks. Sentiment or intent regarding entities. The relation between entities in fact/relation extraction. Entity-linking (co-ref resolution) and KBP. Entity-informed search (GKG) and question answering regarding an entity. Google/Bing Infobox. Competitive/Product Intelligence. . . ',\n"," 'Manchester United striker Wayne Rooney has agreed a new five-and-a-half year contract worth up to £300,000 a week.. The 28-year-old England international will extend his current contract by four years, tying him to the club until June 2019.. Rooney joined United from Everton in August 2004 and is only 42 goals shy of passing Bobby Charlton’s record of 249 for United. . The former Everton forward has taken 430 games in all competitions to score his 208 goals for the Red Devils.. The club have yet to confirm the contract but BBC sports editor David Bond said the deal had been agreed.Manchester United striker Wayne Rooney has agreed a new five-and-a-half year contract worth up to £300,000 a week.. The 28-year-old England international will extend his current contract by four years, tying him to the club until June 2019.. Rooney joined United from Everton in August 2004 and is only 42 goals shy of passing Bobby Charlton’s record of 249 for United. . The former Everton forward has taken 430 games in all competitions to score his 208 goals for the Red Devils.. The club have yet to confirm the contract but BBC sports editor David Bond said the deal had been agreed.',\n"," 'Types of Named EntityThe most popular NER benchmark, CoNLL-2003, includes only these 4 entity types. Other benchmarks include more types, e.g. OntoNotes v5.0 includes 18 types. Temporal expressions and numerical expressions are often included. Some approaches aim to discover any entity regardless of type. Which entity type set might be most useful?Types of Named EntityDifficulties:. Two types of ambiguity: boundary and type. Boundary detection (e.g. the New York Times) – a harder problem than PoS tagging. Two types of type ambiguity: entity-noun, entity-entity. Variation, even with reliable text sources (e.g. United, Utd, Utd.). ',\n"," 'Sequence Labelling – IOB encodingI \\uf0e0 inside a chunk. O \\uf0e0 outside a chunk. B \\uf0e0 beginning a chunkSequence Labelling – IOB encodingI \\uf0e0 inside a chunk. O \\uf0e0 outside a chunk. B \\uf0e0 beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token. Find the correct spans of text that constitute an entity. Typically entities should be identified with the correct type and exact position. Sometimes multiple scores are included including partial overlaps. Also known as BIO encoding. . ',\n"," 'Evaluation ',\n"," 'Which rules or features might be useful in identifying these entity types?. Features commonly used in NERWhat might the choice of features depend on?',\n"," 'Humans annotate training documents. IOB encoding. Feature extraction performed if necessary. Classifier (e.g., HMM, SVM, MEMM, CRF, LSTM or a combination) trained . Evaluation carried out on held out test data typically using precision, recall and the F-measure (F1). Paper is published (possibly)',\n"," 'Sequence labelling task – . We want to assign the most likely sequence of labels given the observed tokens. NOT the most likely label for each token given all of the other tokens. So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt',\n"," 'AdvNLP Week 5',\n"," 'Approximate chronology of NER approaches. Rule-based. Generative (e.g. HMM). Discriminative (e.g. MEMM, CRF). RNN-based, usually LSTM. (Usually) Transformer/attention-based large language models, fine-tuned (e.g. BERT). Hybrid. ',\n"," 'Heuristics, entity lookup lists (gazeteers). Varying degrees of inclusion of supervised ML. Bootstrapping using initial set of seeds. Still used in non-academic scenarios',\n"," 'Model joint probability distributions from training data. Can be used to generate new data from these distributions. Use Bayes theorem to obtain a conditional probability to label unseen data. Examples of generative models are Naïve Bayes and the Hidden Markov Model. ',\n"," 'Model sequences of observed variables (words) and not-directly-observed hidden variables (NE tags). Generated from a labelled dataset (for NER, words and associated NE tags). Consists of two probability distributions. tag type to tag type (transition probabilities). words for each tag type (emission probabilities). . . . To apply a generated HMM to new sentences. Two simplifying assumptions:. bigram – only the previous tag type is required to predict the current tag type. independence – words are the only (observable) feature required to predict tag type. Use simplified Bayes theorem to find the most likely transition for each word. Tag sequences are output for each word wi using. max( max(p(ti-1|ti-2)*p(ti|ti-1)) * p(wi|ti) ). The Viterbi recursive algorithm is used to apply this to decode each sentence by populating a matrix of results word by word (cols=words, rows=tags). This matrix can be referred back to to retrieve previous transition probabilities. . . . . . Tag sequences are output for each word wi using. max( max(p(ti-1|ti-2)*p(ti|ti-1)) * p(wi|ti) ). . . . . . Drawbacks. Arise from the two simplifying assumptions. Bigram limits model history . Feature independence limits model richness. Difficult to add additional features. . . . . . . . ',\n"," 'Simplify the problem by discriminating between classes (NE tag types) rather than modelling every data point. Leverage multiple (potentially interdependent) features (e.g. word shape, presence in gazeteer, PoS, word embeddings) which can improve prediction and help with sparsity. Examples of discriminative models are the Maximum Entropy Markov Model (MEMM) and the Conditional Random Field (CRF). . . . ',\n"," 'Lafferty et al. (2001). Based on log-linear models like regression. Any combination of features is allowed. Include features that help with unknown words (e.g. word shape). One matrix of inputs (sentences and words). One matrix of outputs (NE type labels). Input and output matrix linked by WEIGHTED set of rules. A large set of predictive “feature rules” are generated from training data (e.g. presence of wi in a gazetteer). Rules have access to all words, but only the previous label (linear chain CRF) – this makes decoding easier. Each rule results in a score. When applied to training data for each step (word), rule scores are aggregated for each rule and weighted, then summed to give the score for that step (i.e. a weight exists for each global feature). During training, weights are updated using log-likelihood and SGD. New sentences are labelled using Viterbi (as this is a linear chain) in the same way as HMM, except a sum of weighted rule aggregations if used to populated each cell in the Viterbi matrix (rather than Bayes rule as in HMM).. ',\n"," 'Implementations of CRF. Many good implementations available. Avoid reinventing the wheel!',\n"," '',\n"," 'CRF performs well but is subject to drawbacks. Very slow to train. Lafferty et al.2001 report (on the same dataset):. MEMM+ trained to convergence from uniform distribution in 100 iterations. CRF did not converge after 2000 iterations from the uniform distribution. using the MEMM+ parameters to initialise the CRF, it converged in 1000 iterations. Features need to be hand-crafted',\n"," 'Bidirectional-LSTM is most popular (non-transformer-based). Vanilla RNN and GRU have also been used. NNs allow word, char or other embeddings to be used (or generated). Ma and Hovy (2016) is a good base Bi-LSTM architecture (CoNLL English SotA in 2016 and basis for Wang et al. SotA in 2021). ',\n"," 'Also our seminar paper for this week. End-to-end sequence labelling via Bi-directional LSTM-CNNs-CRF. Achieved F1 91.21 which was SotA in 2016. Brings together concepts learned thus far. End-to-end – no external data (apart from word embeddings) – this is a big deal as previous systems were feature-engineered. A char representation for each word is generated from a CNN (30 filters of width 3) based on char embeddings. Char rep is concatenated with GloVe word embedding. Bi-directional LSTM is achieved by concatenating left-to-right and right-to-left LSTM hidden states (200 units). CRF is used as output layer (rather than Softmax) to decode label sequences. Dropout (0.5) used in CNN and LSTM to prevent overfit. BIOES tagging scheme (E for ending, S for single element). Convergence at around 50 epochs (with early stopping). Word embeddings are fine-tuned during trainingArchitecture diagrams from paper. CRF shows tags from PoS task, NER task uses same config (except for initial LR)',\n"," 'Automated Concatenation of Embeddings for Structured Prediction. Automatic selection of embeddings for tasks using neural architecture search. Generates better word representations. Reduces human effort of architecture design. Different combinations of embeddings are assessed by task accuracy. Paper focusses on ACE, but is SotA in 6 tasks, including NER. Achieved F1 94.6 on English CoNLL-2003 using ACE with embedding fine-tuning. BiLSTM-CRF model based on Ma&Hovy is used for sequence-structured outputs. Embeddings are selected from a combination of contextualised, non-contextualised and character embeddings. Task-specific embedding fine-tuning is done before ACE part. ACE does F1 0.6 better than simply concatenating ALL embedding types!. The sets of embeddings used for tasks were quite variable. The most consistent for semantic sequence tasks (inc. NER) were contextualised embeddings: multi-lingual Flair (87%) and ELMo (80%) and non-contextualised fastText/GloVe (80%). Character embeddings were only selected 40% of the time – contextualised are sufficient?. . . ',\n"," 'Large pre-trained language models have achieved success in many NLP tasks, including NER. (Typically) Use a deep transformer architecture with many layers/parameters . (Typically) Model long-range dependencies using attention mechanism. (Typically) Require task-based fine-tuning. Contextualised word representations/embeddings are generated using sub-word input (BPE in the case of BERT). Notable systems:. ELMo (Peters et al., 2018) 2-layer biLSTM trained on a bidirectional language modelling task. GPT-2 (Radford et al., 2019) uni-directional transformer-based. BERT (Devlin et al., 2019) bi-directional transformer-based MLM and NSP. Optimsations:. RoBERTa (Liu et al., 2019) improved BERT performance through stronger masking strategies. DistilBERT (Sanh et al., 2019) smaller and faster with 95% of the original BERT perform. The are many other BERT variants. Discussed in more detail in weeks 7 and 8. . . . ',\n"," 'Part 1. Named Entity Recognition. What and why. NE types, labelling, evaluation and features',\n"," 'Please read Ma and Hovy (2016)',\n"," 'Getting data!. For supervised training. Existing sets. More efficient labelling. Semi-supervised approaches. Distant supervision. Bootstrapping. Unsupervised. . ']"]},"metadata":{},"execution_count":27}],"source":["# the reagents are replace with a space\n","slidepptexts_=[]\n","for sentences in slidepptexts:\n","  sentences=sentences.replace(\"\\n\",\". \")\n","  sentences=sentences.replace(\"\\t\",\" \")\n","  sentences=sentences.replace(\"\\x0b\",\" \")\n","  sentences=sentences.replace(\"L3\",\" \")\n","\n","\n","  slidepptexts_.append(sentences)\n","slidepptexts_"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"NjnZt0sbuSJV","executionInfo":{"status":"ok","timestamp":1661866434402,"user_tz":-60,"elapsed":13,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#sentence tokenizer\n","from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n","punkt_param = PunktParameters()\n","punkt_param.abbrev_types = set(['e.g','a.l','i.e','inc','etc'])\n","sentence_splitter = PunktSentenceTokenizer(punkt_param)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"hMusswcOuSM5","executionInfo":{"status":"ok","timestamp":1661866434403,"user_tz":-60,"elapsed":13,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#the sentences are tokenized\n","from nltk.tokenize import sent_tokenize\n","sentencesplitted=[]\n","for i in range(len(slidepptexts_)):\n","  sentencesplitted.append(sentence_splitter.tokenize(slidepptexts_[i]))\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"STZTZptPuSQ7","executionInfo":{"status":"ok","timestamp":1661866439953,"user_tz":-60,"elapsed":5563,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#SPaCy lib\n","import spacy\n","import en_core_web_sm\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"5OmRgxeduSUn","executionInfo":{"status":"ok","timestamp":1661866441704,"user_tz":-60,"elapsed":1770,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#a dictionary with the dep_ tags of spacy is created.\n","spacydict={}\n","for i in range(len(sentencesplitted)):\n","  spacylist=[]\n","  for sentences in sentencesplitted[i]:\n","    spacyulist=[]\n","    doc=(nlp(sentences))\n","    sentence2=next(doc.sents)\n","    for word in sentence2:\n","      spacyulist.append((word,word.dep_))\n","    spacylist.append(spacyulist)\n","  spacydict[slideppheadings[i]]=spacylist\n","     "]},{"cell_type":"code","execution_count":32,"metadata":{"id":"H7PiwbcRu3oU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866442196,"user_tz":-60,"elapsed":512,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"25d5a9cb-af9e-42c1-f4c5-4d2fe1f51c1f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["nltk.download('punkt')\n","from nltk import word_tokenize\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ZCOtj55LuSXt","executionInfo":{"status":"ok","timestamp":1661866442197,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["previouswords=[\"formerly\",\"earlier\",\"earlier on\",\"before\",\"previously\",\"previous\",\"early\",\"previous time\",\"last week\",\"so far\",\"lastly\",\"last time\",\"last lesson\",\"last course\",\"so far\",\"Previous\",\"Previously\",\"Last time\"]"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"b6AKFgxvu8vX","executionInfo":{"status":"ok","timestamp":1661866442433,"user_tz":-60,"elapsed":239,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["nextwords=[\"next time\",\"after this\",\"afterwards\",\"next week\",\"then\",\"future\",\"next course\",\"next lesson\",\"future lecture\",\"future lectures\",\"next lecture\",\"Next\",\"After\"]"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"54MylNlfu_Cm","executionInfo":{"status":"ok","timestamp":1661866442434,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["question_words = [\"what\", \"why\", \"when\", \"where\", \n","             \"name\", \"is\", \"how\", \"do\", \"does\", \n","             \"which\", \"are\", \"could\", \"would\", \n","             \"should\", \"has\", \"have\", \"whom\", \"whose\",\"who\",\"don't\"]"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"qsJlTqravAZS","executionInfo":{"status":"ok","timestamp":1661866442435,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["from nltk.util import ngrams\n","text=\"next week we will cover\"\n","_1gram = text.split(\" \")\n","_2gram = [' '.join(e) for e in ngrams(_1gram, 2)]\n"]},{"cell_type":"code","source":["a=\"Next time\"\n","_1gram = str(list(a)).lower().split(\" \")\n","bigrm =[' '.join(e) for e in ngrams(_1gram, 2)]\n","bigrm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSIT5z-4LzGJ","executionInfo":{"status":"ok","timestamp":1661866442435,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"69d512c3-7077-47cb-e439-5a9fbf19fdd6"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"['n', 'e',\",\n"," \"'e', 'x',\",\n"," \"'x', 't',\",\n"," \"'t', '\",\n"," \"' ',\",\n"," \"', 't',\",\n"," \"'t', 'i',\",\n"," \"'i', 'm',\",\n"," \"'m', 'e']\"]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","execution_count":38,"metadata":{"id":"zlXB68cOvEwp","executionInfo":{"status":"ok","timestamp":1661866442435,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#the function to understand if the header presents the future content or the previous content or if the header is a question by checking the words in above. If it is a question what is the interrogation pronoun.\n","import nltk\n","from nltk.util import ngrams\n","def headercheck(spacydictk,i):\n","  _1gram = str(list(spacydictk)[i]).lower().split(\" \")\n","  bigrm =[' '.join(e) for e in ngrams(_1gram, 2)]\n","  tokenizedheading=word_tokenize(str(list(spacydictk)[i].lower()))\n","  question_word_exist=False\n","  next_word_exist=False\n","  previous_word_exist=False\n","  for words in tokenizedheading:\n","    if (words.lower() in  question_words) and (\"?\" in tokenizedheading):\n","      question_word_exist=True\n","      question_word=words.lower()\n","    elif words in nextwords:\n","      next_word_exist=True\n","    elif words in previouswords:\n","      previous_word_exist=True\n","  for words in nextwords:\n","    if words in bigrm:\n","        next_word_exist=True\n","  for words in previouswords:\n","    if words in bigrm:\n","      previous_word_exist=True \n","  \n","  if question_word_exist==False and previous_word_exist==False and next_word_exist==False:\n","    return \"none\"\n","  elif question_word_exist==True and previous_word_exist==False and next_word_exist==False:\n","    if question_word==\"why\":\n","      return \"why\"\n","    else :\n","      return \"question\"\n","  elif previous_word_exist==True:\n","    return \"previous\"\n","  elif next_word_exist==True:\n","    return \"next\"\n","\n","\n","         \n"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"8aGlT4tVvAf5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866449213,"user_tz":-60,"elapsed":6784,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"435ad299-8ea3-4707-f91a-d2a3fb46587b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Named Entity Recognition is advnlp week 5 ',\n"," 'Previously distributional semantics  was covered.',\n"," 'Previously bootstrapping semantics from context  was covered.',\n"," 'Previously probabilistic language models  was covered.',\n"," 'Previously n - gram modelling , perplexity and generalization  was covered.',\n"," 'Previously neural language models  was covered.',\n"," 'Previously word - based and character - based  was covered.',\n"," 'Previously word embeddings  was covered.',\n"," 'Previously dimensionality reduction , neural language models , word2vec , glov was covered.',\n"," 'Week 5 overview is part 1 . ',\n"," 'Week 5 overview is named entity recognition . ',\n"," 'Week 5 overview is what and why . ',\n"," 'Week 5 overview is challenges . ',\n"," 'Week 5 overview is ne types , labelling , evaluation and features ',\n"," 'NLP Tasks are natural language generation . ',\n"," 'NLP Tasks are chatbots , automatic content creation . ',\n"," 'NLP Tasks is summarisation . ',\n"," 'They reduce to key points ( abstractive ) , extract key points ( extractive ) . ',\n"," 'NLP Tasks are question answering . ',\n"," 'Natural language q&a given a text passage . ',\n"," 'NLP Tasks are machine translation . ',\n"," 'NLP Tasks are text , speech or any “ language ” translation ( e.g. q&a ) . ',\n"," 'NLP Tasks are text classification ( sequence labelling ) . ',\n"," 'NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction . ',\n"," 'Sentiment analysis , intent extraction . ',\n"," 'NLP Tasks are language modelling and similarity . ',\n"," 'NLP Tasks can be applied to most tasks . ',\n"," 'NLP Tasks . ',\n"," 'Named Entity Recognition  is assigning labels to a sequence of variables . ',\n"," 'Named Entity Recognition  is the detection and classification of named entities in a text . ',\n"," 'A named entity is anything which can be referred to with a proper name e.g. , “ Boris Johnson ” , “ Pizza Hut ” , “ Brighton ” , but may also include dates , times , prices and more . ',\n"," 'Named Entity Recognition  is often multi - word phrases . ',\n"," 'Named Entity Recognition  is semantic structured prediction . . . ',\n"," 'NER is the basis for downstream NLP tasks . ',\n"," 'Why Named Entity Recognition? It is sentiment or intent regarding entities . ',\n"," 'Why Named Entity Recognition? It is the relation between entities in fact / relation extraction . ',\n"," 'Why Named Entity Recognition? It is entity - linking ( co - ref resolution ) and kbp . ',\n"," 'Why Named Entity Recognition? It is entity - informed search ( gkg ) and question answering regarding an entity . ',\n"," 'Why Named Entity Recognition? It is google / bing infobox . ',\n"," 'Why Named Entity Recognition? It is competitive / product intelligence . . . ',\n"," 'Manchester United striker Wayne Rooney has agreed a new five - and - a - half year contract worth up to £ 300,000 a week .. ',\n"," 'Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types . ',\n"," 'Other benchmarks include more types , e.g. OntoNotes v5.0 includes 18 types . ',\n"," 'Types of Named Entity is temporal expressions and numerical expressions are often included . ',\n"," 'Some approaches aim to discover any entity regardless of type . ',\n"," 'Which entity type set might be most useful?Types of Named EntityDifficulties : . ',\n"," 'Types of Named Entity is two types of ambiguity : boundary and type . ',\n"," 'Types of Named Entity is boundary detection ( e.g. the new york times ) – a harder problem than pos tagging . ',\n"," 'Types of Named Entity is two types of type ambiguity : entity - noun , entity - entity . ',\n"," 'Types of Named Entity is variation , even with reliable text sources ( e.g. united , utd , utd . ',\n"," 'Types of Named Entity ) ',\n"," 'Sequence Labelling – IOB encoding is sequence labelling – iob encodingi \\uf0e0 inside a chunk . ',\n"," 'Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk . ',\n"," 'B \\uf0e0 beginning a chunkSequence Labelling – IOB encodingI \\uf0e0 inside a chunk . ',\n"," 'Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk . ',\n"," 'B \\uf0e0 beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token . ',\n"," 'Find the correct spans of text that constitute an entity . ',\n"," 'Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position . ',\n"," 'For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps . ',\n"," 'Sequence Labelling – IOB encoding is also known as bio encoding . ',\n"," 'Sequence Labelling – IOB encoding . ',\n"," 'Evaluation  evaluation ',\n"," 'Features commonly used in NER which rules or features might be useful in identifying these entity types ? . ',\n"," 'Features commonly used in NERWhat might the choice of features depend on ? ',\n"," 'Humans annotate training documents . ',\n"," 'Typical Supervised Approach is iob encoding . ',\n"," 'Feature extraction performed if necessary . ',\n"," 'Classifier ( e.g. , HMM , SVM , MEMM , CRF , LSTM or a combination ) trained . ',\n"," 'Evaluation carried out on held out test data typically using precision , recall and the F - measure ( F1 ) . ',\n"," 'For Typical Supervised Approach , paper is published ( possibly ) ',\n"," 'Classification is sequence labelling task – . ',\n"," 'We want to assign the most likely sequence of labels given the observed tokens . ',\n"," 'Classification is not the most likely label for each token given all of the other tokens . ',\n"," 'So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt ',\n"," 'Named Entity Recognition Part 2 is advnlp week 5 ',\n"," 'NER Approaches is approximate chronology of ner approaches . ',\n"," 'NER Approaches is rule - based . ',\n"," 'NER Approaches is generative ( e.g. hmm ) . ',\n"," 'NER Approaches is discriminative ( e.g. memm , crf ) . ',\n"," 'They rnn - based , usually lstm . ',\n"," 'NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g. bert ) . ',\n"," 'NER Approaches is hybrid . ',\n"," 'Rule-based is heuristics , entity lookup lists ( gazeteers ) . ',\n"," 'Rule-based is varying degrees of inclusion of supervised ml . ',\n"," 'Bootstrapping using initial set of seeds . ',\n"," 'Rule-based is still used in non - academic scenarios ',\n"," 'Generative models are model joint probability distributions from training data . ',\n"," 'Generative models can be used to generate new data from these distributions . ',\n"," 'Use Bayes theorem to obtain a conditional probability to label unseen data . ',\n"," 'Examples of generative models are Naïve Bayes and the Hidden Markov Model . ',\n"," 'Hidden Markov Model (HMM) is model sequences of observed variables ( words ) and not - directly - observed hidden variables ( ne tags ) . ',\n"," 'Hidden Markov Model (HMM) is generated from a labelled dataset ( for ner , words and associated ne tags ) . ',\n"," 'It consists of two probability distributions . ',\n"," 'Hidden Markov Model (HMM) is tag type to tag type ( transition probabilities ) . ',\n"," 'Hidden Markov Model (HMM) is words for each tag type ( emission probabilities ) . . . . ',\n"," 'Hidden Markov Model (HMM) is two simplifying assumptions : . ',\n"," 'For Hidden Markov Model (HMM) , bigram – only the previous tag type is required to predict the current tag type . ',\n"," 'independence – words are the only ( observable ) feature required to predict tag type . ',\n"," 'Use simplified Bayes theorem to find the most likely transition for each word . ',\n"," 'Tag sequences are output for each word wi using . ',\n"," 'Hidden Markov Model (HMM) is max ( max(p(ti-1|ti-2)*p(ti|ti-1 ) ) ',\n"," 'The Viterbi recursive algorithm is used to apply this to decode each sentence by populating a matrix of results word by word ( cols = words , rows = tags ) . ',\n"," 'Hidden Markov Model (HMM) this matrix can be referred back to to retrieve previous transition probabilities . . . . . . ',\n"," 'Hidden Markov Model (HMM) is max ( max(p(ti-1|ti-2)*p(ti|ti-1 ) ) ',\n"," 'They arise from the two simplifying assumptions . ',\n"," 'Bigram limits model history . ',\n"," 'Feature independence limits model richness . ',\n"," 'Hidden Markov Model (HMM) is difficult to add additional features . ',\n"," 'Hidden Markov Model (HMM) is . . ',\n"," 'They simplify the problem by discriminating between classes ( ne tag types ) rather than modelling every data point . ',\n"," 'Leverage multiple ( potentially interdependent ) features ( e.g. word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity . ',\n"," 'Examples of discriminative models are the Maximum Entropy Markov Model ( MEMM ) and the Conditional Random Field ( CRF ) . ',\n"," 'Discriminative models is . . ',\n"," 'Conditional Random Field (CRF) is lafferty et al . ',\n"," 'Conditional Random Field (CRF) is ( 2001 ) . ',\n"," 'Conditional Random Field (CRF) is based on log - linear models like regression . ',\n"," 'For Conditional Random Field (CRF) , any combination of features is allowed . ',\n"," 'Include features that help with unknown words ( e.g. word shape ) . ',\n"," 'Conditional Random Field (CRF) is one matrix of inputs ( sentences and words ) . ',\n"," 'Conditional Random Field (CRF) is one matrix of outputs ( ne type labels ) . ',\n"," 'Conditional Random Field (CRF) input and output matrix linked by weighted set of rules . ',\n"," 'For Conditional Random Field (CRF) , a large set of predictive “ feature rules ” are generated from training data ( e.g. presence of wi in a gazetteer ) . ',\n"," 'Rules have access to all words , but only the previous label ( linear chain CRF ) – this makes decoding easier . ',\n"," 'Each rule results in a score . ',\n"," 'When applied to training data for each step ( word ) , rule scores are aggregated for each rule and weighted , then summed to give the score for that step ( i.e. a weight exists for each global feature ) . ',\n"," 'For Conditional Random Field (CRF) , during training , weights are updated using log - likelihood and sgd . ',\n"," 'New sentences are labelled using Viterbi ( as this is a linear chain ) in the same way as HMM , except a sum of weighted rule aggregations if used to populated each cell in the Viterbi matrix ( rather than Bayes rule as in HMM ) .. ',\n"," 'Implementations of CRF is implementations of crf . ',\n"," 'Many good implementations available . ',\n"," 'They avoid reinventing the wheel ! ',\n"," 'CRF performs well but is subject to drawbacks . ',\n"," 'Drawbacks of using CRFs very slow to train . ',\n"," 'Drawbacks of using CRFs are lafferty et al.2001 report ( on the same dataset ): . ',\n"," 'Drawbacks of using CRFs memm+ trained to convergence from uniform distribution in 100 iterations . ',\n"," 'CRF did not converge after 2000 iterations from the uniform distribution . ',\n"," 'using the MEMM+ parameters to initialise the CRF , it converged in 1000 iterations . ',\n"," 'Features need to be hand - crafted ',\n"," 'Bidirectional - LSTM is most popular ( non - transformer - based ) . ',\n"," 'For Neural Models , vanilla rnn and gru have also been used . ',\n"," 'NNs allow word , char or other embeddings to be used ( or generated ) . ',\n"," 'Ma and Hovy ( 2016 ) is a good base Bi - LSTM architecture ( CoNLL English SotA in 2016 and basis for Wang et al . ',\n"," 'Neural Models are sota in 2021 ) . ',\n"," 'Ma and Hovy (2016) is also our seminar paper for this week . ',\n"," 'Ma and Hovy (2016) is end - to - end sequence labelling via bi - directional lstm - cnns - crf . ',\n"," 'Achieved F1 91.21 which was SotA in 2016 . ',\n"," 'It brings together concepts learned thus far . ',\n"," 'End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered . ',\n"," 'For Ma and Hovy (2016) , a char representation for each word is generated from a cnn ( 30 filters of width 3 ) based on char embeddings . ',\n"," 'For Ma and Hovy (2016) , char rep is concatenated with glove word embedding . ',\n"," 'For Ma and Hovy (2016) , bi - directional lstm is achieved by concatenating left - to - right and right - to - left lstm hidden states ( 200 units ) . ',\n"," 'For Ma and Hovy (2016) , crf is used as output layer ( rather than softmax ) to decode label sequences . ',\n"," 'Ma and Hovy (2016) dropout ( 0.5 ) used in cnn and lstm to prevent overfit . ',\n"," 'It bioes tagging scheme ( e for ending , s for single element ) . ',\n"," 'Ma and Hovy (2016) is convergence at around 50 epochs ( with early stopping ) . ',\n"," 'Word embeddings are fine - tuned during trainingArchitecture diagrams from paper . ',\n"," 'CRF shows tags from PoS task , NER task uses same config ( except for initial LR ) ',\n"," 'Wang et al. (2021) is automated concatenation of embeddings for structured prediction . ',\n"," 'Wang et al. (2021) is automatic selection of embeddings for tasks using neural architecture search . ',\n"," 'It generates better word representations . ',\n"," 'It reduces human effort of architecture design . ',\n"," 'Wang et al. (2021) is different combinations of embeddings are assessed by task accuracy . ',\n"," 'Wang et al. (2021) paper focusses on ace , but is sota in 6 tasks , including ner . ',\n"," 'Achieved F1 94.6 on English CoNLL-2003 using ACE with embedding fine - tuning . ',\n"," 'For Wang et al. (2021) , bilstm - crf model based on ma&hovy is used for sequence - structured outputs . ',\n"," 'For Wang et al. (2021) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings . ',\n"," 'For Wang et al. (2021) , task - specific embedding fine - tuning is done before ace part . ',\n"," 'ACE does F1 0.6 better than simply concatenating ALL embedding types ! . ',\n"," 'The sets of embeddings used for tasks were quite variable . ',\n"," 'The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) . ',\n"," 'For Wang et al. (2021) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . . ',\n"," 'Wang et al. (2021) . ',\n"," 'Large pre - trained language models have achieved success in many NLP tasks , including NER . ',\n"," 'Transformer-based LMs ( typically ) use a deep transformer architecture with many layers / parameters . ',\n"," 'Transformer-based LMs are ( typically ) model long - range dependencies using attention mechanism . ',\n"," 'Transformer-based LMs ( typically ) require task - based fine - tuning . ',\n"," 'For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) . ',\n"," 'Transformer-based LMs are notable systems : . ',\n"," 'Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task . ',\n"," 'Transformer-based LMs are gpt-2 ( radford et al . , 2019 ) uni - directional transformer - based . ',\n"," 'Transformer-based LMs are bert ( devlin et al . , 2019 ) bi - directional transformer - based mlm and nsp . ',\n"," 'Transformer-based LMs are optimsations : . ',\n"," 'RoBERTa ( Liu et al . , 2019 ) improved BERT performance through stronger masking strategies . ',\n"," 'Transformer-based LMs distilbert ( sanh et al . , 2019 ) smaller and faster with 95 % of the original bert perform . ',\n"," 'The are many other BERT variants . ',\n"," 'Transformer-based LMs are discussed in more detail in weeks 7 and 8 . . . . ',\n"," 'Week 5 lecture summary is part 1 . ',\n"," 'Week 5 lecture summary is named entity recognition . ',\n"," 'Week 5 lecture summary is what and why . ',\n"," 'Week 5 lecture summary is ne types , labelling , evaluation and features ',\n"," 'Before the seminar  please read ma and hovy ( 2016 ) ',\n"," 'Next time getting data !  will be covered.',\n"," 'Next time for supervised training  will be covered.',\n"," 'Next time existing sets  will be covered.',\n"," 'Next time more efficient labelling  will be covered.',\n"," 'Next time semi - supervised approaches  will be covered.',\n"," 'Next time distant supervision  will be covered.',\n"," 'Next time bootstrapping  will be covered.',\n"," 'Next time unsupervised  will be covered.',\n"," 'Next time . ']"]},"metadata":{},"execution_count":39}],"source":["#the sub conditions and the main conditions of the header joining to the sentence step. The decisions are made by looking at the SpaCy pos_,tag_, and dep_  tags. Of else statements are created. sub and main conditions are shown with figures and explained in details in the dissertation.  \n","anewlist=[]\n","for i in range(len(spacydict)):\n"," \n","  nsubjchecksentencelist=[]\n","  for j in range(len(list(spacydict.values())[i])):\n","    \n","    nsubjcheckwordslist=[]\n","    justwords=\"\"\n","    taglistofsentence=[]\n","    for k in range(len(list(spacydict.values())[i][j])):\n","      \n","      nsubjcheckwordslist.append((list(spacydict.values())[i][j][k][1]))\n","     \n","     \n","      justwords=justwords+str(list(spacydict.values())[i][j][k][0])+\" \"\n","  \n","    postagged=nlp(justwords)\n","    postaggedlowered=justwords.lower()\n","    postaggedlowered=nlp(postaggedlowered)\n","    for word in postaggedlowered:\n","     taglistofsentence.append(word.tag_)\n","\n","    headlinetagged=nlp(list(spacydict.keys())[i])\n","    lemma_tags = [\"NNS\", \"NNPS\"] #plurial singular\n","\n","    \n","        \n","    \n","\n","          \n","    if \"nsubj\" in nsubjcheckwordslist or \"expl\" in nsubjcheckwordslist:\n","       anewlist.append(justwords)\n","       #print(\"t\")\n","    else:\n","      \n","\n","        if (len(postaggedlowered) > 1) and (postaggedlowered[0].pos_ == \"ADJ\" or taglistofsentence[0]==\"VBG\") and headlinetagged[-1].tag_ not in lemma_tags and postaggedlowered[1].text != \".\" :\n","          if headercheck(spacydict.keys(),i) not in list(spacydict.keys()) and headercheck(spacydict.keys(),i) ==\"why\" :\n","            anewlist.append(str(list(spacydict.keys())[i])+\" It \"+\"is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"none\" :\n","            anewlist.append((str(list(spacydict.keys())[i])+\" is \"+justwords.lower()))\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"previous\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" was covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"next\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" will be covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"question\":\n","            w=nlp(str(list(spacydict.keys())[i]))\n","            subjs=\"\"\n","            for a in w:\n","              #print(a.dep_)\n","              if a.dep_ == \"nsubj\":\n","                subjs=a\n","            anewlist.append(str(subjs)+\" is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","            \n","\n","\n","        elif (len(postaggedlowered) > 1) and (postaggedlowered[0].pos_ == \"ADJ\" or taglistofsentence[0]==\"VBG\") and headlinetagged[-1].tag_ in lemma_tags and  postaggedlowered[1].text != \".\"  : #NER Approaches are rule - based\n","          if headercheck(spacydict.keys(),i) not in list(spacydict.keys()) and headercheck(spacydict.keys(),i) ==\"why\" :\n","            anewlist.append(str(list(spacydict.keys())[i])+\" They \"+\"are \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"none\" :\n","            anewlist.append((str(list(spacydict.keys())[i])+\" are \"+justwords.lower()))\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"previous\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" was covered.\")\n","          elif headercheck(spacydict.keys(),i)==\"next\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" will be covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"question\":\n","            w=nlp(str(list(spacydict.keys())[i]))\n","            subjs=\"\"\n","            for a in w:\n","              #print(a.dep_)\n","              if a.dep_ == \"nsubj\":\n","                subjs=a\n","            anewlist.append(str(subjs)+\" are \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          \n","          \n","\n","        elif (len(postaggedlowered) > 1) and (postaggedlowered[0].pos_ == \"PROPN\" or postaggedlowered[0].pos_== \"NOUN\") and postaggedlowered[1].text==\"-\" and postaggedlowered[2].pos_==\"VERB\" and headlinetagged[-1].tag_ not in lemma_tags:\n","          if headercheck(spacydict.keys(),i) not in list(spacydict.keys()) and headercheck(spacydict.keys(),i) ==\"why\" :\n","            anewlist.append(str(list(spacydict.keys())[i])+\" It \"+\"is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"none\" :\n","            anewlist.append((str(list(spacydict.keys())[i])+\" is \"+justwords.lower()))\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"previous\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" was covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"next\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" will be covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"question\":\n","            w=nlp(str(list(spacydict.keys())[i]))\n","            subjs=\"\"\n","            for a in w:\n","              #print(a.dep_)\n","              if a.dep_ == \"nsubj\":\n","                subjs=a\n","            anewlist.append(str(subjs)+\" is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          \n","\n","        elif (len(postaggedlowered) > 1) and \"VB\" not in taglistofsentence and \"VBP\" not in taglistofsentence and \"VBD\" not in taglistofsentence and \"VBZ\" not in taglistofsentence and headlinetagged[-1].tag_ in lemma_tags and (postaggedlowered[0].pos_ != \"PUNCT\" or not(postaggedlowered[0].pos_ == \"SPACE\" and  postaggedlowered[1].pos_ == \"PUNCT\")) and postaggedlowered[1].text != \".\":    #one matrix of inputs ( sentences and words ).    #one matrix of inputs ( sentences and words ).\n","          if headercheck(spacydict.keys(),i) not in list(spacydict.keys()) and headercheck(spacydict.keys(),i) ==\"why\" :\n","            anewlist.append(str(list(spacydict.keys())[i])+\" They \"+\"are \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"none\" :\n","            anewlist.append((str(list(spacydict.keys())[i])+\" are \"+justwords.lower()))\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"previous\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \" + justwords.lower()[:-2]+\" was covered.\")\n","          elif headercheck(spacydict.keys(),i)==\"next\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" will be covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"question\":\n","            w=nlp(str(list(spacydict.keys())[i]))\n","            subjs=\"\"\n","            for a in w:\n","              #print(a.dep_)\n","              if a.dep_ == \"nsubj\":\n","                subjs=a\n","            anewlist.append(str(subjs)+\" are \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","\n","        elif (len(postaggedlowered) > 1) and \"VB\" not in taglistofsentence and \"VBP\" not in taglistofsentence and \"VBD\" not in taglistofsentence and \"VBZ\" not in taglistofsentence and headlinetagged[-1].tag_ not in lemma_tags and (postaggedlowered[0].pos_ != \"PUNCT\" or not(postaggedlowered[0].pos_ == \"SPACE\" and  postaggedlowered[1].pos_ == \"PUNCT\")) and postaggedlowered[1].text != \".\" :    #one matrix of inputs ( sentences and words ).\n","          if headercheck(spacydict.keys(),i) not in list(spacydict.keys()) and headercheck(spacydict.keys(),i) ==\"why\" :\n","            anewlist.append(str(list(spacydict.keys())[i])+\" It \"+\"is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"none\" :\n","            anewlist.append((str(list(spacydict.keys())[i])+\" is \"+justwords.lower()))\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"previous\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" was covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"next\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" will be covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"question\":\n","            w=nlp(str(list(spacydict.keys())[i]))\n","            subjs=\"\"\n","            for a in w:\n","              #print(a.dep_)\n","              if a.dep_ == \"nsubj\":\n","                subjs=a\n","            anewlist.append(str(subjs)+\" is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","        elif len(postaggedlowered)==2:\n","          if headercheck(spacydict.keys(),i) not in list(spacydict.keys()) and headercheck(spacydict.keys(),i) ==\"why\" :\n","            anewlist.append(str(list(spacydict.keys())[i])+\" It \"+\"is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"none\" :\n","            anewlist.append((str(list(spacydict.keys())[i])+\" is \"+justwords.lower()))\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"previous\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" was covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"next\":\n","            anewlist.append(str(list(spacydict.keys())[i])+\" \"+justwords.lower()[:-2]+\" will be covered.\")\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","          elif headercheck(spacydict.keys(),i)==\"question\":\n","            w=nlp(str(list(spacydict.keys())[i]))\n","            subjs=\"\"\n","            for a in w:\n","              #print(a.dep_)\n","              if a.dep_ == \"nsubj\":\n","                subjs=a\n","            anewlist.append(str(subjs)+\" is \"+justwords.lower())\n","            nsubjchecksentencelist.append(nsubjcheckwordslist)\n","            \n","            \n","        elif \"nsubjpass\" in nsubjcheckwordslist and  ((\"VBZ\"  in taglistofsentence and \"VBN\" in taglistofsentence) or  ( \"VBP\" in taglistofsentence and \"VBN\" in taglistofsentence) ):#during training , weights are updated using log - likelihood and sgd . ',\n","          anewlist.append(\"For \"+(str(list(spacydict.keys())[i])+\" , \"+justwords.lower()))\n","          nsubjchecksentencelist.append(nsubjcheckwordslist)\n","        \n","        elif postaggedlowered[0].tag_ == \"VBZ\" or postaggedlowered[0].tag_ == \"VBD\" or  postaggedlowered[0].tag_ == \"VBP\" or  postaggedlowered[0].tag_ == \"VB\"  : #NLP!!!x\" is the natural language processing . ']\n","            w=nlp(str(list(spacydict.keys())[i]))\n","            subjs=\"\"\n","            exist=0\n","            for a in w:\n","              if a.dep_ == \"nsubj\":\n","                subjs=a\n","                exist=1\n","            if exist == 1:\n","              anewlist.append(str(subjs)+\" \"+justwords.lower())\n","              nsubjchecksentencelist.append(nsubjcheckwordslist)\n","            elif exist==0 and postaggedlowered[0].tag_ == \"VBZ\":\n","              anewlist.append(\"It \"+justwords.lower())\n","              nsubjchecksentencelist.append(nsubjcheckwordslist)\n","            elif (exist==0 and postaggedlowered[0].tag_ == \"VB\") or (exist==0 and postaggedlowered[0].tag_ == \"VBD\")or (exist==0 and postaggedlowered[0].tag_ == \"VBP\") :\n","              anewlist.append(\"They \"+justwords.lower())\n","              nsubjchecksentencelist.append(nsubjcheckwordslist)\n","              \n","        else :\n","            \n","              anewlist.append((str(list(spacydict.keys())[i])+\" \"+justwords.lower()))\n","              nsubjchecksentencelist.append(nsubjcheckwordslist)\n","\n","\n","          \n","anewlist"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"rjSTbKaNvAkC","executionInfo":{"status":"ok","timestamp":1661866449213,"user_tz":-60,"elapsed":20,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#the abbreviation names finding. By checking the words in the header and their first letters they are found.\n","spacydict.keys()\n","spacydict_keyslist=[]\n","anewlist_2=[]\n","longwords=[]\n","createdwords=[]\n","lenlongwords=[]\n","\n","for n in range(len(spacydict.keys())):\n","  keyss=word_tokenize(list(spacydict.keys())[n])\n","  #print(keyss)\n","  equality_done=False\n","  for i in range(len(keyss)):\n","   # print(keyss[i])\n","    if \"(\"==keyss[i] :\n","      first_bracket_loc=i\n","    #  print(first_bracket_loc)\n","    elif \")\"==keyss[i]:\n","      second_bracket_loc=i\n","     # print(second_bracket_loc)\n","  \n","  try:\n","    bracketword=\"\"\n","    for words in keyss[first_bracket_loc+1:second_bracket_loc]:\n","     #print(words,\"w1\")\n","     bracketword+=words\n","  except:\n","    continue\n","  try:\n","    createdword=\"\"\n","    longword=\"\"\n","    for words in keyss[:first_bracket_loc]:\n","      #print(words,\"w2\")\n","      createdword+=words[0]\n","      #print(createdword)\n","      longword+=words+\" \"\n","  except:\n","    continue\n","  try:  \n","    if bracketword.lower() ==  createdword.lower():\n","      #print(bracketword.lower(),\"done\")\n","      equality_done=True\n","\n","  except:\n","    continue\n","  if equality_done==True:\n","    lenlongword=len(word_tokenize(longword))\n","    longword=word_tokenize(longword)\n","    #print(longword,\"longword\")\n","    #print(n,\"nnnnnnnnnnnnnn\")\n","    #print(list(spacydict.keys())[n],\"header\")\n","    #print(createdword,\"createdword\")\n","    createdwords.append(createdword)\n","    #print(bracketword,\"bracketword\")\n","    #print(longword,\"longword\")\n","    longwords.append(longword)\n","    #print(lenlongword,\"lenlongword\")\n","    lenlongwords.append(lenlongword)\n","    #print(longword[lenlongword-1])\n","    #print(longword[-1])\n","\n","    #print(\"end of the try\\n\")\n","\n","anewlist_3=[]\n","#print(longwords)\n","#print(createdwords,\"createdwords\")\n","#for a in longwords:\n","#  print(a)\n","longwordslist=[]\n","for sentences in longwords:\n","  for words in sentences:\n","    longwordslist.append(words)\n","#print(longwordslist,\"ssssssssss\")\n","for sentences in anewlist:\n","  tokenized_sentences=word_tokenize(sentences)\n","  #print(tokenized_sentences)\n","  anewsentenceforlist=\"\"\n","  for i in range(len(tokenized_sentences)):\n","    anewwordforlist=\"\"\n","    for j in range(len(longwords)):\n","      if tokenized_sentences[i] in longwords[j]:\n","              #print(tokenized_sentences[i])\n","              if tokenized_sentences[i] == longwords[j][0] and tokenized_sentences[i+lenlongwords[j]-1] == longwords[j][-1] and tokenized_sentences[i+lenlongwords[j]] == \"(\" and tokenized_sentences[i+lenlongwords[j]+1] == str(createdwords[j]) and tokenized_sentences[i+lenlongwords[j]+2] == \")\":\n","                   # print(\"HEYYYYYYYY\")\n","                   # print(tokenized_sentences[i])\n","                   # print(tokenized_sentences)\n","                    anewwordforlist+=\" \"+(createdwords[j])\n","\n","              elif tokenized_sentences[i] == longwords[j][0] and tokenized_sentences[i+lenlongwords[j]-1] == longwords[j][-1] :\n","                    #print(\"double hey\")\n","                    #print(tokenized_sentence[i])\n","                    #print(tokenized_sentences)\n","                    anewwordforlist+=\" \"+(createdwords[j])\n","              \n","                  \n","    if tokenized_sentences[i] not in longwordslist:\n","      if  tokenized_sentences[i] == \"(\" and  tokenized_sentences[i+1] in createdwords and tokenized_sentences[i+2] == \")\":\n","                    anewwordforlist+=\"\"\n","      elif tokenized_sentences[i] == \")\" and  tokenized_sentences[i-1] in createdwords and tokenized_sentences[i-2] == \"(\":\n","                    anewwordforlist+=\"\"\n","      elif tokenized_sentences[i] in createdwords and tokenized_sentences[i-1] == \"(\" and  tokenized_sentences[i+1] == \")\":\n","                    anewwordforlist+=\"\"\n","\n","      else:\n","        anewwordforlist+=\" \"+(tokenized_sentences[i])\n","    \n","\n","\n","\n","    anewsentenceforlist+=(anewwordforlist)\n","  anewlist_3.append(anewsentenceforlist)\n","      \n","\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"LNGGYy6QvAoJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866449214,"user_tz":-60,"elapsed":20,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"45daf5ae-2116-48b4-b6b6-cb02a93d849f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' Named Entity Recognition is advnlp week 5',\n"," ' Previously distributional semantics was covered .',\n"," ' Previously bootstrapping semantics from context was covered .',\n"," ' Previously probabilistic language models was covered .',\n"," ' Previously n - gram modelling , perplexity and generalization was covered .',\n"," ' Previously neural language models was covered .',\n"," ' Previously word - based and character - based was covered .',\n"," ' Previously word embeddings was covered .',\n"," ' Previously dimensionality reduction , neural language models , word2vec , glov was covered .',\n"," ' Week 5 overview is part 1 .',\n"," ' Week 5 overview is named entity recognition .',\n"," ' Week 5 overview is what and why .',\n"," ' Week 5 overview is challenges .',\n"," ' Week 5 overview is ne types , labelling , evaluation and features',\n"," ' NLP Tasks are natural language generation .',\n"," ' NLP Tasks are chatbots , automatic content creation .',\n"," ' NLP Tasks is summarisation .',\n"," ' They reduce to key points ( abstractive ) , extract key points ( extractive ) .',\n"," ' NLP Tasks are question answering .',\n"," ' Natural language q & a given a text passage .',\n"," ' NLP Tasks are machine translation .',\n"," ' NLP Tasks are text , speech or any “ language ” translation ( e.g . q & a ) .',\n"," ' NLP Tasks are text classification ( sequence labelling ) .',\n"," ' NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .',\n"," ' Sentiment analysis , intent extraction .',\n"," ' NLP Tasks are language modelling and similarity .',\n"," ' NLP Tasks can be applied to most tasks .',\n"," ' NLP Tasks .',\n"," ' Named Entity Recognition is assigning labels to a sequence of variables .',\n"," ' Named Entity Recognition is the detection and classification of named entities in a text .',\n"," ' A named entity is anything which can be referred to with a proper name e.g . , “ Boris Johnson ” , “ Pizza Hut ” , “ Brighton ” , but may also include dates , times , prices and more .',\n"," ' Named Entity Recognition is often multi - word phrases .',\n"," ' Named Entity Recognition is semantic structured prediction . . .',\n"," ' NER is the basis for downstream NLP tasks .',\n"," ' Why Named Entity Recognition ? It is sentiment or intent regarding entities .',\n"," ' Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .',\n"," ' Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .',\n"," ' Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .',\n"," ' Why Named Entity Recognition ? It is google / bing infobox .',\n"," ' Why Named Entity Recognition ? It is competitive / product intelligence . . .',\n"," ' Manchester United striker Wayne Rooney has agreed a new five - and - a - half year contract worth up to £ 300,000 a week ..',\n"," ' Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .',\n"," ' Other benchmarks include more types , e.g . OntoNotes v5.0 includes 18 types .',\n"," ' Types of Named Entity is temporal expressions and numerical expressions are often included .',\n"," ' Some approaches aim to discover any entity regardless of type .',\n"," ' Which entity type set might be most useful ? Types of Named EntityDifficulties : .',\n"," ' Types of Named Entity is two types of ambiguity : boundary and type .',\n"," ' Types of Named Entity is boundary detection ( e.g . the new york times ) – a harder problem than pos tagging .',\n"," ' Types of Named Entity is two types of type ambiguity : entity - noun , entity - entity .',\n"," ' Types of Named Entity is variation , even with reliable text sources ( e.g . united , utd , utd .',\n"," ' Types of Named Entity )',\n"," ' Sequence Labelling – IOB encoding is sequence labelling – iob encodingi \\uf0e0 inside a chunk .',\n"," ' Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk .',\n"," ' B \\uf0e0 beginning a chunkSequence Labelling – IOB encodingI \\uf0e0 inside a chunk .',\n"," ' Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk .',\n"," ' B \\uf0e0 beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .',\n"," ' Find the correct spans of text that constitute an entity .',\n"," ' Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .',\n"," ' For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .',\n"," ' Sequence Labelling – IOB encoding is also known as bio encoding .',\n"," ' Sequence Labelling – IOB encoding .',\n"," ' Evaluation evaluation',\n"," ' Features commonly used in NER which rules or features might be useful in identifying these entity types ? .',\n"," ' Features commonly used in NERWhat might the choice of features depend on ?',\n"," ' Humans annotate training documents .',\n"," ' Typical Supervised Approach is iob encoding .',\n"," ' Feature extraction performed if necessary .',\n"," ' Classifier ( e.g . , HMM , SVM , MEMM , CRF , LSTM or a combination ) trained .',\n"," ' Evaluation carried out on held out test data typically using precision , recall and the F - measure ( F1 ) .',\n"," ' For Typical Supervised Approach , paper is published ( possibly )',\n"," ' Classification is sequence labelling task – .',\n"," ' We want to assign the most likely sequence of labels given the observed tokens .',\n"," ' Classification is not the most likely label for each token given all of the other tokens .',\n"," ' So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt',\n"," ' Named Entity Recognition Part 2 is advnlp week 5',\n"," ' NER Approaches is approximate chronology of ner approaches .',\n"," ' NER Approaches is rule - based .',\n"," ' NER Approaches is generative ( e.g . hmm ) .',\n"," ' NER Approaches is discriminative ( e.g . memm , crf ) .',\n"," ' They rnn - based , usually lstm .',\n"," ' NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .',\n"," ' NER Approaches is hybrid .',\n"," ' Rule-based is heuristics , entity lookup lists ( gazeteers ) .',\n"," ' Rule-based is varying degrees of inclusion of supervised ml .',\n"," ' Bootstrapping using initial set of seeds .',\n"," ' Rule-based is still used in non - academic scenarios',\n"," ' Generative models are model joint probability distributions from training data .',\n"," ' Generative models can be used to generate new data from these distributions .',\n"," ' Use Bayes theorem to obtain a conditional probability to label unseen data .',\n"," ' Examples of generative models are Naïve Bayes and the HMM .',\n"," ' HMM is model sequences of observed variables ( words ) and not - directly - observed hidden variables ( ne tags ) .',\n"," ' HMM is generated from a labelled dataset ( for ner , words and associated ne tags ) .',\n"," ' It consists of two probability distributions .',\n"," ' HMM is tag type to tag type ( transition probabilities ) .',\n"," ' HMM is words for each tag type ( emission probabilities ) . . . .',\n"," ' HMM is two simplifying assumptions : .',\n"," ' For HMM , bigram – only the previous tag type is required to predict the current tag type .',\n"," ' independence – words are the only ( observable ) feature required to predict tag type .',\n"," ' Use simplified Bayes theorem to find the most likely transition for each word .',\n"," ' Tag sequences are output for each word wi using .',\n"," ' HMM is max ( max ( p ( ti-1|ti-2 ) * p ( ti|ti-1 ) )',\n"," ' The Viterbi recursive algorithm is used to apply this to decode each sentence by populating a matrix of results word by word ( cols = words , rows = tags ) .',\n"," ' HMM this matrix can be referred back to to retrieve previous transition probabilities . . . . . .',\n"," ' HMM is max ( max ( p ( ti-1|ti-2 ) * p ( ti|ti-1 ) )',\n"," ' They arise from the two simplifying assumptions .',\n"," ' Bigram limits model history .',\n"," ' Feature independence limits model richness .',\n"," ' HMM is difficult to add additional features .',\n"," ' HMM is . .',\n"," ' They simplify the problem by discriminating between classes ( ne tag types ) rather than modelling every data point .',\n"," ' Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .',\n"," ' Examples of discriminative models are the Maximum Entropy ( MEMM ) and the CRF .',\n"," ' Discriminative models is . .',\n"," ' CRF is lafferty et al .',\n"," ' CRF is ( 2001 ) .',\n"," ' CRF is based on log - linear models like regression .',\n"," ' For CRF , any combination of features is allowed .',\n"," ' Include features that help with unknown words ( e.g . word shape ) .',\n"," ' CRF is one matrix of inputs ( sentences and words ) .',\n"," ' CRF is one matrix of outputs ( ne type labels ) .',\n"," ' CRF input and output matrix linked by weighted set of rules .',\n"," ' For CRF , a large set of predictive “ feature rules ” are generated from training data ( e.g . presence of wi in a gazetteer ) .',\n"," ' Rules have access to all words , but only the previous label ( linear chain CRF ) – this makes decoding easier .',\n"," ' Each rule results in a score .',\n"," ' When applied to training data for each step ( word ) , rule scores are aggregated for each rule and weighted , then summed to give the score for that step ( i.e . a weight exists for each global feature ) .',\n"," ' For CRF , during training , weights are updated using log - likelihood and sgd .',\n"," ' New sentences are labelled using Viterbi ( as this is a linear chain ) in the same way as HMM , except a sum of weighted rule aggregations if used to populated each cell in the Viterbi matrix ( rather than Bayes rule as in HMM ) ..',\n"," ' Implementations of CRF is implementations of crf .',\n"," ' Many good implementations available .',\n"," ' They avoid reinventing the wheel !',\n"," ' CRF performs well but is subject to drawbacks .',\n"," ' Drawbacks of using CRFs very slow to train .',\n"," ' Drawbacks of using CRFs are lafferty et al.2001 report ( on the same dataset ) : .',\n"," ' Drawbacks of using CRFs memm+ trained to convergence from uniform distribution in 100 iterations .',\n"," ' CRF did not converge after 2000 iterations from the uniform distribution .',\n"," ' using the MEMM+ parameters to initialise the CRF , it converged in 1000 iterations .',\n"," ' Features need to be hand - crafted',\n"," ' Bidirectional - LSTM is most popular ( non - transformer - based ) .',\n"," ' For Neural Models , vanilla rnn and gru have also been used .',\n"," ' NNs allow word , char or other embeddings to be used ( or generated ) .',\n"," ' Ma and Hovy ( 2016 ) is a good base Bi - LSTM architecture ( CoNLL English SotA in 2016 and basis for Wang et al .',\n"," ' Neural Models are sota in 2021 ) .',\n"," ' Ma and Hovy ( 2016 ) is also our seminar paper for this week .',\n"," ' Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .',\n"," ' Achieved F1 91.21 which was SotA in 2016 .',\n"," ' It brings together concepts learned thus far .',\n"," ' End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .',\n"," ' For Ma and Hovy ( 2016 ) , a char representation for each word is generated from a cnn ( 30 filters of width 3 ) based on char embeddings .',\n"," ' For Ma and Hovy ( 2016 ) , char rep is concatenated with glove word embedding .',\n"," ' For Ma and Hovy ( 2016 ) , bi - directional lstm is achieved by concatenating left - to - right and right - to - left lstm hidden states ( 200 units ) .',\n"," ' For Ma and Hovy ( 2016 ) , crf is used as output layer ( rather than softmax ) to decode label sequences .',\n"," ' Ma and Hovy ( 2016 ) dropout ( 0.5 ) used in cnn and lstm to prevent overfit .',\n"," ' It bioes tagging scheme ( e for ending , s for single element ) .',\n"," ' Ma and Hovy ( 2016 ) is convergence at around 50 epochs ( with early stopping ) .',\n"," ' Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .',\n"," ' CRF shows tags from PoS task , NER task uses same config ( except for initial LR )',\n"," ' Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .',\n"," ' Wang et al . ( 2021 ) is automatic selection of embeddings for tasks using neural architecture search .',\n"," ' It generates better word representations .',\n"," ' It reduces human effort of architecture design .',\n"," ' Wang et al . ( 2021 ) is different combinations of embeddings are assessed by task accuracy .',\n"," ' Wang et al . ( 2021 ) paper focusses on ace , but is sota in 6 tasks , including ner .',\n"," ' Achieved F1 94.6 on English CoNLL-2003 using ACE with embedding fine - tuning .',\n"," ' For Wang et al . ( 2021 ) , bilstm - crf model based on ma & hovy is used for sequence - structured outputs .',\n"," ' For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .',\n"," ' For Wang et al . ( 2021 ) , task - specific embedding fine - tuning is done before ace part .',\n"," ' ACE does F1 0.6 better than simply concatenating ALL embedding types ! .',\n"," ' The sets of embeddings used for tasks were quite variable .',\n"," ' The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .',\n"," ' For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .',\n"," ' Wang et al . ( 2021 ) .',\n"," ' Large pre - trained language models have achieved success in many NLP tasks , including NER .',\n"," ' Transformer-based LMs ( typically ) use a deep transformer architecture with many layers / parameters .',\n"," ' Transformer-based LMs are ( typically ) model long - range dependencies using attention mechanism .',\n"," ' Transformer-based LMs ( typically ) require task - based fine - tuning .',\n"," ' For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .',\n"," ' Transformer-based LMs are notable systems : .',\n"," ' Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .',\n"," ' Transformer-based LMs are gpt-2 ( radford et al . , 2019 ) uni - directional transformer - based .',\n"," ' Transformer-based LMs are bert ( devlin et al . , 2019 ) bi - directional transformer - based mlm and nsp .',\n"," ' Transformer-based LMs are optimsations : .',\n"," ' RoBERTa ( Liu et al . , 2019 ) improved BERT performance through stronger masking strategies .',\n"," ' Transformer-based LMs distilbert ( sanh et al . , 2019 ) smaller and faster with 95 % of the original bert perform .',\n"," ' The are many other BERT variants .',\n"," ' Transformer-based LMs are discussed in more detail in weeks 7 and 8 . . . .',\n"," ' Week 5 lecture summary is part 1 .',\n"," ' Week 5 lecture summary is named entity recognition .',\n"," ' Week 5 lecture summary is what and why .',\n"," ' Week 5 lecture summary is ne types , labelling , evaluation and features',\n"," ' Before the seminar please read ma and hovy ( 2016 )',\n"," ' Next time getting data ! will be covered .',\n"," ' Next time for supervised training will be covered .',\n"," ' Next time existing sets will be covered .',\n"," ' Next time more efficient labelling will be covered .',\n"," ' Next time semi - supervised approaches will be covered .',\n"," ' Next time distant supervision will be covered .',\n"," ' Next time bootstrapping will be covered .',\n"," ' Next time unsupervised will be covered .',\n"," ' Next time .']"]},"metadata":{},"execution_count":41}],"source":["anewlist_3"]},{"cell_type":"markdown","metadata":{"id":"F2RyTdFSvqdv"},"source":["# LDA"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"VTk_2yxVvAsC","executionInfo":{"status":"ok","timestamp":1661866450403,"user_tz":-60,"elapsed":1207,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6924af3-569f-446c-8317-c77612930345"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n","  from collections import Iterable\n"]}],"source":["import re\n","import numpy as np\n","import pandas as pd\n","from pprint import pprint\n","\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","\n","import pyLDAvis\n","import pyLDAvis.gensim_models\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Enable logging for gensim - optional\n","import logging\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"SAQaV6NIvsab","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866450403,"user_tz":-60,"elapsed":21,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"5031ac0d-6676-467a-aaf4-1553393b7173"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import nltk; nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop_words = stopwords.words('english')\n","stop_words.extend(['from'])"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"n1z2aj9nv1Dc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866450404,"user_tz":-60,"elapsed":19,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"4569b04f-dae0-4c9e-8f92-6cc780f8f1fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["[['named', 'entity', 'recognition', 'is', 'advnlp', 'week'], ['previously', 'distributional', 'semantics', 'was', 'covered'], ['previously', 'bootstrapping', 'semantics', 'from', 'context', 'was', 'covered'], ['previously', 'probabilistic', 'language', 'models', 'was', 'covered'], ['previously', 'gram', 'modelling', 'perplexity', 'and', 'generalization', 'was', 'covered'], ['previously', 'neural', 'language', 'models', 'was', 'covered'], ['previously', 'word', 'based', 'and', 'character', 'based', 'was', 'covered'], ['previously', 'word', 'embeddings', 'was', 'covered'], ['previously', 'dimensionality', 'reduction', 'neural', 'language', 'models', 'word', 'vec', 'glov', 'was', 'covered'], ['week', 'overview', 'is', 'part'], ['week', 'overview', 'is', 'named', 'entity', 'recognition'], ['week', 'overview', 'is', 'what', 'and', 'why'], ['week', 'overview', 'is', 'challenges'], ['week', 'overview', 'is', 'ne', 'types', 'labelling', 'evaluation', 'and', 'features'], ['nlp', 'tasks', 'are', 'natural', 'language', 'generation'], ['nlp', 'tasks', 'are', 'chatbots', 'automatic', 'content', 'creation'], ['nlp', 'tasks', 'is', 'summarisation'], ['they', 'reduce', 'to', 'key', 'points', 'abstractive', 'extract', 'key', 'points', 'extractive'], ['nlp', 'tasks', 'are', 'question', 'answering'], ['natural', 'language', 'given', 'text', 'passage'], ['nlp', 'tasks', 'are', 'machine', 'translation'], ['nlp', 'tasks', 'are', 'text', 'speech', 'or', 'any', 'language', 'translation'], ['nlp', 'tasks', 'are', 'text', 'classification', 'sequence', 'labelling'], ['nlp', 'tasks', 'are', 'part', 'of', 'speech', 'synactic', 'named', 'entity', 'recognition', 'semantic', 'and', 'event', 'extraction'], ['sentiment', 'analysis', 'intent', 'extraction'], ['nlp', 'tasks', 'are', 'language', 'modelling', 'and', 'similarity'], ['nlp', 'tasks', 'can', 'be', 'applied', 'to', 'most', 'tasks'], ['nlp', 'tasks'], ['named', 'entity', 'recognition', 'is', 'assigning', 'labels', 'to', 'sequence', 'of', 'variables'], ['named', 'entity', 'recognition', 'is', 'the', 'detection', 'and', 'classification', 'of', 'named', 'entities', 'in', 'text'], ['named', 'entity', 'is', 'anything', 'which', 'can', 'be', 'referred', 'to', 'with', 'proper', 'name', 'boris', 'johnson', 'pizza', 'hut', 'brighton', 'but', 'may', 'also', 'include', 'dates', 'times', 'prices', 'and', 'more'], ['named', 'entity', 'recognition', 'is', 'often', 'multi', 'word', 'phrases'], ['named', 'entity', 'recognition', 'is', 'semantic', 'structured', 'prediction'], ['ner', 'is', 'the', 'basis', 'for', 'downstream', 'nlp', 'tasks'], ['why', 'named', 'entity', 'recognition', 'it', 'is', 'sentiment', 'or', 'intent', 'regarding', 'entities'], ['why', 'named', 'entity', 'recognition', 'it', 'is', 'the', 'relation', 'between', 'entities', 'in', 'fact', 'relation', 'extraction'], ['why', 'named', 'entity', 'recognition', 'it', 'is', 'entity', 'linking', 'co', 'ref', 'resolution', 'and', 'kbp'], ['why', 'named', 'entity', 'recognition', 'it', 'is', 'entity', 'informed', 'search', 'gkg', 'and', 'question', 'answering', 'regarding', 'an', 'entity'], ['why', 'named', 'entity', 'recognition', 'it', 'is', 'google', 'bing', 'infobox'], ['why', 'named', 'entity', 'recognition', 'it', 'is', 'competitive', 'product', 'intelligence'], ['manchester', 'united', 'striker', 'wayne', 'rooney', 'has', 'agreed', 'new', 'five', 'and', 'half', 'year', 'contract', 'worth', 'up', 'to', 'week'], ['types', 'of', 'named', 'entitythe', 'most', 'popular', 'ner', 'benchmark', 'conll', 'includes', 'only', 'these', 'entity', 'types'], ['other', 'benchmarks', 'include', 'more', 'types', 'ontonotes', 'includes', 'types'], ['types', 'of', 'named', 'entity', 'is', 'temporal', 'expressions', 'and', 'numerical', 'expressions', 'are', 'often', 'included'], ['some', 'approaches', 'aim', 'to', 'discover', 'any', 'entity', 'regardless', 'of', 'type'], ['which', 'entity', 'type', 'set', 'might', 'be', 'most', 'useful', 'types', 'of', 'named'], ['types', 'of', 'named', 'entity', 'is', 'two', 'types', 'of', 'ambiguity', 'boundary', 'and', 'type'], ['types', 'of', 'named', 'entity', 'is', 'boundary', 'detection', 'the', 'new', 'york', 'times', 'harder', 'problem', 'than', 'pos', 'tagging'], ['types', 'of', 'named', 'entity', 'is', 'two', 'types', 'of', 'type', 'ambiguity', 'entity', 'noun', 'entity', 'entity'], ['types', 'of', 'named', 'entity', 'is', 'variation', 'even', 'with', 'reliable', 'text', 'sources', 'united', 'utd', 'utd'], ['types', 'of', 'named', 'entity'], ['sequence', 'labelling', 'iob', 'encoding', 'is', 'sequence', 'labelling', 'iob', 'encodingi', 'inside', 'chunk'], ['sequence', 'labelling', 'iob', 'encoding', 'is', 'outside', 'chunk'], ['beginning', 'chunksequence', 'labelling', 'iob', 'encodingi', 'inside', 'chunk'], ['sequence', 'labelling', 'iob', 'encoding', 'is', 'outside', 'chunk'], ['beginning', 'chunkturn', 'span', 'identification', 'into', 'sequence', 'labelling', 'problem', 'using', 'iob', 'encoding', 'tag', 'per', 'token'], ['find', 'the', 'correct', 'spans', 'of', 'text', 'that', 'constitute', 'an', 'entity'], ['sequence', 'labelling', 'iob', 'encoding', 'typically', 'entities', 'should', 'be', 'identified', 'with', 'the', 'correct', 'type', 'and', 'exact', 'position'], ['for', 'sequence', 'labelling', 'iob', 'encoding', 'sometimes', 'multiple', 'scores', 'are', 'included', 'including', 'partial', 'overlaps'], ['sequence', 'labelling', 'iob', 'encoding', 'is', 'also', 'known', 'as', 'bio', 'encoding'], ['sequence', 'labelling', 'iob', 'encoding'], ['evaluation', 'evaluation'], ['features', 'commonly', 'used', 'in', 'ner', 'which', 'rules', 'or', 'features', 'might', 'be', 'useful', 'in', 'identifying', 'these', 'entity', 'types'], ['features', 'commonly', 'used', 'in', 'nerwhat', 'might', 'the', 'choice', 'of', 'features', 'depend', 'on'], ['humans', 'annotate', 'training', 'documents'], ['typical', 'supervised', 'approach', 'is', 'iob', 'encoding'], ['feature', 'extraction', 'performed', 'if', 'necessary'], ['classifier', 'hmm', 'svm', 'memm', 'crf', 'lstm', 'or', 'combination', 'trained'], ['evaluation', 'carried', 'out', 'on', 'held', 'out', 'test', 'data', 'typically', 'using', 'precision', 'recall', 'and', 'the', 'measure'], ['for', 'typical', 'supervised', 'approach', 'paper', 'is', 'published', 'possibly'], ['classification', 'is', 'sequence', 'labelling', 'task'], ['we', 'want', 'to', 'assign', 'the', 'most', 'likely', 'sequence', 'of', 'labels', 'given', 'the', 'observed', 'tokens'], ['classification', 'is', 'not', 'the', 'most', 'likely', 'label', 'for', 'each', 'token', 'given', 'all', 'of', 'the', 'other', 'tokens'], ['so', 'this', 'might', 'rule', 'out', 'simple', 'classifiers', 'such', 'as', 'naive', 'bayes', 'and', 'logistic', 'regression', 'maxent'], ['named', 'entity', 'recognition', 'part', 'is', 'advnlp', 'week'], ['ner', 'approaches', 'is', 'approximate', 'chronology', 'of', 'ner', 'approaches'], ['ner', 'approaches', 'is', 'rule', 'based'], ['ner', 'approaches', 'is', 'generative', 'hmm'], ['ner', 'approaches', 'is', 'discriminative', 'memm', 'crf'], ['they', 'rnn', 'based', 'usually', 'lstm'], ['ner', 'approaches', 'is', 'usually', 'transformer', 'attention', 'based', 'large', 'language', 'models', 'fine', 'tuned', 'bert'], ['ner', 'approaches', 'is', 'hybrid'], ['rule', 'based', 'is', 'heuristics', 'entity', 'lookup', 'lists', 'gazeteers'], ['rule', 'based', 'is', 'varying', 'degrees', 'of', 'inclusion', 'of', 'supervised', 'ml'], ['bootstrapping', 'using', 'initial', 'set', 'of', 'seeds'], ['rule', 'based', 'is', 'still', 'used', 'in', 'non', 'academic', 'scenarios'], ['generative', 'models', 'are', 'model', 'joint', 'probability', 'distributions', 'from', 'training', 'data'], ['generative', 'models', 'can', 'be', 'used', 'to', 'generate', 'new', 'data', 'from', 'these', 'distributions'], ['use', 'bayes', 'theorem', 'to', 'obtain', 'conditional', 'probability', 'to', 'label', 'unseen', 'data'], ['examples', 'of', 'generative', 'models', 'are', 'naive', 'bayes', 'and', 'the', 'hmm'], ['hmm', 'is', 'model', 'sequences', 'of', 'observed', 'variables', 'words', 'and', 'not', 'directly', 'observed', 'hidden', 'variables', 'ne', 'tags'], ['hmm', 'is', 'generated', 'from', 'labelled', 'dataset', 'for', 'ner', 'words', 'and', 'associated', 'ne', 'tags'], ['it', 'consists', 'of', 'two', 'probability', 'distributions'], ['hmm', 'is', 'tag', 'type', 'to', 'tag', 'type', 'transition', 'probabilities'], ['hmm', 'is', 'words', 'for', 'each', 'tag', 'type', 'emission', 'probabilities'], ['hmm', 'is', 'two', 'simplifying', 'assumptions'], ['for', 'hmm', 'bigram', 'only', 'the', 'previous', 'tag', 'type', 'is', 'required', 'to', 'predict', 'the', 'current', 'tag', 'type'], ['independence', 'words', 'are', 'the', 'only', 'observable', 'feature', 'required', 'to', 'predict', 'tag', 'type'], ['use', 'simplified', 'bayes', 'theorem', 'to', 'find', 'the', 'most', 'likely', 'transition', 'for', 'each', 'word'], ['tag', 'sequences', 'are', 'output', 'for', 'each', 'word', 'wi', 'using'], ['hmm', 'is', 'max', 'max', 'ti', 'ti', 'ti', 'ti'], ['the', 'viterbi', 'recursive', 'algorithm', 'is', 'used', 'to', 'apply', 'this', 'to', 'decode', 'each', 'sentence', 'by', 'populating', 'matrix', 'of', 'results', 'word', 'by', 'word', 'cols', 'words', 'rows', 'tags'], ['hmm', 'this', 'matrix', 'can', 'be', 'referred', 'back', 'to', 'to', 'retrieve', 'previous', 'transition', 'probabilities'], ['hmm', 'is', 'max', 'max', 'ti', 'ti', 'ti', 'ti'], ['they', 'arise', 'from', 'the', 'two', 'simplifying', 'assumptions'], ['bigram', 'limits', 'model', 'history'], ['feature', 'independence', 'limits', 'model', 'richness'], ['hmm', 'is', 'difficult', 'to', 'add', 'additional', 'features'], ['hmm', 'is'], ['they', 'simplify', 'the', 'problem', 'by', 'discriminating', 'between', 'classes', 'ne', 'tag', 'types', 'rather', 'than', 'modelling', 'every', 'data', 'point'], ['leverage', 'multiple', 'potentially', 'interdependent', 'features', 'word', 'shape', 'presence', 'in', 'gazeteer', 'pos', 'word', 'embeddings', 'which', 'can', 'improve', 'prediction', 'and', 'help', 'with', 'sparsity'], ['examples', 'of', 'discriminative', 'models', 'are', 'the', 'maximum', 'entropy', 'memm', 'and', 'the', 'crf'], ['discriminative', 'models', 'is'], ['crf', 'is', 'lafferty', 'et', 'al'], ['crf', 'is'], ['crf', 'is', 'based', 'on', 'log', 'linear', 'models', 'like', 'regression'], ['for', 'crf', 'any', 'combination', 'of', 'features', 'is', 'allowed'], ['include', 'features', 'that', 'help', 'with', 'unknown', 'words', 'word', 'shape'], ['crf', 'is', 'one', 'matrix', 'of', 'inputs', 'sentences', 'and', 'words'], ['crf', 'is', 'one', 'matrix', 'of', 'outputs', 'ne', 'type', 'labels'], ['crf', 'input', 'and', 'output', 'matrix', 'linked', 'by', 'weighted', 'set', 'of', 'rules'], ['for', 'crf', 'large', 'set', 'of', 'predictive', 'feature', 'rules', 'are', 'generated', 'from', 'training', 'data', 'presence', 'of', 'wi', 'in', 'gazetteer'], ['rules', 'have', 'access', 'to', 'all', 'words', 'but', 'only', 'the', 'previous', 'label', 'linear', 'chain', 'crf', 'this', 'makes', 'decoding', 'easier'], ['each', 'rule', 'results', 'in', 'score'], ['when', 'applied', 'to', 'training', 'data', 'for', 'each', 'step', 'word', 'rule', 'scores', 'are', 'aggregated', 'for', 'each', 'rule', 'and', 'weighted', 'then', 'summed', 'to', 'give', 'the', 'score', 'for', 'that', 'step', 'weight', 'exists', 'for', 'each', 'global', 'feature'], ['for', 'crf', 'during', 'training', 'weights', 'are', 'updated', 'using', 'log', 'likelihood', 'and', 'sgd'], ['new', 'sentences', 'are', 'labelled', 'using', 'viterbi', 'as', 'this', 'is', 'linear', 'chain', 'in', 'the', 'same', 'way', 'as', 'hmm', 'except', 'sum', 'of', 'weighted', 'rule', 'aggregations', 'if', 'used', 'to', 'populated', 'each', 'cell', 'in', 'the', 'viterbi', 'matrix', 'rather', 'than', 'bayes', 'rule', 'as', 'in', 'hmm'], ['implementations', 'of', 'crf', 'is', 'implementations', 'of', 'crf'], ['many', 'good', 'implementations', 'available'], ['they', 'avoid', 'reinventing', 'the', 'wheel'], ['crf', 'performs', 'well', 'but', 'is', 'subject', 'to', 'drawbacks'], ['drawbacks', 'of', 'using', 'crfs', 'very', 'slow', 'to', 'train'], ['drawbacks', 'of', 'using', 'crfs', 'are', 'lafferty', 'et', 'al', 'report', 'on', 'the', 'same', 'dataset'], ['drawbacks', 'of', 'using', 'crfs', 'memm', 'trained', 'to', 'convergence', 'from', 'uniform', 'distribution', 'in', 'iterations'], ['crf', 'did', 'not', 'converge', 'after', 'iterations', 'from', 'the', 'uniform', 'distribution'], ['using', 'the', 'memm', 'parameters', 'to', 'initialise', 'the', 'crf', 'it', 'converged', 'in', 'iterations'], ['features', 'need', 'to', 'be', 'hand', 'crafted'], ['bidirectional', 'lstm', 'is', 'most', 'popular', 'non', 'transformer', 'based'], ['for', 'neural', 'models', 'vanilla', 'rnn', 'and', 'gru', 'have', 'also', 'been', 'used'], ['nns', 'allow', 'word', 'char', 'or', 'other', 'embeddings', 'to', 'be', 'used', 'or', 'generated'], ['ma', 'and', 'hovy', 'is', 'good', 'base', 'bi', 'lstm', 'architecture', 'conll', 'english', 'sota', 'in', 'and', 'basis', 'for', 'wang', 'et', 'al'], ['neural', 'models', 'are', 'sota', 'in'], ['ma', 'and', 'hovy', 'is', 'also', 'our', 'seminar', 'paper', 'for', 'this', 'week'], ['ma', 'and', 'hovy', 'is', 'end', 'to', 'end', 'sequence', 'labelling', 'via', 'bi', 'directional', 'lstm', 'cnns', 'crf'], ['achieved', 'which', 'was', 'sota', 'in'], ['it', 'brings', 'together', 'concepts', 'learned', 'thus', 'far'], ['end', 'to', 'end', 'no', 'external', 'data', 'apart', 'from', 'word', 'embeddings', 'this', 'is', 'big', 'deal', 'as', 'previous', 'systems', 'were', 'feature', 'engineered'], ['for', 'ma', 'and', 'hovy', 'char', 'representation', 'for', 'each', 'word', 'is', 'generated', 'from', 'cnn', 'filters', 'of', 'width', 'based', 'on', 'char', 'embeddings'], ['for', 'ma', 'and', 'hovy', 'char', 'rep', 'is', 'concatenated', 'with', 'glove', 'word', 'embedding'], ['for', 'ma', 'and', 'hovy', 'bi', 'directional', 'lstm', 'is', 'achieved', 'by', 'concatenating', 'left', 'to', 'right', 'and', 'right', 'to', 'left', 'lstm', 'hidden', 'states', 'units'], ['for', 'ma', 'and', 'hovy', 'crf', 'is', 'used', 'as', 'output', 'layer', 'rather', 'than', 'softmax', 'to', 'decode', 'label', 'sequences'], ['ma', 'and', 'hovy', 'dropout', 'used', 'in', 'cnn', 'and', 'lstm', 'to', 'prevent', 'overfit'], ['it', 'bioes', 'tagging', 'scheme', 'for', 'ending', 'for', 'single', 'element'], ['ma', 'and', 'hovy', 'is', 'convergence', 'at', 'around', 'epochs', 'with', 'early', 'stopping'], ['word', 'embeddings', 'are', 'fine', 'tuned', 'during', 'diagrams', 'from', 'paper'], ['crf', 'shows', 'tags', 'from', 'pos', 'task', 'ner', 'task', 'uses', 'same', 'config', 'except', 'for', 'initial', 'lr'], ['wang', 'et', 'al', 'is', 'automated', 'concatenation', 'of', 'embeddings', 'for', 'structured', 'prediction'], ['wang', 'et', 'al', 'is', 'automatic', 'selection', 'of', 'embeddings', 'for', 'tasks', 'using', 'neural', 'architecture', 'search'], ['it', 'generates', 'better', 'word', 'representations'], ['it', 'reduces', 'human', 'effort', 'of', 'architecture', 'design'], ['wang', 'et', 'al', 'is', 'different', 'combinations', 'of', 'embeddings', 'are', 'assessed', 'by', 'task', 'accuracy'], ['wang', 'et', 'al', 'paper', 'focusses', 'on', 'ace', 'but', 'is', 'sota', 'in', 'tasks', 'including', 'ner'], ['achieved', 'on', 'english', 'conll', 'using', 'ace', 'with', 'embedding', 'fine', 'tuning'], ['for', 'wang', 'et', 'al', 'bilstm', 'crf', 'model', 'based', 'on', 'ma', 'hovy', 'is', 'used', 'for', 'sequence', 'structured', 'outputs'], ['for', 'wang', 'et', 'al', 'embeddings', 'are', 'selected', 'from', 'combination', 'of', 'contextualised', 'non', 'contextualised', 'and', 'character', 'embeddings'], ['for', 'wang', 'et', 'al', 'task', 'specific', 'embedding', 'fine', 'tuning', 'is', 'done', 'before', 'ace', 'part'], ['ace', 'does', 'better', 'than', 'simply', 'concatenating', 'all', 'embedding', 'types'], ['the', 'sets', 'of', 'embeddings', 'used', 'for', 'tasks', 'were', 'quite', 'variable'], ['the', 'most', 'consistent', 'for', 'semantic', 'sequence', 'tasks', 'inc', 'ner', 'were', 'contextualised', 'embeddings', 'multi', 'lingual', 'flair', 'and', 'elmo', 'and', 'non', 'contextualised', 'fasttext', 'glove'], ['for', 'wang', 'et', 'al', 'character', 'embeddings', 'were', 'only', 'selected', 'of', 'the', 'time', 'contextualised', 'are', 'sufficient'], ['wang', 'et', 'al'], ['large', 'pre', 'trained', 'language', 'models', 'have', 'achieved', 'success', 'in', 'many', 'nlp', 'tasks', 'including', 'ner'], ['transformer', 'based', 'lms', 'typically', 'use', 'deep', 'transformer', 'architecture', 'with', 'many', 'layers', 'parameters'], ['transformer', 'based', 'lms', 'are', 'typically', 'model', 'long', 'range', 'dependencies', 'using', 'attention', 'mechanism'], ['transformer', 'based', 'lms', 'typically', 'require', 'task', 'based', 'fine', 'tuning'], ['for', 'transformer', 'based', 'lms', 'contextualised', 'word', 'representations', 'embeddings', 'are', 'generated', 'using', 'sub', 'word', 'input', 'bpe', 'in', 'the', 'case', 'of', 'bert'], ['transformer', 'based', 'lms', 'are', 'notable', 'systems'], ['transformer', 'based', 'lms', 'are', 'elmo', 'peters', 'et', 'al', 'layer', 'bilstm', 'trained', 'on', 'bidirectional', 'language', 'modelling', 'task'], ['transformer', 'based', 'lms', 'are', 'gpt', 'radford', 'et', 'al', 'uni', 'directional', 'transformer', 'based'], ['transformer', 'based', 'lms', 'are', 'bert', 'devlin', 'et', 'al', 'bi', 'directional', 'transformer', 'based', 'mlm', 'and', 'nsp'], ['transformer', 'based', 'lms', 'are', 'optimsations'], ['roberta', 'liu', 'et', 'al', 'improved', 'bert', 'performance', 'through', 'stronger', 'masking', 'strategies'], ['transformer', 'based', 'lms', 'distilbert', 'sanh', 'et', 'al', 'smaller', 'and', 'faster', 'with', 'of', 'the', 'original', 'bert', 'perform'], ['the', 'are', 'many', 'other', 'bert', 'variants'], ['transformer', 'based', 'lms', 'are', 'discussed', 'in', 'more', 'detail', 'in', 'weeks', 'and'], ['week', 'lecture', 'summary', 'is', 'part'], ['week', 'lecture', 'summary', 'is', 'named', 'entity', 'recognition'], ['week', 'lecture', 'summary', 'is', 'what', 'and', 'why'], ['week', 'lecture', 'summary', 'is', 'ne', 'types', 'labelling', 'evaluation', 'and', 'features'], ['before', 'the', 'seminar', 'please', 'read', 'ma', 'and', 'hovy'], ['next', 'time', 'getting', 'data', 'will', 'be', 'covered'], ['next', 'time', 'for', 'supervised', 'training', 'will', 'be', 'covered'], ['next', 'time', 'existing', 'sets', 'will', 'be', 'covered'], ['next', 'time', 'more', 'efficient', 'labelling', 'will', 'be', 'covered'], ['next', 'time', 'semi', 'supervised', 'approaches', 'will', 'be', 'covered'], ['next', 'time', 'distant', 'supervision', 'will', 'be', 'covered'], ['next', 'time', 'bootstrapping', 'will', 'be', 'covered'], ['next', 'time', 'unsupervised', 'will', 'be', 'covered'], ['next', 'time']]\n"]}],"source":["#tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether with gensim.utils.simple_preprocess()\n","def sent_to_words(sentences):\n","    for sentence in sentences:\n","        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n","\n","data_words = list(sent_to_words(anewlist_3))\n","\n","print(data_words)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"SiINDX3Hv1IU","executionInfo":{"status":"ok","timestamp":1661866450404,"user_tz":-60,"elapsed":12,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#stopwords removal\n","def remove_stopwords(texts):\n","    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n","\n","# Remove Stop Words\n","data_words_nostops = remove_stopwords(data_words)\n","\n"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"kyQlpONwv1Mb","executionInfo":{"status":"ok","timestamp":1661866450405,"user_tz":-60,"elapsed":13,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["#lemmatization keeping only noun, adj, vb, adv\n","def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","    texts_out = []\n","    for sent in texts:\n","        doc = nlp(\" \".join(sent)) \n","        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n","    return texts_out\n"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"UXxesUzVvsec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866451580,"user_tz":-60,"elapsed":1188,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"f8e55150-aca0-4df5-be6d-b86c4e6fc1b6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['name', 'entity', 'recognition', 'advnlp', 'week']]"]},"metadata":{},"execution_count":47}],"source":["data_lemmatized_x= lemmatization(data_words_nostops, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n","data_lemmatized_x[:1]"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"UewobrAsvsh-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866451593,"user_tz":-60,"elapsed":36,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"9d01bc76-9b7c-4846-b5bd-ef7229ae7ac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]]\n"]}],"source":["#Create dictionary and the corpus needed for the Topic Modeling\n","# Dictionary\n","id2word = corpora.Dictionary(data_lemmatized_x)\n","\n","# Corpus\n","texts = data_lemmatized_x\n","\n","# Term Document Frequency\n","corpus = [id2word.doc2bow(text) for text in texts]\n","\n","# Frequencies\n","print(corpus[:1])"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"EgKwau51wDxK","executionInfo":{"status":"ok","timestamp":1661866452908,"user_tz":-60,"elapsed":1347,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["# LDA model\n","lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n","                                           id2word=id2word,\n","                                           num_topics=10, \n","                                           random_state=100,\n","                                           update_every=1,\n","                                           chunksize=100,\n","                                           passes=10,\n","                                           alpha='auto',\n","                                           per_word_topics=True)"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"4TF4sAJUwD1e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866452908,"user_tz":-60,"elapsed":11,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"ace3d431-b08c-4bed-e67b-e4ebdc95fc58"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(0,\n","  '0.098*\"time\" + 0.095*\"cover\" + 0.082*\"next\" + 0.043*\"training\" + '\n","  '0.031*\"simplify\" + 0.022*\"variable\" + 0.021*\"previously\" + 0.019*\"exist\" + '\n","  '0.017*\"word\" + 0.016*\"assumption\"'),\n"," (1,\n","  '0.045*\"task\" + 0.025*\"achieve\" + 0.025*\"many\" + 0.019*\"hovy\" + '\n","  '0.019*\"embed\" + 0.019*\"decode\" + 0.019*\"tuning\" + 0.017*\"apply\" + '\n","  '0.013*\"implementation\" + 0.013*\"ti\"'),\n"," (2,\n","  '0.105*\"embedding\" + 0.076*\"word\" + 0.043*\"contextualise\" + 0.028*\"task\" + '\n","  '0.024*\"previously\" + 0.023*\"cover\" + 0.022*\"evaluation\" + 0.022*\"semantic\" '\n","  '+ 0.018*\"neural\" + 0.018*\"sequence\"'),\n"," (3,\n","  '0.110*\"base\" + 0.085*\"transformer\" + 0.081*\"use\" + 0.062*\"lm\" + '\n","  '0.029*\"model\" + 0.029*\"fine\" + 0.027*\"train\" + 0.027*\"set\" + '\n","  '0.023*\"combination\" + 0.017*\"bert\"'),\n"," (4,\n","  '0.049*\"labelling\" + 0.049*\"approach\" + 0.036*\"feature\" + 0.028*\"model\" + '\n","  '0.027*\"point\" + 0.027*\"supervised\" + 0.025*\"tag\" + 0.023*\"end\" + '\n","  '0.019*\"sequence\" + 0.019*\"independence\"'),\n"," (5,\n","  '0.127*\"entity\" + 0.100*\"type\" + 0.075*\"name\" + 0.039*\"recognition\" + '\n","  '0.028*\"typically\" + 0.024*\"previous\" + 0.017*\"paper\" + 0.017*\"prediction\" + '\n","  '0.014*\"tag\" + 0.013*\"include\"'),\n"," (6,\n","  '0.074*\"use\" + 0.064*\"word\" + 0.049*\"generate\" + 0.043*\"tag\" + '\n","  '0.039*\"matrix\" + 0.037*\"output\" + 0.034*\"label\" + 0.028*\"probability\" + '\n","  '0.021*\"text\" + 0.020*\"language\"'),\n"," (7,\n","  '0.060*\"feature\" + 0.051*\"rule\" + 0.048*\"model\" + 0.047*\"datum\" + '\n","  '0.030*\"distribution\" + 0.022*\"base\" + 0.021*\"weight\" + '\n","  '0.020*\"discriminative\" + 0.020*\"perform\" + 0.018*\"new\"'),\n"," (8,\n","  '0.070*\"sequence\" + 0.062*\"label\" + 0.045*\"word\" + 0.041*\"include\" + '\n","  '0.040*\"base\" + 0.033*\"encode\" + 0.029*\"chunk\" + 0.027*\"task\" + 0.025*\"rule\" '\n","  '+ 0.020*\"use\"'),\n"," (9,\n","  '0.094*\"week\" + 0.061*\"name\" + 0.061*\"entity\" + 0.043*\"recognition\" + '\n","  '0.039*\"part\" + 0.036*\"score\" + 0.033*\"overview\" + 0.033*\"also\" + '\n","  '0.029*\"lecture\" + 0.029*\"summary\"')]\n"]}],"source":["# The topics in LDA model\n","# tThey are printed with the possibilities.\n","pprint(lda_model.print_topics())\n","doc_lda = lda_model[corpus]"]},{"cell_type":"markdown","metadata":{"id":"EtTVVJecvsre"},"source":["# KPE"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"8Sa9K3ErvAvN","executionInfo":{"status":"ok","timestamp":1661866452908,"user_tz":-60,"elapsed":9,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"c95cfe7d-3f5d-4639-c07c-0936efa27b7d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Named Entity Recognition is advnlp week 5 Previously distributional semantics was covered . Previously bootstrapping semantics from context was covered . Previously probabilistic language models was covered . Previously n - gram modelling , perplexity and generalization was covered . Previously neural language models was covered . Previously word - based and character - based was covered . Previously word embeddings was covered . Previously dimensionality reduction , neural language models , word2vec , glov was covered . Week 5 overview is part 1 . Week 5 overview is named entity recognition . Week 5 overview is what and why . Week 5 overview is challenges . Week 5 overview is ne types , labelling , evaluation and features NLP Tasks are natural language generation . NLP Tasks are chatbots , automatic content creation . NLP Tasks is summarisation . They reduce to key points ( abstractive ) , extract key points ( extractive ) . NLP Tasks are question answering . Natural language q & a given a text passage . NLP Tasks are machine translation . NLP Tasks are text , speech or any “ language ” translation ( e.g . q & a ) . NLP Tasks are text classification ( sequence labelling ) . NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction . Sentiment analysis , intent extraction . NLP Tasks are language modelling and similarity . NLP Tasks can be applied to most tasks . NLP Tasks . Named Entity Recognition is assigning labels to a sequence of variables . Named Entity Recognition is the detection and classification of named entities in a text . A named entity is anything which can be referred to with a proper name e.g . , “ Boris Johnson ” , “ Pizza Hut ” , “ Brighton ” , but may also include dates , times , prices and more . Named Entity Recognition is often multi - word phrases . Named Entity Recognition is semantic structured prediction . . . NER is the basis for downstream NLP tasks . Why Named Entity Recognition ? It is sentiment or intent regarding entities . Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction . Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp . Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity . Why Named Entity Recognition ? It is google / bing infobox . Why Named Entity Recognition ? It is competitive / product intelligence . . . Manchester United striker Wayne Rooney has agreed a new five - and - a - half year contract worth up to £ 300,000 a week .. Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types . Other benchmarks include more types , e.g . OntoNotes v5.0 includes 18 types . Types of Named Entity is temporal expressions and numerical expressions are often included . Some approaches aim to discover any entity regardless of type . Which entity type set might be most useful ? Types of Named EntityDifficulties : . Types of Named Entity is two types of ambiguity : boundary and type . Types of Named Entity is boundary detection ( e.g . the new york times ) – a harder problem than pos tagging . Types of Named Entity is two types of type ambiguity : entity - noun , entity - entity . Types of Named Entity is variation , even with reliable text sources ( e.g . united , utd , utd . Types of Named Entity ) Sequence Labelling – IOB encoding is sequence labelling – iob encodingi \\uf0e0 inside a chunk . Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk . B \\uf0e0 beginning a chunkSequence Labelling – IOB encodingI \\uf0e0 inside a chunk . Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk . B \\uf0e0 beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token . Find the correct spans of text that constitute an entity . Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position . For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps . Sequence Labelling – IOB encoding is also known as bio encoding . Sequence Labelling – IOB encoding . Evaluation evaluation Features commonly used in NER which rules or features might be useful in identifying these entity types ? . Features commonly used in NERWhat might the choice of features depend on ? Humans annotate training documents . Typical Supervised Approach is iob encoding . Feature extraction performed if necessary . Classifier ( e.g . , HMM , SVM , MEMM , CRF , LSTM or a combination ) trained . Evaluation carried out on held out test data typically using precision , recall and the F - measure ( F1 ) . For Typical Supervised Approach , paper is published ( possibly ) Classification is sequence labelling task – . We want to assign the most likely sequence of labels given the observed tokens . Classification is not the most likely label for each token given all of the other tokens . So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt Named Entity Recognition Part 2 is advnlp week 5 NER Approaches is approximate chronology of ner approaches . NER Approaches is rule - based . NER Approaches is generative ( e.g . hmm ) . NER Approaches is discriminative ( e.g . memm , crf ) . They rnn - based , usually lstm . NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) . NER Approaches is hybrid . Rule-based is heuristics , entity lookup lists ( gazeteers ) . Rule-based is varying degrees of inclusion of supervised ml . Bootstrapping using initial set of seeds . Rule-based is still used in non - academic scenarios Generative models are model joint probability distributions from training data . Generative models can be used to generate new data from these distributions . Use Bayes theorem to obtain a conditional probability to label unseen data . Examples of generative models are Naïve Bayes and the HMM . HMM is model sequences of observed variables ( words ) and not - directly - observed hidden variables ( ne tags ) . HMM is generated from a labelled dataset ( for ner , words and associated ne tags ) . It consists of two probability distributions . HMM is tag type to tag type ( transition probabilities ) . HMM is words for each tag type ( emission probabilities ) . . . . HMM is two simplifying assumptions : . For HMM , bigram – only the previous tag type is required to predict the current tag type . independence – words are the only ( observable ) feature required to predict tag type . Use simplified Bayes theorem to find the most likely transition for each word . Tag sequences are output for each word wi using . HMM is max ( max ( p ( ti-1|ti-2 ) * p ( ti|ti-1 ) ) The Viterbi recursive algorithm is used to apply this to decode each sentence by populating a matrix of results word by word ( cols = words , rows = tags ) . HMM this matrix can be referred back to to retrieve previous transition probabilities . . . . . . HMM is max ( max ( p ( ti-1|ti-2 ) * p ( ti|ti-1 ) ) They arise from the two simplifying assumptions . Bigram limits model history . Feature independence limits model richness . HMM is difficult to add additional features . HMM is . . They simplify the problem by discriminating between classes ( ne tag types ) rather than modelling every data point . Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity . Examples of discriminative models are the Maximum Entropy ( MEMM ) and the CRF . Discriminative models is . . CRF is lafferty et al . CRF is ( 2001 ) . CRF is based on log - linear models like regression . For CRF , any combination of features is allowed . Include features that help with unknown words ( e.g . word shape ) . CRF is one matrix of inputs ( sentences and words ) . CRF is one matrix of outputs ( ne type labels ) . CRF input and output matrix linked by weighted set of rules . For CRF , a large set of predictive “ feature rules ” are generated from training data ( e.g . presence of wi in a gazetteer ) . Rules have access to all words , but only the previous label ( linear chain CRF ) – this makes decoding easier . Each rule results in a score . When applied to training data for each step ( word ) , rule scores are aggregated for each rule and weighted , then summed to give the score for that step ( i.e . a weight exists for each global feature ) . For CRF , during training , weights are updated using log - likelihood and sgd . New sentences are labelled using Viterbi ( as this is a linear chain ) in the same way as HMM , except a sum of weighted rule aggregations if used to populated each cell in the Viterbi matrix ( rather than Bayes rule as in HMM ) .. Implementations of CRF is implementations of crf . Many good implementations available . They avoid reinventing the wheel ! CRF performs well but is subject to drawbacks . Drawbacks of using CRFs very slow to train . Drawbacks of using CRFs are lafferty et al.2001 report ( on the same dataset ) : . Drawbacks of using CRFs memm+ trained to convergence from uniform distribution in 100 iterations . CRF did not converge after 2000 iterations from the uniform distribution . using the MEMM+ parameters to initialise the CRF , it converged in 1000 iterations . Features need to be hand - crafted Bidirectional - LSTM is most popular ( non - transformer - based ) . For Neural Models , vanilla rnn and gru have also been used . NNs allow word , char or other embeddings to be used ( or generated ) . Ma and Hovy ( 2016 ) is a good base Bi - LSTM architecture ( CoNLL English SotA in 2016 and basis for Wang et al . Neural Models are sota in 2021 ) . Ma and Hovy ( 2016 ) is also our seminar paper for this week . Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf . Achieved F1 91.21 which was SotA in 2016 . It brings together concepts learned thus far . End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered . For Ma and Hovy ( 2016 ) , a char representation for each word is generated from a cnn ( 30 filters of width 3 ) based on char embeddings . For Ma and Hovy ( 2016 ) , char rep is concatenated with glove word embedding . For Ma and Hovy ( 2016 ) , bi - directional lstm is achieved by concatenating left - to - right and right - to - left lstm hidden states ( 200 units ) . For Ma and Hovy ( 2016 ) , crf is used as output layer ( rather than softmax ) to decode label sequences . Ma and Hovy ( 2016 ) dropout ( 0.5 ) used in cnn and lstm to prevent overfit . It bioes tagging scheme ( e for ending , s for single element ) . Ma and Hovy ( 2016 ) is convergence at around 50 epochs ( with early stopping ) . Word embeddings are fine - tuned during trainingArchitecture diagrams from paper . CRF shows tags from PoS task , NER task uses same config ( except for initial LR ) Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction . Wang et al . ( 2021 ) is automatic selection of embeddings for tasks using neural architecture search . It generates better word representations . It reduces human effort of architecture design . Wang et al . ( 2021 ) is different combinations of embeddings are assessed by task accuracy . Wang et al . ( 2021 ) paper focusses on ace , but is sota in 6 tasks , including ner . Achieved F1 94.6 on English CoNLL-2003 using ACE with embedding fine - tuning . For Wang et al . ( 2021 ) , bilstm - crf model based on ma & hovy is used for sequence - structured outputs . For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings . For Wang et al . ( 2021 ) , task - specific embedding fine - tuning is done before ace part . ACE does F1 0.6 better than simply concatenating ALL embedding types ! . The sets of embeddings used for tasks were quite variable . The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) . For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . . Wang et al . ( 2021 ) . Large pre - trained language models have achieved success in many NLP tasks , including NER . Transformer-based LMs ( typically ) use a deep transformer architecture with many layers / parameters . Transformer-based LMs are ( typically ) model long - range dependencies using attention mechanism . Transformer-based LMs ( typically ) require task - based fine - tuning . For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) . Transformer-based LMs are notable systems : . Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task . Transformer-based LMs are gpt-2 ( radford et al . , 2019 ) uni - directional transformer - based . Transformer-based LMs are bert ( devlin et al . , 2019 ) bi - directional transformer - based mlm and nsp . Transformer-based LMs are optimsations : . RoBERTa ( Liu et al . , 2019 ) improved BERT performance through stronger masking strategies . Transformer-based LMs distilbert ( sanh et al . , 2019 ) smaller and faster with 95 % of the original bert perform . The are many other BERT variants . Transformer-based LMs are discussed in more detail in weeks 7 and 8 . . . . Week 5 lecture summary is part 1 . Week 5 lecture summary is named entity recognition . Week 5 lecture summary is what and why . Week 5 lecture summary is ne types , labelling , evaluation and features Before the seminar please read ma and hovy ( 2016 ) Next time getting data ! will be covered . Next time for supervised training will be covered . Next time existing sets will be covered . Next time more efficient labelling will be covered . Next time semi - supervised approaches will be covered . Next time distant supervision will be covered . Next time bootstrapping will be covered . Next time unsupervised will be covered . Next time .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}],"source":["#baf of word creation\n","strlist=\"\"\n","\n","for sentences in anewlist_3:\n","    strlist+=sentences\n","strlist"]},{"cell_type":"code","source":[],"metadata":{"id":"-o54ue8uHgR3","executionInfo":{"status":"ok","timestamp":1661866452909,"user_tz":-60,"elapsed":9,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","execution_count":52,"metadata":{"id":"UaGi04SNwPwa","executionInfo":{"status":"ok","timestamp":1661866452909,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["from keyphrase_vectorizers import KeyphraseCountVectorizer"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"-ERqjpNlwRtN","executionInfo":{"status":"ok","timestamp":1661866452909,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["# KPV can make stopword removal\n","vectorizer = KeyphraseCountVectorizer(stop_words='english',max_df=True)"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"NbaaEBDAwP0p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866453762,"user_tz":-60,"elapsed":859,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"38869ab3-8b0f-40a6-9438-08ab1be724fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1  2  0  1  3  1  3  1  1 10  1  1  1  1  8  1  1  1 13  1  2  1  1 15\n","   1  0  1  1  1  1  1  1  1  2  1  0  1  1  1  1  1  1  4  1  3  0  1  1\n","  17  1  6  1  2  2  2  1  1  1  5  1  1  1  0  4  0 10  4  1  5  2  2  1\n","   1  1  1  1 10 16  0  1  1  2  2  3  1  1  1  2  1  1 10  1  1  1  2  1\n","   1  1 12  1  1  2  2  1  2  3  0  1  1  1  1  9  1  1  0  5  1  2  2  1\n","   2  2  1  1  2  1  1  2  1  1  1  6  1  0  1  2  1  1  1  3  4  1  2  1\n","  16  3  1  2  1  4  1  1  1  1  2  1  1  1  1  9  2  5  7  1  2  1 17  2\n","   1  1  1  1  1  1  1  1  4  4  1  1  1  1  1 12  1  1  1  1  1  6  1  1\n","   1  1  1  1  1  1  1  3  1  1  4  1  1  1  1  4  1  1 16  1  2 34  1  1\n","   1  2 15  1  6  1  1  1  0  1  0  1  3  2  1  1  1  6  2  1  0  1  1  0\n","   1 15 15  1  1  1  0  1 11  1  1  1  3  2  1  1  0  0  9  0 13 18  1  2\n","   1  2  5  1  3  1  1  9  1  2  3  1  1  1  1  1  1  0  1  1  2  4  2  1\n","   1 16  1  1 11  1  1  1 19  4  1  1  3  0  1  2  8  2  1  2  1  1  1  1\n","   1  1  2  1  1  2  1  1  1  2  4  1  3  2  0  1  1  1  2  1  1  5  1  1\n","   3  1  6  4  0  3  4  1  1  2  1  1  1  0  1  9  1  1  1  1  1  2  2  1\n","  22  1  1 18  1  1  1  2  0 11 11  2  2  1  4  3  1  1  4  1  1  1  1  1\n","   6  3  2  5  1  1  1  2 22  7  1  3  1  0  1  1  2  1  2  0  2  1  2]]\n"]}],"source":["#KPV fitted to the document to find the candidate KPs and KVs exisitng in the document.\n","document_keyphrase_matrix = vectorizer.fit_transform([strlist]).toarray()\n","print(document_keyphrase_matrix)"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpFplpVuwP4b","executionInfo":{"status":"ok","timestamp":1661866453763,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"309ea8ea-fc34-4b9e-b790-b927404658b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['maximum entropy', 'presence', 'e.g . bert', 'unseen data',\n","       'variables', 'good base bi', 'generative models', 'type ambiguity',\n","       'unknown words', 'time', 'distant supervision', 'data point',\n","       'half year contract', 'chatbots', 'lstm', 'humans',\n","       'seminar paper', 'bidirectional language modelling task', 'week',\n","       'initial set', 'right', 'weights', 'global feature', 'embeddings',\n","       'brighton', 'f', 'cell', 'word phrases', 'epochs',\n","       'previous tag type', 'feature extraction', 'output layer',\n","       'overfit', 'sentences', 'different combinations', 'o \\uf0e0',\n","       'harder problem', 'architecture design', 'likely label',\n","       'model sequences', 'text classification', 'simple classifiers',\n","       'drawbacks', 'tagging scheme', 'prediction', 'proper name e.g',\n","       'same dataset', 'supervised ml', 'al', 'many nlp tasks', 'feature',\n","       'nsp', 'bilstm', 'sentiment', 'dataset', 'weeks',\n","       'observed variables', 'intent extraction', 'language models',\n","       'challenges', 'test data', 'better word representations',\n","       'ontonotes v5.0', 'classification', 'e.g', 'wang et al', 'end',\n","       'gkg', 'part', 'detection', 'elmo', 'model richness', 'units',\n","       'original bert perform', 'chunkturn span identification',\n","       'stronger masking strategies', 'language', 'sequence',\n","       'natural language q', 'word wi', 'hand', 'question answering',\n","       'language modelling', 'use', 'neural architecture search',\n","       'exact position', 'popular ner benchmark',\n","       'transition probabilities', 'sgd', 'extractive', 'rule',\n","       'entity recognition part', 'dates', 'big deal', 'directional lstm',\n","       'downstream nlp tasks', 'entity type set', 'paper focusses',\n","       'type', 'named entitydifficulties',\n","       'semantic structured prediction', 'uniform distribution',\n","       'advnlp week', 'correct spans', 'assumptions', 'crfs', '%',\n","       'boundary detection', 'manchester united striker wayne rooney',\n","       'gazetteer', 'google', 'iob encoding', 'initial lr', 'most tasks',\n","       'ti|ti-1', 'overview', 'crf model', 'ne types', 'independence',\n","       'range dependencies', 'ambiguity', 'lafferty et al',\n","       'weighted rule aggregations', 'same way', 'sets',\n","       'attention mechanism', 'ace part', 'speech', 'additional features',\n","       'numerical expressions', 'reliable text sources', 'model',\n","       'human effort', 'conll-2003', 'choice', 'relation', 'infobox',\n","       'many other bert variants', 'decode label sequences', 'problem',\n","       'bi', 'other benchmarks', 'structured prediction', 'large set',\n","       'hmm', 'combination', 'text passage', 'discriminative models',\n","       'previous transition probabilities', 'max', 'named entitythe',\n","       'model joint probability distributions', 'concepts', 'classifier',\n","       'wi', 'inclusion', 'previous systems', 'more types',\n","       'viterbi matrix', 'next time', 'bidirectional', 'memm',\n","       'ner approaches', 'fasttext', 'seminar', 'rule scores', 'et al',\n","       'bigram', 'correct type', 'ne type labels', 'pos task',\n","       'external data', 'sub', 'next time bootstrapping', 'dropout',\n","       'current tag type', 'word embeddings', 'rules',\n","       'supervised approaches', 'access', 'filters', 'kbp', 'crf input',\n","       'sequence labelling', 'output matrix', 'sequence labelling task',\n","       'ending', 'concatenation', 'likely sequence', 'tag type',\n","       'end sequence labelling', 'noun', 'sum', 'inc', 'layer bilstm',\n","       'more detail', 'efficient labelling', 'fact',\n","       'char representation', 'pos', 'word input', 'new data', 'char',\n","       'lstm architecture', 'context', 'likelihood', 'observed tokens',\n","       'f1', 'event extraction', 'width', 'labelling', 'anything', 'step',\n","       'entity', 'results word', 'many good implementations', 'maxent',\n","       'neural language models', 'ner', 'trainingarchitecture diagrams',\n","       'training', 'ref resolution', 'deep transformer architecture',\n","       'notable systems', 'e.g . memm', 'single element', 'e',\n","       'dimensionality reduction', 'viterbi', 'attention', 'many layers',\n","       'early stopping', 'model history', 'matrix', 'log', 'heuristics',\n","       '\\uf0e0', 'relation extraction', 'other embeddings',\n","       'e.g . united', 'cols', 'named entity recognition',\n","       'entity recognition', 'similarity', 'radford et al',\n","       'sequence labelling problem', 'memm+ parameters', 'degrees', 'iob',\n","       'chunksequence labelling', 'emission probabilities',\n","       'tag sequences', 'training data', 'convergence',\n","       'logistic regression', 'partial overlaps', 'ti-1|ti-2', 'e.g .',\n","       'data', 'e.g . word shape', 'nlp tasks', 'tasks',\n","       'distributional semantics', 'outputs', 'measure', 'regression',\n","       'bayes', 'mlm', 'distributions', 'seeds', 'roberta', 'approaches',\n","       'nns', 'token', 'character', 'bayes rule',\n","       'automatic content creation', 'other tokens',\n","       'product intelligence', 'gazeteer', 'approximate chronology', 'p',\n","       'generalization', 'liu', 'neural models', 'ace',\n","       'typical supervised approach', 'vanilla', 'feature independence',\n","       'transformer', 'states', 'boris johnson', 'hovy', 'sparsity',\n","       'large language models', 'char rep', 'word', 'tags',\n","       'previous label', 'bootstrapping semantics', 'discriminative', 'q',\n","       'weight', 'utd', 'words', 'character embeddings', 'variation',\n","       'translation', 'classes', 'same config', 'leverage', 'pizza hut',\n","       'ner task', 'ne tag types', 'key points', 'conll english sota',\n","       'prices', 'word representations', 'new york times',\n","       'entity lookup lists', 'sentiment analysis', 'ne tags', 'paper',\n","       'summarisation', 'labels', 'intent', 'b \\uf0e0',\n","       'training documents', 'precision', 'optimsations', 'glove',\n","       'temporal expressions', 'supervised training', 'fine',\n","       'linear models', 'devlin et al', 'tuning', 'bert performance',\n","       'text', 'entities', 'n', 'implementations', 'lecture summary',\n","       'evaluation evaluation features', 'task accuracy', 'times', 'svm',\n","       'natural language generation', 'gazeteers',\n","       'non - academic scenarios', 'probabilistic language models', 'tag',\n","       'semantic sequence tasks', 'char embeddings', 'case', 'co',\n","       'feature rules', 'basis', 'directional transformer',\n","       'peters et al', 'named entity', 'inputs', 'cnns', 'types', 'wheel',\n","       'recursive algorithm', 'perplexity', 'parameters',\n","       'english conll-2003', 'lms', 'features', 'search', 'score',\n","       'sentence', 'non', 'entity types', 'likely transition',\n","       'lingual flair', 'chunk', 'gram modelling', 'linear chain crf',\n","       'automatic selection', 'synactic', 'success', 'bert', 'output',\n","       'examples', 'evaluation', 'glov', 'bio encoding',\n","       'conditional probability', 'probability distributions', 'crf',\n","       'task', 'multiple scores', 'iterations', 'recall',\n","       'lafferty et al.2001 report', 'softmax', 'glove word',\n","       'naïve bayes', 'new sentences', 'question', '* p', 'cnn',\n","       'machine translation', 'linear chain'], dtype=object)"]},"metadata":{},"execution_count":55}],"source":["#candidates regarding to their Term Document Frequencies\n","keyphrases_candidates = vectorizer.get_feature_names_out()\n","keyphrases_candidates"]},{"cell_type":"markdown","metadata":{"id":"ztxzqT7UwbAq"},"source":["# KPE BERT"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"infZtfH-wP8L","executionInfo":{"status":"ok","timestamp":1661866464137,"user_tz":-60,"elapsed":10376,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"colab":{"base_uri":"https://localhost:8080/","height":465,"referenced_widgets":["fb6924b9a7784c8dba5d214b39d7daa8","2b14fc14442646189fea6fbe98c7a4c8","eb8ecafa1815458dadeef763442d14c5","6b472530f19e4862a275747bf4b76390","8e237cf5a2924b74a35610a103da0ab1","b8b8626fb61b45d397af0d55fffe61d0","63e342243353452b8a164a43e46fdacb","80da96e838454ab8a6530f90ccb26e25","2be845158895415487b7dda569af5295","6b31857607e84b56a7ab48731dcdd716","675325f87d04483dbbb62cf368fe0797","cb55541efa5a4bbd84052e6304b34deb","4a9c53969d6b46558edffb6d23a5dd05","78dbfaeb2fc742f29cda6ebf57658997","e72c12d7886e46f19d1d212900ea9317","d8fe7892a4d44f66998344b529b19551","0436b17eed994263ada2d7ab040da88e","cc1774e3eb46406e837ed06a7c6be198","959407c5e3c94a28825fa4131a3cd7ef","5cdd9f0f426446968054fa46d4795517","1d1a15caa321431e9c771e3efbbd08c5","992f4156728c4d9cb1c20742cb7481cd","14d6ddfb31314075bdfad0a9cb411113","e5001e678d6643538f649dba38e9697c","12c1834f780f4d93a44010ded043b25b","ea0540a0b5bd4703a84634475ab651a5","50f0dae9da2a4add8bb2e76135c44104","83a55fc441c64fbab38d27536d5739ce","317b69d001e64897b237e1ff4e606330","bc041e1d7f5d4716b068fb2b31cdc1d9","e43cdb5dfcf84d33a891f4aa315be3b8","aec0670dca0f4420bfafc1f62f232c5a","9397aa6fc93040dca28419be5ab046ec","6b3076ec6ea041909014d7c58b4d2411","6d153c4c6db44e388969d2bbd4fcdbd7","60c19dc28ac143a18f57f99364e5596e","24aad48f541e471181b06904e8650aef","1ac1035ee756436c95df1b3805ccf634","1bdbb40f82ed42cea78940db193cb045","075ba978358d4486a877641c8924040f","47d7c3fbfabd4ca8a312b22820fbb914","6d03852459104f8ebda97fb3786d5ed3","bfcb9f5aee1f4de1ae52523f2313ed0c","ef91a4f94fb64e2eb8ab8968651d3c9c","8a44c120e79f454094d861fe973b58ee","49f897a6e2234abdad2049831051b9ca","63cfd5bf0ef849698497f3605c549a60","ba14ce90ae9542f3939875d0e46b4e71","9f01fa9b54794218b6cf20d2ca7db361","6353c797931649c6aee18fb957408db9","7dd91d0512484b75bfd290ca9236a520","1b1214ebf46c4eb0850e88545352a42d","ebbb022e00844172ac8f3099c5e11179","9154b16974db4e9eaa34a12350734076","90b5392f862040c583ef5d9b382452f3","235dd3efcf73455597466f586f70b573","ba656719d589470d8cbfdf3cdfa05e09","84b55f8779cd46bbb5897f4ec9766e6b","af5751b9d53045c29ff53050ecf7041f","4207c498cb844c0bb208057abb63483a","2124a932c55a4ca9bae084055a3c8930","2692c01c71e541ea870dda62c825ef68","7b1bd138df0c4c10bac94542679c500f","017085682fa34006ac12e8d4751b82f0","b55b2a1ffd534220bb04f7f844a2dbba","1a9948b804e24add8bc976c665eac737","b2cda8aa16d44d24b3383c2066abd24f","52359158bfeb4d16958e35b8d27a4ee5","ce6079a359544ea087c21a0bc3b7973f","999f1c2e2ca04b46bb73c0dd9e165488","10055895b81248c4ba07f66f70145355","6d3c3dad30ee4418abc584f1a5f0dabc","9b973d84bd954771a57d9e7c4b3a48f7","6388d3ace4f84cc9ad4cf6e0d108abdf","907067fb6b2141a19322b07094d134a4","3b4398de30964631ab12e87ded73b749","f3a80220192d41c7a8ba993bcd37ef66","89957df4522f426fbbb721764ef96e45","b3d5546be64f44269938c7d3c8a4e0fc","91d2c2b71bab4fcc8427296143be6b29","a9fcd843c62b443dabe4b1f27f4fb035","8748b88c9ffe484799a5492cb37b8854","ce50ccabe20e4552ac62cc170a88546c","bec24d7c1b3c4fd29a1ed7ffe69f2825","6e2080929430444bb17e1ad2cba01d0e","425f7510af2a4ca08e4d22c7f3a4d0b3","c649c7e81f17473d8bc2a7ff482cb5c3","9d2eaaf469c2435ca38de2b608034606","f97f4b1cd33c4a69803d5f852ea335b7","9619ab168f3341e6b6760bdff41ba065","d916a187217140a3a0c6bec2ce6a3745","17ccc418f8b14531a3901a049b332a99","0fed838faa8442a0b14bbc197f233d30","d789547b7cd847d1ad1317c88826b29e","5d97a22f282442f181072aa1b0d350c8","a12adece3c7847cb85419697368a24b5","1350291ee322460eb31f935b03e493c6","0b3d5fc8dcc8462dad527202a30da491","7ce495da3b9a48c891f26fe02320369b","09bad6cbdefd483ba36005ae08cec4d6","8b9def6b3f78443ea587bb6ae937ad24","f72cc39609aa4c01ae5b8347fc49b99d","6b5e3567c82a4550a736a10313ae3786","4b17154a616f419e928bca2fa38bb494","b021dce5419f46138fd8d1a9117730cd","1dd6b29f1bee4f8bbcb703f70010be3c","6aaec3ce7ebc454297e7ef23f4ad3227","f191d56f267d45a5aafcd6071a16ac56","4c64293537e341568d59dcb0d4546b15","1caa086fbaa945c6869f1188e7adacb3","1adce2bfa2314181b21ccb1192285f95","290ca991506e4fe19ae8f1462cffde61","f1bbd6bc1a944a0d865a7009b6905474","815d7cf1ac5c4616ab900dc84b9c0cdf","a4992141459d4b69aeb7639785e63e60","e270e13901db4a9ba00af70df211d5fa","929791e47ac041f2a0e651be7e1390ae","2d314a87528a4fa1b231c2abd97a53f8","c0dac07275474a628ae04193232d848a","595d6c743bc145b083df9f25713bd691","d1d06c7c0ebc41cc9b0d6467b8d492ab","54eb351a91c94180958c0ae95d7173f7","f531d79714f64219885de3fed80bd8ee","3af84ff6a21e427ebf2c9b597511a99e","fa3b8d6375dd4fe980fb0869101e1219","8187a52010f9431a92a3c8b085f73544","01dd0d9c010a4a2eb58cea0abc2a9d37","83bdcd860c23414b99c4f28f51e0dead","8aa9b753c17c42d4b4b6b295e9f3b118","0670994dc2d342388c24ebba60ef8a6b","cedd1907a459433eac9db82376e579ed","35d4a5870426420c8b4ef25eebbda2af","9719f531e3134b179f62f5fb3f5e0feb","65a9351e11c54190b095c5908ed835c6","96f898c708f843828c0652a82d05b8d3","725cee007a634ad796c50c2d33fd770c","e90d483f3a574d5ead3272f8ae8596de","24c6838015d04389a83111daf1ffb14f","9e1b711c584e4ecb9e10d3594a8d87db","002c89b303ef40f5b6d8993dcc050c14","938dbc815fc3497f9f69f4b8d875c9e3","931b1525e2124d3dbbe9cf4d9629d1d1","7b5ff4e9fdbb4294829ca6e71df8d077","113cc901e96b44a38b36e7293bdbca0b","d939d5b4f82444379b6d763010872911","cfe18c51539b4c22954e554806f7e266","5f062d151beb4c20836ebd9af3a70cc0","a94962686ef24a54ade31c0381c18f09","96dbe97498e2457c90d50bb428ff879d","c1b626e183e9438b9f06238412c01b08","a76d75bbdbd244b698ff805c4b935749","fe4bf834359c4234b289a69b4285abf1","ca882bc533934bd5a9dba6acdaa2e4ab","5be6f29fea3e453694ec6caf8804b03d"]},"outputId":"8bb8bd78-08fd-48e4-a4dd-cab14a3a1a77"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb6924b9a7784c8dba5d214b39d7daa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb55541efa5a4bbd84052e6304b34deb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d6ddfb31314075bdfad0a9cb411113"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b3076ec6ea041909014d7c58b4d2411"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a44c120e79f454094d861fe973b58ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235dd3efcf73455597466f586f70b573"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2cda8aa16d44d24b3383c2066abd24f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89957df4522f426fbbb721764ef96e45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f97f4b1cd33c4a69803d5f852ea335b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09bad6cbdefd483ba36005ae08cec4d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1adce2bfa2314181b21ccb1192285f95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54eb351a91c94180958c0ae95d7173f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9719f531e3134b179f62f5fb3f5e0feb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"113cc901e96b44a38b36e7293bdbca0b"}},"metadata":{}}],"source":["from keybert import KeyBERT\n","kw_model = KeyBERT()\n"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"aeflBNTHwdZx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866466920,"user_tz":-60,"elapsed":2786,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"80e958f0-cfb1-4789-9ed4-34bfadd6f1a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('nlp', 0.4256),\n"," ('semantic', 0.3947),\n"," ('annotate', 0.387),\n"," ('word2vec', 0.3715),\n"," ('semantics', 0.3384),\n"," ('entities', 0.3199),\n"," ('tasks', 0.3136),\n"," ('tagging', 0.3092),\n"," ('entity', 0.2982),\n"," ('supervised', 0.2932),\n"," ('language', 0.2894),\n"," ('chatbots', 0.2875),\n"," ('classification', 0.2812),\n"," ('words', 0.2786),\n"," ('overview', 0.2709),\n"," ('text', 0.2677),\n"," ('labelling', 0.2673),\n"," ('lingual', 0.2651),\n"," ('task', 0.2649),\n"," ('classifiers', 0.2627),\n"," ('word', 0.261),\n"," ('lstm', 0.2595),\n"," ('entitythe', 0.2547),\n"," ('attention', 0.2527),\n"," ('fasttext', 0.2524),\n"," ('speech', 0.2521),\n"," ('classifier', 0.2518),\n"," ('sentences', 0.2461),\n"," ('rnn', 0.241),\n"," ('softmax', 0.2406)]"]},"metadata":{},"execution_count":57}],"source":["#KWs are extracted with choosing the range as 1, unigram\n","kwBERTf=kw_model.extract_keywords(docs=[strlist], keyphrase_ngram_range=(1,1),top_n=30)\n","kwBERTf"]},{"cell_type":"code","source":["unikwBERT=[]\n","for kws in kwBERTf:\n","  unikwBERT.append(kws[0])\n","unikwBERT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ky747JPWADE","executionInfo":{"status":"ok","timestamp":1661866466920,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"bd53c756-0203-4cbb-fabd-4ca65acbfb67"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['nlp',\n"," 'semantic',\n"," 'annotate',\n"," 'word2vec',\n"," 'semantics',\n"," 'entities',\n"," 'tasks',\n"," 'tagging',\n"," 'entity',\n"," 'supervised',\n"," 'language',\n"," 'chatbots',\n"," 'classification',\n"," 'words',\n"," 'overview',\n"," 'text',\n"," 'labelling',\n"," 'lingual',\n"," 'task',\n"," 'classifiers',\n"," 'word',\n"," 'lstm',\n"," 'entitythe',\n"," 'attention',\n"," 'fasttext',\n"," 'speech',\n"," 'classifier',\n"," 'sentences',\n"," 'rnn',\n"," 'softmax']"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","execution_count":59,"metadata":{"id":"F6AWLH3HwdeE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866471279,"user_tz":-60,"elapsed":4361,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"7386a91c-0c69-46b9-a01e-d407e652ae61"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('many nlp tasks', 0.6471),\n"," ('nlp tasks', 0.6456),\n"," ('named entity recognition', 0.6234),\n"," ('downstream nlp tasks', 0.5708),\n"," ('entity recognition part', 0.5575),\n"," ('semantic sequence tasks', 0.5517),\n"," ('entity recognition', 0.5437),\n"," ('bidirectional language modelling task', 0.5126),\n"," ('language modelling', 0.4649),\n"," ('word representations', 0.4599),\n"," ('better word representations', 0.4504),\n"," ('sequence labelling task', 0.4426),\n"," ('language models', 0.4412),\n"," ('neural language models', 0.4396),\n"," ('large language models', 0.4274),\n"," ('word embeddings', 0.4258),\n"," ('named entity', 0.4165),\n"," ('probabilistic language models', 0.4108),\n"," ('text classification', 0.4068),\n"," ('semantic structured prediction', 0.406),\n"," ('question answering', 0.4022),\n"," ('natural language generation', 0.3872),\n"," ('machine translation', 0.3722),\n"," ('sequence labelling', 0.3681),\n"," ('word input', 0.3601),\n"," ('named entitythe', 0.3568),\n"," ('distributional semantics', 0.3535),\n"," ('event extraction', 0.3507),\n"," ('word phrases', 0.3347),\n"," ('gram modelling', 0.3278),\n"," ('ner task', 0.3262),\n"," ('intent extraction', 0.3229),\n"," ('entities', 0.3199),\n"," ('tasks', 0.3136),\n"," ('named entitydifficulties', 0.3102),\n"," ('evaluation evaluation features', 0.3017),\n"," ('entity', 0.2982),\n"," ('efficient labelling', 0.2948),\n"," ('sequence labelling problem', 0.2943),\n"," ('bootstrapping semantics', 0.2933),\n"," ('results word', 0.2911),\n"," ('automatic content creation', 0.29),\n"," ('language', 0.2894),\n"," ('relation extraction', 0.2888),\n"," ('chatbots', 0.2875),\n"," ('entity types', 0.2864),\n"," ('end sequence labelling', 0.2842),\n"," ('training documents', 0.2837),\n"," ('classification', 0.2812),\n"," ('words', 0.2786)]"]},"metadata":{},"execution_count":59}],"source":["#KPs with KPV\n","keywords_KeyBert=kw_model.extract_keywords(docs=[strlist], vectorizer=KeyphraseCountVectorizer(),top_n=50)\n","keywords_KeyBert"]},{"cell_type":"code","source":["#KPs with n-gram range\n","kwBERTng=kw_model.extract_keywords(docs=[strlist], keyphrase_ngram_range=(1,3),top_n=50)\n","kwBERTng"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXnksx4IeVFF","executionInfo":{"status":"ok","timestamp":1661866485208,"user_tz":-60,"elapsed":13932,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"9d2e70ec-69fc-4b32-da70-3759e778b4ca"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('entity recognition week', 0.6699),\n"," ('nlp tasks including', 0.6481),\n"," ('nlp tasks', 0.6456),\n"," ('nlp tasks named', 0.6434),\n"," ('features nlp tasks', 0.6331),\n"," ('labelling nlp tasks', 0.6254),\n"," ('named entity recognition', 0.6234),\n"," ('nlp tasks applied', 0.6232),\n"," ('tasks nlp', 0.6226),\n"," ('nlp tasks natural', 0.6166),\n"," ('creation nlp tasks', 0.6166),\n"," ('nlp tasks language', 0.6125),\n"," ('nlp tasks machine', 0.6111),\n"," ('nlp tasks speech', 0.6098),\n"," ('tasks nlp tasks', 0.5982),\n"," ('nlp tasks text', 0.5891),\n"," ('generation nlp tasks', 0.5879),\n"," ('tasks natural language', 0.5858),\n"," ('features nlp', 0.585),\n"," ('nlp tasks question', 0.5846),\n"," ('extraction nlp tasks', 0.5822),\n"," ('extractive nlp tasks', 0.5775),\n"," ('applied tasks nlp', 0.5769),\n"," ('downstream nlp tasks', 0.5708),\n"," ('nlp tasks summarisation', 0.5654),\n"," ('nlp tasks chatbots', 0.5646),\n"," ('passage nlp tasks', 0.5603),\n"," ('translation nlp tasks', 0.5591),\n"," ('success nlp tasks', 0.5579),\n"," ('tasks text classification', 0.5549),\n"," ('entity recognition semantic', 0.5538),\n"," ('evaluation features nlp', 0.5537),\n"," ('entity recognition advnlp', 0.5524),\n"," ('semantic sequence tasks', 0.5517),\n"," ('entity recognition google', 0.5444),\n"," ('entity recognition', 0.5437),\n"," ('labelling nlp', 0.5385),\n"," ('language modelling task', 0.5295),\n"," ('sequence labelling nlp', 0.5282),\n"," ('tasks language modelling', 0.528),\n"," ('classification named entities', 0.5187),\n"," ('entity recognition assigning', 0.5145),\n"," ('extraction nlp', 0.5139),\n"," ('entity recognition entity', 0.5133),\n"," ('creation nlp', 0.5118),\n"," ('named entities text', 0.51),\n"," ('similarity nlp tasks', 0.5064),\n"," ('language models word2vec', 0.5058),\n"," ('phrases named entity', 0.5017),\n"," ('content creation nlp', 0.5012)]"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","execution_count":61,"metadata":{"id":"szWlb0pqwdiB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866485209,"user_tz":-60,"elapsed":17,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"9acb351e-fcd2-4b02-d869-09944567cb85"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['many nlp tasks',\n"," 'nlp tasks',\n"," 'named entity recognition',\n"," 'downstream nlp tasks',\n"," 'entity recognition part',\n"," 'semantic sequence tasks',\n"," 'entity recognition',\n"," 'bidirectional language modelling task',\n"," 'language modelling',\n"," 'word representations',\n"," 'better word representations',\n"," 'sequence labelling task',\n"," 'language models',\n"," 'neural language models',\n"," 'large language models',\n"," 'word embeddings',\n"," 'named entity',\n"," 'probabilistic language models',\n"," 'text classification',\n"," 'semantic structured prediction',\n"," 'question answering',\n"," 'natural language generation',\n"," 'machine translation',\n"," 'sequence labelling',\n"," 'word input',\n"," 'named entitythe',\n"," 'distributional semantics',\n"," 'event extraction',\n"," 'word phrases',\n"," 'gram modelling',\n"," 'ner task',\n"," 'intent extraction',\n"," 'entities',\n"," 'tasks',\n"," 'named entitydifficulties',\n"," 'evaluation evaluation features',\n"," 'entity',\n"," 'efficient labelling',\n"," 'sequence labelling problem',\n"," 'bootstrapping semantics',\n"," 'results word',\n"," 'automatic content creation',\n"," 'language',\n"," 'relation extraction',\n"," 'chatbots',\n"," 'entity types',\n"," 'end sequence labelling',\n"," 'training documents',\n"," 'classification',\n"," 'words']"]},"metadata":{},"execution_count":61}],"source":["keywordsBERT=[]\n","for kws in keywords_KeyBert:\n","  keywordsBERT.append(kws[0])\n","keywordsBERT"]},{"cell_type":"code","source":[],"metadata":{"id":"cadBzVLzYtYA","executionInfo":{"status":"ok","timestamp":1661866485209,"user_tz":-60,"elapsed":15,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S_1GQJlswoOF"},"source":["# KPE MPNet"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"fXWsAovMwP_s","executionInfo":{"status":"ok","timestamp":1661866485209,"user_tz":-60,"elapsed":15,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["from sentence_transformers import SentenceTransformer"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"LCZe6l34wx4D","executionInfo":{"status":"ok","timestamp":1661866504019,"user_tz":-60,"elapsed":18824,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"colab":{"base_uri":"https://localhost:8080/","height":465,"referenced_widgets":["fbe3fc9613d6456a969b8b6c9fb7716d","9e865fdc365c4d859c00862f7e6aa99d","a058132c315847b5ad1597fa99414e3f","087c75ae861d4827b3d08ab5da655a46","8f5af00d6a4d4975a2578a4eb6630bcd","c53d3efab148439ca40595b4d4ac4508","a6d4f80769664b0a81011afa79bf28e4","4e1cbf6ac85f480291c695512b53b70e","41dfdbcef8ca4ae2918847c53f64fe03","12088693939d4cb983e0b9f1c8fcfe32","60e403bcf3cf4e6a844e68fa38ab04c6","185aa29ba3ea40a99b75f4576368a65c","bb569183a29d4efa93f67b2f650592eb","795f21fa5ff646208338ba0f5c52ca01","f15fbeb5950d4c44a6ef58a4129fd348","3fd5f93c338040b48ab203af2f3aac95","c02a50052c4c42d4aa4ec9e9c7217163","0412a5735c824342b5bcf8943d1a477f","7a5aeda40a1747e38e587214135ab9ce","ccd60cac10fd43de8ec62b0f2b41167e","72dab580e5ea4eccb9006812c775918c","790b6afa4ed048b78d1669db431b3777","32ef281a732746d0a1144fe124404b25","a61a73ef0b964325840605e8aed77dc2","15e5fcbb085b4a9990a142fe0c6542f3","6fece2d1c0114e96a6df11288a34ae6b","121fed69324e42169ffb7d89848d5cfa","989e435a65f5439684f5c49c39766738","8a3b6c954ec643e8a0aa31deec1479bc","c8df6af8049a4929a2399baea360a9d2","c8a184e0ce024730ace21360a85a1b03","4dcc9588a5fa457dab37f75d901f7c4d","cc8922962ae74d9b976186d7e5403961","7522507849e0453b857d185ef20663dd","1a157748df764e55addfbd2944409df5","a438071a59eb454482fbc1c42f30c50c","a6454593b16a4e249789181cd2c69ce5","f2adbff0b44942a982c86f9ec695c74f","b8db4424f657498493afe606859ce646","88df111373134365af9e9e837f770be6","5af6b0ad1a7b40b6bf69945ba866810d","ab82e55dc69a4683964f63a4447df5e3","902778ab46e841d5971470751e54c90b","38ae83c360154b679c65536502b62e02","55c86bf2d7e147dba57863e00e7e5767","0f9442fa9b24403d977b66aa534b2754","209168365f354a9fa256c9889bc2c1ad","22d6434b305a466f89e5c0cc85a3388e","d6b4aaeca1d24a25b4b007ffb4583b4a","4b65268a3e2d44908fb0cd80f1e6bf05","0a5206f25cdf442c9377a25fb24b7df0","6585e6c11bcb4987841aedf9ee18e19b","1641174bcc9b4abfaf92bf0a5fb7a162","61127e02f19140f2af451114f1dded92","ae575f6267d746be923e02138f7159d1","10dd178ebdbf4adcb671d71701841290","9c096c627f8945ca9da7192b37a5c2d8","ab06c0f51c4145d6926ae64fda3289ef","64e469e8a5f04d1289d316de9c930fd9","84090c6f3f1546278a65bd7aee320177","642a87be8805485aae48442ababc49f8","9ab1ed26c35a4398951a235ff74bf8fd","1ad12ccecfba43ad969d2c30799a2f41","8db140ac8bf24b198f0a37aabfc7823f","afc7a746079241bcbd3e03f2d9544875","77f38c224d134133b6a7fa5a2e02c1dc","94aab0e1a9bb43d6800ea0ab6657ff5f","cb5cb2cdc29e401caf963e3add6d0cf0","0b0e89848cf64c8287983e6d5caae058","1d68d12ee4bb488eb7765e0d2957a75a","cc1b018195a946a49f9e82c75f4603b2","cf12e062e52e407c85c05de2cd634c91","b7519f225c7541bea564db8dc8e52c5d","a787868411c24456b3bb75b99c07d2ab","2513cb7f7ebf4f0b8b51880cb106912d","3872f4d6711a4db89cd8cbec50dfdb41","343bdec5a3784c92ad5e7dbe2f227016","ff6fa3be4b234b338311c839a7783834","2c05199d39c0453d86abca7049b4d1a3","e2f3eb3170684de38a46e2e8e3eef45d","13f983aa03a542fdb3f7eddd97a40d02","35c997503c6949a8aa044e8eabacbb8e","3d7153f6f00641d3b81b09ea2f2c16eb","60b1745d45154591b808aba19f3d9363","ecfde292f5664d47b9f68e014fbe1a49","efc607ade7a34b35a538e0b68dbdff08","d131190ed6604dc690e995c732bad162","77db5210f2fd4b8c8b07fb3361f7689d","90668ec3279c48b19cc91a748a56114f","7f56fc87bf084110843b34e07685f2a6","5f0584ac4e4d466e8f63339b8ea4b401","ef66f90d020b45ceab1ff058f43a7bc8","04ed87da142946b09f6c1401e9c4ed92","2ffa8fa7757f49fcb71244a0fae85b0b","e46e042035594f9a889b8ab674a6f2d7","75e9ff44625f4afe9a5c6ef6c6be29a4","690871cf95244626a222517bbd1c4cd1","dd5bf135705248f8b7d885eca30e138e","d63ffc0def7748a4bfae01ba3488c67d","1859b0f242d0417c96cccdc6738f90e9","9a68f52b7c1b43caad8662ca4bf0b6eb","5d095089c021462b8fa93cb7af1b02ce","0dbec8e2f3ed46d8bc1a593dfdb4b39e","89cadd032e3f4a989ca8486afe9ac033","18036f5b2c364e8f9a68de68efcb1423","9c061d9394094f9fbda3f4c8b4d7efe1","995d4cdb68724f61ad12551457fd4484","0057ebb9ca9b4de7a165440d97beb525","df393f9c214a4d159b0062c160119600","5791c544ad594b5fa4c6ba116f51bfaf","f4adb4ede55040a28cf2a6a5476172fa","b56db3ea42df4558836c4ca7ba9bc6eb","8fd1fce2fb0049538540fd18de29796b","33c0130999b449f294c170c98b3350f5","b60ea11d2a7441bb8d29fea48ec5aaa3","73672e78bd1a4b5ba652cabe093a82d5","35120be898064f54a6f5388d44d2a2d0","230f1a38cd4142f2ac7b600dcb92fa6d","035c21897720458ebb38d70cdd32e7bd","a9f2d5e78e7f4311aed1f864e8f9cfbd","599baef74d40488b8f3018454c1ca87e","54e9482793054117aec511f50888de74","dc2b9fb503484dd39fe5e805c54649bc","2d6142a2a404446e855a3302bd7d5c2e","1ad891beb54545c08bfa2f6120e8f835","7cb012ccfe8841aab9f82db4fa8a5dbf","af558d286fe1475e908a2eff2a89abd4","4041c9ea936a4c5da475f83f5e192b71","0433b49a8f004d418efb3891aadcf438","46440e7ef24c487a97ce9498ffafaf75","8bfee4732e854202bef3a8a7561e1e71","6b596cc65cdb4336a718d5042878ddc5","1a788cca93c74eabb238ad9c2de01dc1","e0bd27c2a07846cb9a538ca568a5cd53","878ff1eff7a14b08a6fbee388e4314d5","1ee58314acea470091856200348789e8","5531b8430e544b4ab4e0b877cd9754ee","469270d18f19426293583fb852c1b944","93558a67a92f493aabb58d1e36c6ee27","7e321f4b553d4a328d8c8c3d4104a083","599a2e15f8cb4610859a92f90cdbc4e9","08bb8a59bef74259be78cb2a4382aa79","52d209e79dc545e8bce09991d8877f2e","294749c87a494a1bb3a4f9d993677c3b","011618c3f28d42959d072025076b17bc","933cfb4c3ee046ffa867711aacee847f","21b16a0c9a064f6fa4a5667b6c1aa1b8","f2acc566937a44e89fb1fbca7565e25f","85cc6d0571d94598a3a38dc1defc666c","4ea44ac8f2b44219b2000d5dea138402","2b8519bdc7724540bb4602b166cc4310","96e0995080664c2e97606ddc67106ed8","c8c22de8be6845f9b73ea8f78d68bb23","d33d696cc1e24234882a330159f9183f"]},"outputId":"c30cf209-fd74-4098-9895-3ad819b0ea0e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe3fc9613d6456a969b8b6c9fb7716d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"185aa29ba3ea40a99b75f4576368a65c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32ef281a732746d0a1144fe124404b25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7522507849e0453b857d185ef20663dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55c86bf2d7e147dba57863e00e7e5767"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10dd178ebdbf4adcb671d71701841290"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94aab0e1a9bb43d6800ea0ab6657ff5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff6fa3be4b234b338311c839a7783834"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90668ec3279c48b19cc91a748a56114f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1859b0f242d0417c96cccdc6738f90e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4adb4ede55040a28cf2a6a5476172fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54e9482793054117aec511f50888de74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a788cca93c74eabb238ad9c2de01dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"294749c87a494a1bb3a4f9d993677c3b"}},"metadata":{}}],"source":["sent_trans = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"rgqUNC05wx70","executionInfo":{"status":"ok","timestamp":1661866504275,"user_tz":-60,"elapsed":261,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"outputs":[],"source":["keyBERT_model = KeyBERT(model = sent_trans)"]},{"cell_type":"code","source":["#KWs\n","kwMPf=keyBERT_model.extract_keywords(docs=[strlist], keyphrase_ngram_range=(1,1),top_n=50)\n","kwMPf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZbNv_xfJJxD","executionInfo":{"status":"ok","timestamp":1661866521269,"user_tz":-60,"elapsed":16995,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"f7f7229b-d5e4-4d7e-e3ca-47c8c1e4b10b"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('word2vec', 0.4966),\n"," ('nlp', 0.4939),\n"," ('embeddings', 0.4231),\n"," ('fasttext', 0.3794),\n"," ('contextualised', 0.3722),\n"," ('tagging', 0.3603),\n"," ('labelling', 0.3512),\n"," ('annotate', 0.3493),\n"," ('rnn', 0.336),\n"," ('classifiers', 0.3348),\n"," ('embedding', 0.3293),\n"," ('classification', 0.3086),\n"," ('lstm', 0.3062),\n"," ('named', 0.3026),\n"," ('entities', 0.3024),\n"," ('neural', 0.3009),\n"," ('classifier', 0.2976),\n"," ('entity', 0.2952),\n"," ('advnlp', 0.2947),\n"," ('cnns', 0.2933),\n"," ('discriminative', 0.293),\n"," ('lingual', 0.2928),\n"," ('text', 0.2906),\n"," ('extractive', 0.2852),\n"," ('decoding', 0.2831),\n"," ('sentences', 0.2792),\n"," ('phrases', 0.2789),\n"," ('chatbots', 0.2776),\n"," ('entitythe', 0.276),\n"," ('svm', 0.2741),\n"," ('sentiment', 0.2682),\n"," ('subject', 0.2682),\n"," ('words', 0.2647),\n"," ('semantic', 0.2594),\n"," ('nns', 0.2556),\n"," ('entitydifficulties', 0.25),\n"," ('distributional', 0.2467),\n"," ('summarisation', 0.2427),\n"," ('context', 0.241),\n"," ('bayes', 0.2407),\n"," ('bootstrapping', 0.2402),\n"," ('ml', 0.2398),\n"," ('labelled', 0.2387),\n"," ('read', 0.2359),\n"," ('sentence', 0.234),\n"," ('extract', 0.2328),\n"," ('spans', 0.2322),\n"," ('english', 0.2316),\n"," ('generative', 0.2284),\n"," ('language', 0.2276)]"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","execution_count":66,"metadata":{"id":"i4MACfYwwx_G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866538460,"user_tz":-60,"elapsed":17194,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"fae11077-2cc1-4187-aab1-6a7429ce6b1f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('named entity recognition', 0.7247),\n"," ('entity recognition', 0.655),\n"," ('entity recognition part', 0.5926),\n"," ('nlp tasks', 0.5811),\n"," ('many nlp tasks', 0.5759),\n"," ('downstream nlp tasks', 0.5468),\n"," ('semantic sequence tasks', 0.5311),\n"," ('neural language models', 0.5166),\n"," ('named entity', 0.5063),\n"," ('relation extraction', 0.5006),\n"," ('bidirectional language modelling task', 0.4838),\n"," ('text classification', 0.4835),\n"," ('language modelling', 0.4811),\n"," ('large language models', 0.4804),\n"," ('word embeddings', 0.4696),\n"," ('named entitythe', 0.4529),\n"," ('distributional semantics', 0.4489),\n"," ('probabilistic language models', 0.4348),\n"," ('better word representations', 0.4338),\n"," ('language models', 0.433),\n"," ('question answering', 0.4264),\n"," ('word representations', 0.4254),\n"," ('embeddings', 0.4231),\n"," ('sentiment analysis', 0.4218),\n"," ('intent extraction', 0.4126),\n"," ('semantic structured prediction', 0.4089),\n"," ('event extraction', 0.399),\n"," ('machine translation', 0.3981),\n"," ('named entitydifficulties', 0.3979),\n"," ('sequence labelling task', 0.3954),\n"," ('supervised training', 0.3897),\n"," ('ner task', 0.382),\n"," ('fasttext', 0.3794),\n"," ('neural models', 0.379),\n"," ('natural language generation', 0.3777),\n"," ('character embeddings', 0.3679),\n"," ('simple classifiers', 0.3659),\n"," ('efficient labelling', 0.3621),\n"," ('training data', 0.3613),\n"," ('structured prediction', 0.359),\n"," ('word phrases', 0.357),\n"," ('gram modelling', 0.3537),\n"," ('supervised ml', 0.3512),\n"," ('labelling', 0.3512),\n"," ('discriminative models', 0.351),\n"," ('feature extraction', 0.3482),\n"," ('sequence labelling', 0.3402),\n"," ('entity lookup lists', 0.34),\n"," ('other embeddings', 0.323),\n"," ('unknown words', 0.3217)]"]},"metadata":{},"execution_count":66}],"source":["#KPs with KPV\n","keywords_KeyBert_x=keyBERT_model.extract_keywords(docs=[strlist], vectorizer=KeyphraseCountVectorizer(),top_n=50)\n","keywords_KeyBert_x"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"AKG4Nd77wyCl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866538461,"user_tz":-60,"elapsed":19,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"7a8593a5-616c-4fac-c38d-acdd503b75a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['named entity recognition',\n"," 'entity recognition',\n"," 'entity recognition part',\n"," 'nlp tasks',\n"," 'many nlp tasks',\n"," 'downstream nlp tasks',\n"," 'semantic sequence tasks',\n"," 'neural language models',\n"," 'named entity',\n"," 'relation extraction',\n"," 'bidirectional language modelling task',\n"," 'text classification',\n"," 'language modelling',\n"," 'large language models',\n"," 'word embeddings',\n"," 'named entitythe',\n"," 'distributional semantics',\n"," 'probabilistic language models',\n"," 'better word representations',\n"," 'language models',\n"," 'question answering',\n"," 'word representations',\n"," 'embeddings',\n"," 'sentiment analysis',\n"," 'intent extraction',\n"," 'semantic structured prediction',\n"," 'event extraction',\n"," 'machine translation',\n"," 'named entitydifficulties',\n"," 'sequence labelling task',\n"," 'supervised training',\n"," 'ner task',\n"," 'fasttext',\n"," 'neural models',\n"," 'natural language generation',\n"," 'character embeddings',\n"," 'simple classifiers',\n"," 'efficient labelling',\n"," 'training data',\n"," 'structured prediction',\n"," 'word phrases',\n"," 'gram modelling',\n"," 'supervised ml',\n"," 'labelling',\n"," 'discriminative models',\n"," 'feature extraction',\n"," 'sequence labelling',\n"," 'entity lookup lists',\n"," 'other embeddings',\n"," 'unknown words']"]},"metadata":{},"execution_count":67}],"source":["keywordsMPNet=[]\n","for keywords in keywords_KeyBert_x:\n","  keywordsMPNet.append(keywords[0])\n","keywordsMPNet"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"jqpzXb4iwyGE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866538461,"user_tz":-60,"elapsed":16,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"4c8b83e7-9526-4aa7-d5cc-26012b56d61b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('named entity recognition', 1),\n"," ('entity recognition', 2),\n"," ('entity recognition part', 3),\n"," ('nlp tasks', 4),\n"," ('many nlp tasks', 5),\n"," ('downstream nlp tasks', 6),\n"," ('semantic sequence tasks', 7),\n"," ('neural language models', 8),\n"," ('named entity', 9),\n"," ('relation extraction', 10),\n"," ('bidirectional language modelling task', 11),\n"," ('text classification', 12),\n"," ('language modelling', 13),\n"," ('large language models', 14),\n"," ('word embeddings', 15),\n"," ('named entitythe', 16),\n"," ('distributional semantics', 17),\n"," ('probabilistic language models', 18),\n"," ('better word representations', 19),\n"," ('language models', 20),\n"," ('question answering', 21),\n"," ('word representations', 22),\n"," ('intent extraction', 25),\n"," ('semantic structured prediction', 26),\n"," ('event extraction', 27),\n"," ('machine translation', 28),\n"," ('named entitydifficulties', 29),\n"," ('sequence labelling task', 30),\n"," ('ner task', 32),\n"," ('natural language generation', 35),\n"," ('efficient labelling', 38),\n"," ('word phrases', 41),\n"," ('gram modelling', 42),\n"," ('sequence labelling', 47)]"]},"metadata":{},"execution_count":68}],"source":["#same KPs exisiting in MPNet and BERT models\n","samekws=[]\n","i=1\n","for kw in keywordsMPNet:\n","  if kw in keywordsBERT:\n","    samekws.append((kw,i))\n","  i+=1\n","samekws"]},{"cell_type":"code","source":["unikwMP=[]\n","for kw in kwMPf:\n","  unikwMP.append(kw[0])\n","unikwMP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyV-EkrqWPfy","executionInfo":{"status":"ok","timestamp":1661866538462,"user_tz":-60,"elapsed":12,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"f9047d6c-8b20-4210-948f-14650badf5eb"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['word2vec',\n"," 'nlp',\n"," 'embeddings',\n"," 'fasttext',\n"," 'contextualised',\n"," 'tagging',\n"," 'labelling',\n"," 'annotate',\n"," 'rnn',\n"," 'classifiers',\n"," 'embedding',\n"," 'classification',\n"," 'lstm',\n"," 'named',\n"," 'entities',\n"," 'neural',\n"," 'classifier',\n"," 'entity',\n"," 'advnlp',\n"," 'cnns',\n"," 'discriminative',\n"," 'lingual',\n"," 'text',\n"," 'extractive',\n"," 'decoding',\n"," 'sentences',\n"," 'phrases',\n"," 'chatbots',\n"," 'entitythe',\n"," 'svm',\n"," 'sentiment',\n"," 'subject',\n"," 'words',\n"," 'semantic',\n"," 'nns',\n"," 'entitydifficulties',\n"," 'distributional',\n"," 'summarisation',\n"," 'context',\n"," 'bayes',\n"," 'bootstrapping',\n"," 'ml',\n"," 'labelled',\n"," 'read',\n"," 'sentence',\n"," 'extract',\n"," 'spans',\n"," 'english',\n"," 'generative',\n"," 'language']"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["#same KWs exisitng in both of the models\n","samekwsuni=[]\n","i=1\n","for kw in unikwBERT:\n","  if kw in unikwMP:\n","    samekwsuni.append((kw,i))\n","  i+=1\n","samekwsuni"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BH48vMZnVpQG","executionInfo":{"status":"ok","timestamp":1661866538462,"user_tz":-60,"elapsed":9,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"bc6d842d-c8c1-439a-80e3-2d0e710b79b2"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('nlp', 1),\n"," ('semantic', 2),\n"," ('annotate', 3),\n"," ('word2vec', 4),\n"," ('entities', 6),\n"," ('tagging', 8),\n"," ('entity', 9),\n"," ('language', 11),\n"," ('chatbots', 12),\n"," ('classification', 13),\n"," ('words', 14),\n"," ('text', 16),\n"," ('labelling', 17),\n"," ('lingual', 18),\n"," ('classifiers', 20),\n"," ('lstm', 22),\n"," ('entitythe', 23),\n"," ('fasttext', 25),\n"," ('classifier', 27),\n"," ('sentences', 28),\n"," ('rnn', 29)]"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["len(samekwsuni)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"at0OvOvyWh4T","executionInfo":{"status":"ok","timestamp":1661866538462,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"d64a4854-5aa7-433f-c2b4-72ea7cb9463b"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["len(samekws)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRu4EOdSWneT","executionInfo":{"status":"ok","timestamp":1661866538706,"user_tz":-60,"elapsed":249,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"3d626981-9430-4e6f-c7c8-c2e3b5ca45f1"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","execution_count":73,"metadata":{"id":"LmLPdqcV0XJX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661866538706,"user_tz":-60,"elapsed":5,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"92d94fdf-6268-48f3-8203-35857176b65e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["14373"]},"metadata":{},"execution_count":73}],"source":["len(strlist)"]},{"cell_type":"code","source":["loweredanewlist_3=[]\n","for sentences in anewlist_3:\n","  sentences=sentences.lower()\n","  loweredanewlist_3.append(sentences)"],"metadata":{"id":"Odqccr2ojYU3","executionInfo":{"status":"ok","timestamp":1661866538706,"user_tz":-60,"elapsed":2,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["#the sentences that have KWs or KPs extracted inside\n","sentencesforquestions=[]\n","for sentences in loweredanewlist_3:\n","  for keywords in keywords_KeyBert_x:\n","    sentencestokenized=word_tokenize(sentences)\n","    #print(sentencestokenized)\n","    #print(sentencestokenized[0].lower())\n","    if len(word_tokenize(keywords[0]))==1 and (keywords[0] in word_tokenize(sentences)):\n","      #print(keywords[0],anewlist_3[indexs])\n","      indexs=loweredanewlist_3.index(sentences)\n","      if (anewlist_3[indexs],keywords[0]) not in sentencesforquestions:\n","        sentencesforquestions.append((anewlist_3[indexs],keywords[0]))\n","    if len(word_tokenize(keywords[0]))>=1 and (keywords[0] in (sentences)):\n","      indexs=loweredanewlist_3.index(sentences)\n","      print(keywords[0],anewlist_3[indexs])\n","      if (anewlist_3[indexs],keywords[0]) not in sentencesforquestions:\n","        sentencesforquestions.append((anewlist_3[indexs],keywords[0]))\n","\n","\n","\n","    \n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MIRwD4_1L3z","executionInfo":{"status":"ok","timestamp":1661866544618,"user_tz":-60,"elapsed":5914,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"05b6800e-d8e7-4489-f4f1-a692d24d8e78"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["named entity recognition  Named Entity Recognition is advnlp week 5\n","entity recognition  Named Entity Recognition is advnlp week 5\n","named entity  Named Entity Recognition is advnlp week 5\n","distributional semantics  Previously distributional semantics was covered .\n","probabilistic language models  Previously probabilistic language models was covered .\n","language models  Previously probabilistic language models was covered .\n","gram modelling  Previously n - gram modelling , perplexity and generalization was covered .\n","neural language models  Previously neural language models was covered .\n","language models  Previously neural language models was covered .\n","word embeddings  Previously word embeddings was covered .\n","embeddings  Previously word embeddings was covered .\n","neural language models  Previously dimensionality reduction , neural language models , word2vec , glov was covered .\n","language models  Previously dimensionality reduction , neural language models , word2vec , glov was covered .\n","named entity recognition  Week 5 overview is named entity recognition .\n","entity recognition  Week 5 overview is named entity recognition .\n","named entity  Week 5 overview is named entity recognition .\n","labelling  Week 5 overview is ne types , labelling , evaluation and features\n","nlp tasks  NLP Tasks are natural language generation .\n","natural language generation  NLP Tasks are natural language generation .\n","nlp tasks  NLP Tasks are chatbots , automatic content creation .\n","nlp tasks  NLP Tasks is summarisation .\n","nlp tasks  NLP Tasks are question answering .\n","question answering  NLP Tasks are question answering .\n","nlp tasks  NLP Tasks are machine translation .\n","machine translation  NLP Tasks are machine translation .\n","nlp tasks  NLP Tasks are text , speech or any “ language ” translation ( e.g . q & a ) .\n","nlp tasks  NLP Tasks are text classification ( sequence labelling ) .\n","text classification  NLP Tasks are text classification ( sequence labelling ) .\n","labelling  NLP Tasks are text classification ( sequence labelling ) .\n","sequence labelling  NLP Tasks are text classification ( sequence labelling ) .\n","named entity recognition  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n","entity recognition  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n","nlp tasks  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n","named entity  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n","event extraction  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n","sentiment analysis  Sentiment analysis , intent extraction .\n","intent extraction  Sentiment analysis , intent extraction .\n","nlp tasks  NLP Tasks are language modelling and similarity .\n","language modelling  NLP Tasks are language modelling and similarity .\n","nlp tasks  NLP Tasks can be applied to most tasks .\n","nlp tasks  NLP Tasks .\n","named entity recognition  Named Entity Recognition is assigning labels to a sequence of variables .\n","entity recognition  Named Entity Recognition is assigning labels to a sequence of variables .\n","named entity  Named Entity Recognition is assigning labels to a sequence of variables .\n","named entity recognition  Named Entity Recognition is the detection and classification of named entities in a text .\n","entity recognition  Named Entity Recognition is the detection and classification of named entities in a text .\n","named entity  Named Entity Recognition is the detection and classification of named entities in a text .\n","named entity  A named entity is anything which can be referred to with a proper name e.g . , “ Boris Johnson ” , “ Pizza Hut ” , “ Brighton ” , but may also include dates , times , prices and more .\n","named entity recognition  Named Entity Recognition is often multi - word phrases .\n","entity recognition  Named Entity Recognition is often multi - word phrases .\n","named entity  Named Entity Recognition is often multi - word phrases .\n","word phrases  Named Entity Recognition is often multi - word phrases .\n","named entity recognition  Named Entity Recognition is semantic structured prediction . . .\n","entity recognition  Named Entity Recognition is semantic structured prediction . . .\n","named entity  Named Entity Recognition is semantic structured prediction . . .\n","semantic structured prediction  Named Entity Recognition is semantic structured prediction . . .\n","structured prediction  Named Entity Recognition is semantic structured prediction . . .\n","nlp tasks  NER is the basis for downstream NLP tasks .\n","downstream nlp tasks  NER is the basis for downstream NLP tasks .\n","named entity recognition  Why Named Entity Recognition ? It is sentiment or intent regarding entities .\n","entity recognition  Why Named Entity Recognition ? It is sentiment or intent regarding entities .\n","named entity  Why Named Entity Recognition ? It is sentiment or intent regarding entities .\n","named entity recognition  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n","entity recognition  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n","named entity  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n","relation extraction  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n","named entity recognition  Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .\n","entity recognition  Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .\n","named entity  Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .\n","named entity recognition  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n","entity recognition  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n","named entity  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n","question answering  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n","named entity recognition  Why Named Entity Recognition ? It is google / bing infobox .\n","entity recognition  Why Named Entity Recognition ? It is google / bing infobox .\n","named entity  Why Named Entity Recognition ? It is google / bing infobox .\n","named entity recognition  Why Named Entity Recognition ? It is competitive / product intelligence . . .\n","entity recognition  Why Named Entity Recognition ? It is competitive / product intelligence . . .\n","named entity  Why Named Entity Recognition ? It is competitive / product intelligence . . .\n","named entity  Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .\n","named entitythe  Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .\n","named entity  Types of Named Entity is temporal expressions and numerical expressions are often included .\n","named entity  Which entity type set might be most useful ? Types of Named EntityDifficulties : .\n","named entitydifficulties  Which entity type set might be most useful ? Types of Named EntityDifficulties : .\n","named entity  Types of Named Entity is two types of ambiguity : boundary and type .\n","named entity  Types of Named Entity is boundary detection ( e.g . the new york times ) – a harder problem than pos tagging .\n","named entity  Types of Named Entity is two types of type ambiguity : entity - noun , entity - entity .\n","named entity  Types of Named Entity is variation , even with reliable text sources ( e.g . united , utd , utd .\n","named entity  Types of Named Entity )\n","labelling  Sequence Labelling – IOB encoding is sequence labelling – iob encodingi  inside a chunk .\n","sequence labelling  Sequence Labelling – IOB encoding is sequence labelling – iob encodingi  inside a chunk .\n","labelling  Sequence Labelling – IOB encoding is o  outside a chunk .\n","sequence labelling  Sequence Labelling – IOB encoding is o  outside a chunk .\n","labelling  B  beginning a chunkSequence Labelling – IOB encodingI  inside a chunk .\n","sequence labelling  B  beginning a chunkSequence Labelling – IOB encodingI  inside a chunk .\n","labelling  Sequence Labelling – IOB encoding is o  outside a chunk .\n","sequence labelling  Sequence Labelling – IOB encoding is o  outside a chunk .\n","labelling  B  beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .\n","sequence labelling  B  beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .\n","labelling  Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .\n","sequence labelling  Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .\n","labelling  For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .\n","sequence labelling  For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .\n","labelling  Sequence Labelling – IOB encoding is also known as bio encoding .\n","sequence labelling  Sequence Labelling – IOB encoding is also known as bio encoding .\n","labelling  Sequence Labelling – IOB encoding .\n","sequence labelling  Sequence Labelling – IOB encoding .\n","feature extraction  Feature extraction performed if necessary .\n","sequence labelling task  Classification is sequence labelling task – .\n","labelling  Classification is sequence labelling task – .\n","sequence labelling  Classification is sequence labelling task – .\n","simple classifiers  So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt\n","named entity recognition  Named Entity Recognition Part 2 is advnlp week 5\n","entity recognition  Named Entity Recognition Part 2 is advnlp week 5\n","entity recognition part  Named Entity Recognition Part 2 is advnlp week 5\n","named entity  Named Entity Recognition Part 2 is advnlp week 5\n","large language models  NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .\n","language models  NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .\n","entity lookup lists  Rule-based is heuristics , entity lookup lists ( gazeteers ) .\n","supervised ml  Rule-based is varying degrees of inclusion of supervised ml .\n","training data  Generative models are model joint probability distributions from training data .\n","word embeddings  Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .\n","embeddings  Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .\n","discriminative models  Examples of discriminative models are the Maximum Entropy ( MEMM ) and the CRF .\n","discriminative models  Discriminative models is . .\n","unknown words  Include features that help with unknown words ( e.g . word shape ) .\n","training data  For CRF , a large set of predictive “ feature rules ” are generated from training data ( e.g . presence of wi in a gazetteer ) .\n","training data  When applied to training data for each step ( word ) , rule scores are aggregated for each rule and weighted , then summed to give the score for that step ( i.e . a weight exists for each global feature ) .\n","neural models  For Neural Models , vanilla rnn and gru have also been used .\n","embeddings  NNs allow word , char or other embeddings to be used ( or generated ) .\n","other embeddings  NNs allow word , char or other embeddings to be used ( or generated ) .\n","neural models  Neural Models are sota in 2021 ) .\n","labelling  Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .\n","sequence labelling  Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .\n","word embeddings  End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .\n","embeddings  End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .\n","embeddings  For Ma and Hovy ( 2016 ) , a char representation for each word is generated from a cnn ( 30 filters of width 3 ) based on char embeddings .\n","word embeddings  Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .\n","embeddings  Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .\n","ner task  CRF shows tags from PoS task , NER task uses same config ( except for initial LR )\n","embeddings  Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .\n","structured prediction  Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .\n","embeddings  Wang et al . ( 2021 ) is automatic selection of embeddings for tasks using neural architecture search .\n","better word representations  It generates better word representations .\n","word representations  It generates better word representations .\n","embeddings  Wang et al . ( 2021 ) is different combinations of embeddings are assessed by task accuracy .\n","embeddings  For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .\n","character embeddings  For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .\n","embeddings  The sets of embeddings used for tasks were quite variable .\n","semantic sequence tasks  The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .\n","embeddings  The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .\n","fasttext  The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .\n","embeddings  For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .\n","character embeddings  For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .\n","nlp tasks  Large pre - trained language models have achieved success in many NLP tasks , including NER .\n","many nlp tasks  Large pre - trained language models have achieved success in many NLP tasks , including NER .\n","language models  Large pre - trained language models have achieved success in many NLP tasks , including NER .\n","word representations  For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .\n","embeddings  For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .\n","bidirectional language modelling task  Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .\n","language modelling  Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .\n","named entity recognition  Week 5 lecture summary is named entity recognition .\n","entity recognition  Week 5 lecture summary is named entity recognition .\n","named entity  Week 5 lecture summary is named entity recognition .\n","labelling  Week 5 lecture summary is ne types , labelling , evaluation and features\n","supervised training  Next time for supervised training will be covered .\n","efficient labelling  Next time more efficient labelling will be covered .\n","labelling  Next time more efficient labelling will be covered .\n"]}]},{"cell_type":"code","source":["#the sentences with KWs and KPs\n","a=\"\"\n","for sens in sentencesforquestions:\n","  print(sens[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Th38pd9kzfTZ","executionInfo":{"status":"ok","timestamp":1661866544618,"user_tz":-60,"elapsed":28,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"a92eea60-361c-4377-eb34-fd0670af813a"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":[" Named Entity Recognition is advnlp week 5\n"," Named Entity Recognition is advnlp week 5\n"," Named Entity Recognition is advnlp week 5\n"," Previously distributional semantics was covered .\n"," Previously probabilistic language models was covered .\n"," Previously probabilistic language models was covered .\n"," Previously n - gram modelling , perplexity and generalization was covered .\n"," Previously neural language models was covered .\n"," Previously neural language models was covered .\n"," Previously word embeddings was covered .\n"," Previously word embeddings was covered .\n"," Previously dimensionality reduction , neural language models , word2vec , glov was covered .\n"," Previously dimensionality reduction , neural language models , word2vec , glov was covered .\n"," Week 5 overview is named entity recognition .\n"," Week 5 overview is named entity recognition .\n"," Week 5 overview is named entity recognition .\n"," Week 5 overview is ne types , labelling , evaluation and features\n"," NLP Tasks are natural language generation .\n"," NLP Tasks are natural language generation .\n"," NLP Tasks are chatbots , automatic content creation .\n"," NLP Tasks is summarisation .\n"," NLP Tasks are question answering .\n"," NLP Tasks are question answering .\n"," NLP Tasks are machine translation .\n"," NLP Tasks are machine translation .\n"," NLP Tasks are text , speech or any “ language ” translation ( e.g . q & a ) .\n"," NLP Tasks are text classification ( sequence labelling ) .\n"," NLP Tasks are text classification ( sequence labelling ) .\n"," NLP Tasks are text classification ( sequence labelling ) .\n"," NLP Tasks are text classification ( sequence labelling ) .\n"," NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n"," NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n"," NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n"," NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n"," NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .\n"," Sentiment analysis , intent extraction .\n"," Sentiment analysis , intent extraction .\n"," NLP Tasks are language modelling and similarity .\n"," NLP Tasks are language modelling and similarity .\n"," NLP Tasks can be applied to most tasks .\n"," NLP Tasks .\n"," Named Entity Recognition is assigning labels to a sequence of variables .\n"," Named Entity Recognition is assigning labels to a sequence of variables .\n"," Named Entity Recognition is assigning labels to a sequence of variables .\n"," Named Entity Recognition is the detection and classification of named entities in a text .\n"," Named Entity Recognition is the detection and classification of named entities in a text .\n"," Named Entity Recognition is the detection and classification of named entities in a text .\n"," A named entity is anything which can be referred to with a proper name e.g . , “ Boris Johnson ” , “ Pizza Hut ” , “ Brighton ” , but may also include dates , times , prices and more .\n"," Named Entity Recognition is often multi - word phrases .\n"," Named Entity Recognition is often multi - word phrases .\n"," Named Entity Recognition is often multi - word phrases .\n"," Named Entity Recognition is often multi - word phrases .\n"," Named Entity Recognition is semantic structured prediction . . .\n"," Named Entity Recognition is semantic structured prediction . . .\n"," Named Entity Recognition is semantic structured prediction . . .\n"," Named Entity Recognition is semantic structured prediction . . .\n"," Named Entity Recognition is semantic structured prediction . . .\n"," NER is the basis for downstream NLP tasks .\n"," NER is the basis for downstream NLP tasks .\n"," Why Named Entity Recognition ? It is sentiment or intent regarding entities .\n"," Why Named Entity Recognition ? It is sentiment or intent regarding entities .\n"," Why Named Entity Recognition ? It is sentiment or intent regarding entities .\n"," Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n"," Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n"," Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n"," Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .\n"," Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .\n"," Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .\n"," Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .\n"," Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n"," Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n"," Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n"," Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .\n"," Why Named Entity Recognition ? It is google / bing infobox .\n"," Why Named Entity Recognition ? It is google / bing infobox .\n"," Why Named Entity Recognition ? It is google / bing infobox .\n"," Why Named Entity Recognition ? It is competitive / product intelligence . . .\n"," Why Named Entity Recognition ? It is competitive / product intelligence . . .\n"," Why Named Entity Recognition ? It is competitive / product intelligence . . .\n"," Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .\n"," Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .\n"," Types of Named Entity is temporal expressions and numerical expressions are often included .\n"," Which entity type set might be most useful ? Types of Named EntityDifficulties : .\n"," Which entity type set might be most useful ? Types of Named EntityDifficulties : .\n"," Types of Named Entity is two types of ambiguity : boundary and type .\n"," Types of Named Entity is boundary detection ( e.g . the new york times ) – a harder problem than pos tagging .\n"," Types of Named Entity is two types of type ambiguity : entity - noun , entity - entity .\n"," Types of Named Entity is variation , even with reliable text sources ( e.g . united , utd , utd .\n"," Types of Named Entity )\n"," Sequence Labelling – IOB encoding is sequence labelling – iob encodingi  inside a chunk .\n"," Sequence Labelling – IOB encoding is sequence labelling – iob encodingi  inside a chunk .\n"," Sequence Labelling – IOB encoding is o  outside a chunk .\n"," Sequence Labelling – IOB encoding is o  outside a chunk .\n"," B  beginning a chunkSequence Labelling – IOB encodingI  inside a chunk .\n"," B  beginning a chunkSequence Labelling – IOB encodingI  inside a chunk .\n"," B  beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .\n"," B  beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .\n"," Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .\n"," Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .\n"," For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .\n"," For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .\n"," Sequence Labelling – IOB encoding is also known as bio encoding .\n"," Sequence Labelling – IOB encoding is also known as bio encoding .\n"," Sequence Labelling – IOB encoding .\n"," Sequence Labelling – IOB encoding .\n"," Feature extraction performed if necessary .\n"," Classification is sequence labelling task – .\n"," Classification is sequence labelling task – .\n"," Classification is sequence labelling task – .\n"," So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt\n"," Named Entity Recognition Part 2 is advnlp week 5\n"," Named Entity Recognition Part 2 is advnlp week 5\n"," Named Entity Recognition Part 2 is advnlp week 5\n"," Named Entity Recognition Part 2 is advnlp week 5\n"," NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .\n"," NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .\n"," Rule-based is heuristics , entity lookup lists ( gazeteers ) .\n"," Rule-based is varying degrees of inclusion of supervised ml .\n"," Generative models are model joint probability distributions from training data .\n"," Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .\n"," Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .\n"," Examples of discriminative models are the Maximum Entropy ( MEMM ) and the CRF .\n"," Discriminative models is . .\n"," Include features that help with unknown words ( e.g . word shape ) .\n"," For CRF , a large set of predictive “ feature rules ” are generated from training data ( e.g . presence of wi in a gazetteer ) .\n"," When applied to training data for each step ( word ) , rule scores are aggregated for each rule and weighted , then summed to give the score for that step ( i.e . a weight exists for each global feature ) .\n"," For Neural Models , vanilla rnn and gru have also been used .\n"," NNs allow word , char or other embeddings to be used ( or generated ) .\n"," NNs allow word , char or other embeddings to be used ( or generated ) .\n"," Neural Models are sota in 2021 ) .\n"," Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .\n"," Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .\n"," End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .\n"," End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .\n"," For Ma and Hovy ( 2016 ) , a char representation for each word is generated from a cnn ( 30 filters of width 3 ) based on char embeddings .\n"," Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .\n"," Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .\n"," CRF shows tags from PoS task , NER task uses same config ( except for initial LR )\n"," Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .\n"," Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .\n"," Wang et al . ( 2021 ) is automatic selection of embeddings for tasks using neural architecture search .\n"," It generates better word representations .\n"," It generates better word representations .\n"," Wang et al . ( 2021 ) is different combinations of embeddings are assessed by task accuracy .\n"," For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .\n"," For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .\n"," The sets of embeddings used for tasks were quite variable .\n"," The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .\n"," The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .\n"," The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .\n"," For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .\n"," For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .\n"," Large pre - trained language models have achieved success in many NLP tasks , including NER .\n"," Large pre - trained language models have achieved success in many NLP tasks , including NER .\n"," Large pre - trained language models have achieved success in many NLP tasks , including NER .\n"," For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .\n"," For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .\n"," Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .\n"," Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .\n"," Week 5 lecture summary is named entity recognition .\n"," Week 5 lecture summary is named entity recognition .\n"," Week 5 lecture summary is named entity recognition .\n"," Week 5 lecture summary is ne types , labelling , evaluation and features\n"," Next time for supervised training will be covered .\n"," Next time more efficient labelling will be covered .\n"," Next time more efficient labelling will be covered .\n"]}]},{"cell_type":"code","source":["sentencesforquestions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJ8aBAUuV_65","executionInfo":{"status":"ok","timestamp":1661866544618,"user_tz":-60,"elapsed":18,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"c426f784-05f7-4170-b702-a65839764d19"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(' Named Entity Recognition is advnlp week 5', 'named entity recognition'),\n"," (' Named Entity Recognition is advnlp week 5', 'entity recognition'),\n"," (' Named Entity Recognition is advnlp week 5', 'named entity'),\n"," (' Previously distributional semantics was covered .',\n","  'distributional semantics'),\n"," (' Previously probabilistic language models was covered .',\n","  'probabilistic language models'),\n"," (' Previously probabilistic language models was covered .',\n","  'language models'),\n"," (' Previously n - gram modelling , perplexity and generalization was covered .',\n","  'gram modelling'),\n"," (' Previously neural language models was covered .',\n","  'neural language models'),\n"," (' Previously neural language models was covered .', 'language models'),\n"," (' Previously word embeddings was covered .', 'word embeddings'),\n"," (' Previously word embeddings was covered .', 'embeddings'),\n"," (' Previously dimensionality reduction , neural language models , word2vec , glov was covered .',\n","  'neural language models'),\n"," (' Previously dimensionality reduction , neural language models , word2vec , glov was covered .',\n","  'language models'),\n"," (' Week 5 overview is named entity recognition .',\n","  'named entity recognition'),\n"," (' Week 5 overview is named entity recognition .', 'entity recognition'),\n"," (' Week 5 overview is named entity recognition .', 'named entity'),\n"," (' Week 5 overview is ne types , labelling , evaluation and features',\n","  'labelling'),\n"," (' NLP Tasks are natural language generation .', 'nlp tasks'),\n"," (' NLP Tasks are natural language generation .',\n","  'natural language generation'),\n"," (' NLP Tasks are chatbots , automatic content creation .', 'nlp tasks'),\n"," (' NLP Tasks is summarisation .', 'nlp tasks'),\n"," (' NLP Tasks are question answering .', 'nlp tasks'),\n"," (' NLP Tasks are question answering .', 'question answering'),\n"," (' NLP Tasks are machine translation .', 'nlp tasks'),\n"," (' NLP Tasks are machine translation .', 'machine translation'),\n"," (' NLP Tasks are text , speech or any “ language ” translation ( e.g . q & a ) .',\n","  'nlp tasks'),\n"," (' NLP Tasks are text classification ( sequence labelling ) .', 'nlp tasks'),\n"," (' NLP Tasks are text classification ( sequence labelling ) .',\n","  'text classification'),\n"," (' NLP Tasks are text classification ( sequence labelling ) .', 'labelling'),\n"," (' NLP Tasks are text classification ( sequence labelling ) .',\n","  'sequence labelling'),\n"," (' NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .',\n","  'named entity recognition'),\n"," (' NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .',\n","  'entity recognition'),\n"," (' NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .',\n","  'nlp tasks'),\n"," (' NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .',\n","  'named entity'),\n"," (' NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .',\n","  'event extraction'),\n"," (' Sentiment analysis , intent extraction .', 'sentiment analysis'),\n"," (' Sentiment analysis , intent extraction .', 'intent extraction'),\n"," (' NLP Tasks are language modelling and similarity .', 'nlp tasks'),\n"," (' NLP Tasks are language modelling and similarity .', 'language modelling'),\n"," (' NLP Tasks can be applied to most tasks .', 'nlp tasks'),\n"," (' NLP Tasks .', 'nlp tasks'),\n"," (' Named Entity Recognition is assigning labels to a sequence of variables .',\n","  'named entity recognition'),\n"," (' Named Entity Recognition is assigning labels to a sequence of variables .',\n","  'entity recognition'),\n"," (' Named Entity Recognition is assigning labels to a sequence of variables .',\n","  'named entity'),\n"," (' Named Entity Recognition is the detection and classification of named entities in a text .',\n","  'named entity recognition'),\n"," (' Named Entity Recognition is the detection and classification of named entities in a text .',\n","  'entity recognition'),\n"," (' Named Entity Recognition is the detection and classification of named entities in a text .',\n","  'named entity'),\n"," (' A named entity is anything which can be referred to with a proper name e.g . , “ Boris Johnson ” , “ Pizza Hut ” , “ Brighton ” , but may also include dates , times , prices and more .',\n","  'named entity'),\n"," (' Named Entity Recognition is often multi - word phrases .',\n","  'named entity recognition'),\n"," (' Named Entity Recognition is often multi - word phrases .',\n","  'entity recognition'),\n"," (' Named Entity Recognition is often multi - word phrases .', 'named entity'),\n"," (' Named Entity Recognition is often multi - word phrases .', 'word phrases'),\n"," (' Named Entity Recognition is semantic structured prediction . . .',\n","  'named entity recognition'),\n"," (' Named Entity Recognition is semantic structured prediction . . .',\n","  'entity recognition'),\n"," (' Named Entity Recognition is semantic structured prediction . . .',\n","  'named entity'),\n"," (' Named Entity Recognition is semantic structured prediction . . .',\n","  'semantic structured prediction'),\n"," (' Named Entity Recognition is semantic structured prediction . . .',\n","  'structured prediction'),\n"," (' NER is the basis for downstream NLP tasks .', 'nlp tasks'),\n"," (' NER is the basis for downstream NLP tasks .', 'downstream nlp tasks'),\n"," (' Why Named Entity Recognition ? It is sentiment or intent regarding entities .',\n","  'named entity recognition'),\n"," (' Why Named Entity Recognition ? It is sentiment or intent regarding entities .',\n","  'entity recognition'),\n"," (' Why Named Entity Recognition ? It is sentiment or intent regarding entities .',\n","  'named entity'),\n"," (' Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .',\n","  'named entity recognition'),\n"," (' Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .',\n","  'entity recognition'),\n"," (' Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .',\n","  'named entity'),\n"," (' Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .',\n","  'relation extraction'),\n"," (' Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .',\n","  'named entity recognition'),\n"," (' Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .',\n","  'entity recognition'),\n"," (' Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .',\n","  'named entity'),\n"," (' Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .',\n","  'named entity recognition'),\n"," (' Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .',\n","  'entity recognition'),\n"," (' Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .',\n","  'named entity'),\n"," (' Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .',\n","  'question answering'),\n"," (' Why Named Entity Recognition ? It is google / bing infobox .',\n","  'named entity recognition'),\n"," (' Why Named Entity Recognition ? It is google / bing infobox .',\n","  'entity recognition'),\n"," (' Why Named Entity Recognition ? It is google / bing infobox .',\n","  'named entity'),\n"," (' Why Named Entity Recognition ? It is competitive / product intelligence . . .',\n","  'named entity recognition'),\n"," (' Why Named Entity Recognition ? It is competitive / product intelligence . . .',\n","  'entity recognition'),\n"," (' Why Named Entity Recognition ? It is competitive / product intelligence . . .',\n","  'named entity'),\n"," (' Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .',\n","  'named entity'),\n"," (' Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .',\n","  'named entitythe'),\n"," (' Types of Named Entity is temporal expressions and numerical expressions are often included .',\n","  'named entity'),\n"," (' Which entity type set might be most useful ? Types of Named EntityDifficulties : .',\n","  'named entity'),\n"," (' Which entity type set might be most useful ? Types of Named EntityDifficulties : .',\n","  'named entitydifficulties'),\n"," (' Types of Named Entity is two types of ambiguity : boundary and type .',\n","  'named entity'),\n"," (' Types of Named Entity is boundary detection ( e.g . the new york times ) – a harder problem than pos tagging .',\n","  'named entity'),\n"," (' Types of Named Entity is two types of type ambiguity : entity - noun , entity - entity .',\n","  'named entity'),\n"," (' Types of Named Entity is variation , even with reliable text sources ( e.g . united , utd , utd .',\n","  'named entity'),\n"," (' Types of Named Entity )', 'named entity'),\n"," (' Sequence Labelling – IOB encoding is sequence labelling – iob encodingi \\uf0e0 inside a chunk .',\n","  'labelling'),\n"," (' Sequence Labelling – IOB encoding is sequence labelling – iob encodingi \\uf0e0 inside a chunk .',\n","  'sequence labelling'),\n"," (' Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk .',\n","  'labelling'),\n"," (' Sequence Labelling – IOB encoding is o \\uf0e0 outside a chunk .',\n","  'sequence labelling'),\n"," (' B \\uf0e0 beginning a chunkSequence Labelling – IOB encodingI \\uf0e0 inside a chunk .',\n","  'labelling'),\n"," (' B \\uf0e0 beginning a chunkSequence Labelling – IOB encodingI \\uf0e0 inside a chunk .',\n","  'sequence labelling'),\n"," (' B \\uf0e0 beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .',\n","  'labelling'),\n"," (' B \\uf0e0 beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .',\n","  'sequence labelling'),\n"," (' Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .',\n","  'labelling'),\n"," (' Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .',\n","  'sequence labelling'),\n"," (' For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .',\n","  'labelling'),\n"," (' For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .',\n","  'sequence labelling'),\n"," (' Sequence Labelling – IOB encoding is also known as bio encoding .',\n","  'labelling'),\n"," (' Sequence Labelling – IOB encoding is also known as bio encoding .',\n","  'sequence labelling'),\n"," (' Sequence Labelling – IOB encoding .', 'labelling'),\n"," (' Sequence Labelling – IOB encoding .', 'sequence labelling'),\n"," (' Feature extraction performed if necessary .', 'feature extraction'),\n"," (' Classification is sequence labelling task – .', 'sequence labelling task'),\n"," (' Classification is sequence labelling task – .', 'labelling'),\n"," (' Classification is sequence labelling task – .', 'sequence labelling'),\n"," (' So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt',\n","  'simple classifiers'),\n"," (' Named Entity Recognition Part 2 is advnlp week 5',\n","  'named entity recognition'),\n"," (' Named Entity Recognition Part 2 is advnlp week 5', 'entity recognition'),\n"," (' Named Entity Recognition Part 2 is advnlp week 5',\n","  'entity recognition part'),\n"," (' Named Entity Recognition Part 2 is advnlp week 5', 'named entity'),\n"," (' NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .',\n","  'large language models'),\n"," (' NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .',\n","  'language models'),\n"," (' Rule-based is heuristics , entity lookup lists ( gazeteers ) .',\n","  'entity lookup lists'),\n"," (' Rule-based is varying degrees of inclusion of supervised ml .',\n","  'supervised ml'),\n"," (' Generative models are model joint probability distributions from training data .',\n","  'training data'),\n"," (' Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .',\n","  'word embeddings'),\n"," (' Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .',\n","  'embeddings'),\n"," (' Examples of discriminative models are the Maximum Entropy ( MEMM ) and the CRF .',\n","  'discriminative models'),\n"," (' Discriminative models is . .', 'discriminative models'),\n"," (' Include features that help with unknown words ( e.g . word shape ) .',\n","  'unknown words'),\n"," (' For CRF , a large set of predictive “ feature rules ” are generated from training data ( e.g . presence of wi in a gazetteer ) .',\n","  'training data'),\n"," (' When applied to training data for each step ( word ) , rule scores are aggregated for each rule and weighted , then summed to give the score for that step ( i.e . a weight exists for each global feature ) .',\n","  'training data'),\n"," (' For Neural Models , vanilla rnn and gru have also been used .',\n","  'neural models'),\n"," (' NNs allow word , char or other embeddings to be used ( or generated ) .',\n","  'embeddings'),\n"," (' NNs allow word , char or other embeddings to be used ( or generated ) .',\n","  'other embeddings'),\n"," (' Neural Models are sota in 2021 ) .', 'neural models'),\n"," (' Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .',\n","  'labelling'),\n"," (' Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .',\n","  'sequence labelling'),\n"," (' End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .',\n","  'word embeddings'),\n"," (' End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .',\n","  'embeddings'),\n"," (' For Ma and Hovy ( 2016 ) , a char representation for each word is generated from a cnn ( 30 filters of width 3 ) based on char embeddings .',\n","  'embeddings'),\n"," (' Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .',\n","  'word embeddings'),\n"," (' Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .',\n","  'embeddings'),\n"," (' CRF shows tags from PoS task , NER task uses same config ( except for initial LR )',\n","  'ner task'),\n"," (' Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .',\n","  'embeddings'),\n"," (' Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .',\n","  'structured prediction'),\n"," (' Wang et al . ( 2021 ) is automatic selection of embeddings for tasks using neural architecture search .',\n","  'embeddings'),\n"," (' It generates better word representations .',\n","  'better word representations'),\n"," (' It generates better word representations .', 'word representations'),\n"," (' Wang et al . ( 2021 ) is different combinations of embeddings are assessed by task accuracy .',\n","  'embeddings'),\n"," (' For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .',\n","  'embeddings'),\n"," (' For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .',\n","  'character embeddings'),\n"," (' The sets of embeddings used for tasks were quite variable .',\n","  'embeddings'),\n"," (' The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .',\n","  'semantic sequence tasks'),\n"," (' The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .',\n","  'embeddings'),\n"," (' The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .',\n","  'fasttext'),\n"," (' For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .',\n","  'embeddings'),\n"," (' For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .',\n","  'character embeddings'),\n"," (' Large pre - trained language models have achieved success in many NLP tasks , including NER .',\n","  'nlp tasks'),\n"," (' Large pre - trained language models have achieved success in many NLP tasks , including NER .',\n","  'many nlp tasks'),\n"," (' Large pre - trained language models have achieved success in many NLP tasks , including NER .',\n","  'language models'),\n"," (' For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .',\n","  'word representations'),\n"," (' For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .',\n","  'embeddings'),\n"," (' Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .',\n","  'bidirectional language modelling task'),\n"," (' Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .',\n","  'language modelling'),\n"," (' Week 5 lecture summary is named entity recognition .',\n","  'named entity recognition'),\n"," (' Week 5 lecture summary is named entity recognition .',\n","  'entity recognition'),\n"," (' Week 5 lecture summary is named entity recognition .', 'named entity'),\n"," (' Week 5 lecture summary is ne types , labelling , evaluation and features',\n","  'labelling'),\n"," (' Next time for supervised training will be covered .',\n","  'supervised training'),\n"," (' Next time more efficient labelling will be covered .',\n","  'efficient labelling'),\n"," (' Next time more efficient labelling will be covered .', 'labelling')]"]},"metadata":{},"execution_count":77}]},{"cell_type":"markdown","source":["# QG"],"metadata":{"id":"P2WLXX6nBCFG"}},{"cell_type":"code","source":["len(sentencesforquestions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEQKeMNjVqiz","executionInfo":{"status":"ok","timestamp":1661866544619,"user_tz":-60,"elapsed":13,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"d570e745-9114-4762-fc4a-5572fd43d2d8"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["166"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["#model is installed\n","from transformers import AutoModelWithLMHead, AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n","model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-question-generation-ap\")\n","\n","def get_question(answer, context, max_length=64):\n","  input_text = \"answer: %s  context: %s </s>\" % (answer, context)\n","  features = tokenizer([input_text], return_tensors='pt')\n","\n","  output = model.generate(input_ids=features['input_ids'], \n","               attention_mask=features['attention_mask'],\n","               max_length=max_length)\n","\n","  return tokenizer.decode(output[0])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246,"referenced_widgets":["d14a3576947345ab88457bb5b58f3176","05c60ff716184db9a2caa91c787a31a6","df99bfdd606b405f830c59aecb887dd1","8ffbc8798b534c199dd3b2890a34ff98","0f0b48588745464a91a9c85b1ad5c537","af14d8f175e446528c12b43431aff16a","02d198c01cba4fe3a4c4105a7105c758","d14e1491588d4377af223213e08246d1","2cb038a7b187422fbe77293b82c0cc8c","fe86d7d814b04e5fb403c9d7d4f455ff","2caf0928b5b14cd99cf54c1fd60357f8","ebf1afc50eae4fc285735405c8d0f4bc","074d315d90e1497f8910e42911025476","8780426a3ee840acb1f8184875937d0e","f08cea0d09544870819c5e5505719e56","62fb13ab19034282b80b6c163f55b26f","68ad1ed380ff413badc564b7daac38de","8ccdc31f960d4590979d782a8ce7728a","1f669e3adca744f58ae8b253ddd4b1c7","8836f048cd004a3a9b7196a6d810083a","fb1755dd3bfa4c548526a2aa4c73e632","4e24475b57934338a1280007536d3f4e","49517b4053814cfa9646e6ac60bc116f","35084566f8144300b29c24c2ec5c0c65","680e8266bd2e4a2ab392d59b4cd5eeb6","dbfd8d5d630640ab871f3ab8303aba82","9ae3a61864c949e499a6dda21e300f44","b65d674b138a4b5888bf78ef227c0253","027c6a2518d14b99afeaf5de90ca7a05","c24a2e4e015141c89053074bd34f20af","81aa561f26c54861a78c1f0414a41e5f","cdf27c92b6c444ffb3632be55dba2403","4bcabc6d47104ea6833f6e647f3acb2a","c4557bb1aae74e94907fbf79c9c6fa2b","adf934ecc676477e9982a4d6e9eee171","d39e56cdd6d9432c90facb60ec8ddc7a","ff571841dd45439b8dff4aac68dd2e7b","d1cefef4da10418db54d2cb6e57a0121","0e84260fe28d40a591d68cac3e0cf984","04da800b0b754eaf8b19b782ff6145ac","e0b281ce86c74f9a8249effa3d3bcd13","90a69f945c814233aa0b19b204dc2a22","2e501479807145788b74394c33667d47","23e870ba8c324d54a7b5066b62f33cda","9b29c2d6d32c443193d6ca8563bd5a1a","19632bc10ed649c7942f62c3f92cbc02","814dae56d503400aad540dcc3526c054","42a8be2e583846a68fd3ac2937eb9511","87896d6c618e4dc590e20013cb0bc812","1fa395043b9343a882854722b63bced9","2e79d97a57774c8a8b5e17d2f07d999d","eab285c52a494ba9b0dfb272c0f99575","d961652312584c739ccf316024e2e620","4d38a960ee1647038a703eed7de54d92","78a02627b28641b18d048fbed75f15ed"]},"id":"OHKQnjUJV-p8","executionInfo":{"status":"ok","timestamp":1661866595360,"user_tz":-60,"elapsed":50745,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"8c821857-61ad-4b5b-eb43-64513e567f35"},"execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14a3576947345ab88457bb5b58f3176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebf1afc50eae4fc285735405c8d0f4bc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading spiece.model:   0%|          | 0.00/773k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49517b4053814cfa9646e6ac60bc116f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4557bb1aae74e94907fbf79c9c6fa2b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n","The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n","The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b29c2d6d32c443193d6ca8563bd5a1a"}},"metadata":{}}]},{"cell_type":"code","source":["#QG \n","a=0\n","for i in range(len(sentencesforquestions)):\n","  a+=1\n","  context = sentencesforquestions[i][0]\n","  answer = sentencesforquestions[i][1]\n","  print(\"context:\",context,\" answer: \",answer )\n","  print(get_question(answer, context))\n","  print(\"\\n\")\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPXdsSp1WFMX","executionInfo":{"status":"ok","timestamp":1661866884952,"user_tz":-60,"elapsed":289595,"user":{"displayName":"Kağan Uzgören","userId":"17466733233946920531"}},"outputId":"72c5872e-b129-4033-e307-2f67e6c2d914"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["context:  Named Entity Recognition is advnlp week 5  answer:  named entity recognition\n","<pad> question: What is advnlp week 5?</s>\n","\n","\n","context:  Named Entity Recognition is advnlp week 5  answer:  entity recognition\n","<pad> question: What is the name of the advnlp week 5?</s>\n","\n","\n","context:  Named Entity Recognition is advnlp week 5  answer:  named entity\n","<pad> question: What type of entity recognition is advnlp week 5?</s>\n","\n","\n","context:  Previously distributional semantics was covered .  answer:  distributional semantics\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously probabilistic language models was covered .  answer:  probabilistic language models\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously probabilistic language models was covered .  answer:  language models\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously n - gram modelling , perplexity and generalization was covered .  answer:  gram modelling\n","<pad> question: What was previously covered in terms of n - gram modelling?</s>\n","\n","\n","context:  Previously neural language models was covered .  answer:  neural language models\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously neural language models was covered .  answer:  language models\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously word embeddings was covered .  answer:  word embeddings\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously word embeddings was covered .  answer:  embeddings\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously dimensionality reduction , neural language models , word2vec , glov was covered .  answer:  neural language models\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Previously dimensionality reduction , neural language models , word2vec , glov was covered .  answer:  language models\n","<pad> question: What was previously covered?</s>\n","\n","\n","context:  Week 5 overview is named entity recognition .  answer:  named entity recognition\n","<pad> question: What is the name of the week 5 overview?</s>\n","\n","\n","context:  Week 5 overview is named entity recognition .  answer:  entity recognition\n","<pad> question: What is the name of the overview for Week 5?</s>\n","\n","\n","context:  Week 5 overview is named entity recognition .  answer:  named entity\n","<pad> question: What is the name of the entity that is recognized in Week 5?</s>\n","\n","\n","context:  Week 5 overview is ne types , labelling , evaluation and features  answer:  labelling\n","<pad> question: What is one of the topics covered in Week 5?</s>\n","\n","\n","context:  NLP Tasks are natural language generation .  answer:  nlp tasks\n","<pad> question: What are natural language generation tasks?</s>\n","\n","\n","context:  NLP Tasks are natural language generation .  answer:  natural language generation\n","<pad> question: What are NLP Tasks?</s>\n","\n","\n","context:  NLP Tasks are chatbots , automatic content creation .  answer:  nlp tasks\n","<pad> question: What are chatbots?</s>\n","\n","\n","context:  NLP Tasks is summarisation .  answer:  nlp tasks\n","<pad> question: What is the term for summarisation?</s>\n","\n","\n","context:  NLP Tasks are question answering .  answer:  nlp tasks\n","<pad> question: What are question answering?</s>\n","\n","\n","context:  NLP Tasks are question answering .  answer:  question answering\n","<pad> question: What are NLP Tasks?</s>\n","\n","\n","context:  NLP Tasks are machine translation .  answer:  nlp tasks\n","<pad> question: What are machine translation tasks?</s>\n","\n","\n","context:  NLP Tasks are machine translation .  answer:  machine translation\n","<pad> question: What are NLP Tasks?</s>\n","\n","\n","context:  NLP Tasks are text , speech or any “ language ” translation ( e.g . q & a ) .  answer:  nlp tasks\n","<pad> question: What are text, speech or any \" language translation\"?</s>\n","\n","\n","context:  NLP Tasks are text classification ( sequence labelling ) .  answer:  nlp tasks\n","<pad> question: What are text classification tasks?</s>\n","\n","\n","context:  NLP Tasks are text classification ( sequence labelling ) .  answer:  text classification\n","<pad> question: What are NLP Tasks?</s>\n","\n","\n","context:  NLP Tasks are text classification ( sequence labelling ) .  answer:  labelling\n","<pad> question: What is another term for sequence classification?</s>\n","\n","\n","context:  NLP Tasks are text classification ( sequence labelling ) .  answer:  sequence labelling\n","<pad> question: What is another name for text classification?</s>\n","\n","\n","context:  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .  answer:  named entity recognition\n","<pad> question: What is a semantic term for NLP?</s>\n","\n","\n","context:  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .  answer:  entity recognition\n","<pad> question: What is a semantic term for NLP?</s>\n","\n","\n","context:  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .  answer:  nlp tasks\n","<pad> question: What is part of speech?</s>\n","\n","\n","context:  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .  answer:  named entity\n","<pad> question: What type of recognition is used in NLP?</s>\n","\n","\n","context:  NLP Tasks are part of speech ( synactic ) , named entity recognition ( semantic ) and event extraction .  answer:  event extraction\n","<pad> question: What is a part of NLP Tasks?</s>\n","\n","\n","context:  Sentiment analysis , intent extraction .  answer:  sentiment analysis\n","<pad> question: What is the term for sentiment analysis?</s>\n","\n","\n","context:  Sentiment analysis , intent extraction .  answer:  intent extraction\n","<pad> question: What is another term for sentiment analysis?</s>\n","\n","\n","context:  NLP Tasks are language modelling and similarity .  answer:  nlp tasks\n","<pad> question: What are NLP tasks?</s>\n","\n","\n","context:  NLP Tasks are language modelling and similarity .  answer:  language modelling\n","<pad> question: What are NLP Tasks?</s>\n","\n","\n","context:  NLP Tasks can be applied to most tasks .  answer:  nlp tasks\n","<pad> question: What can be applied to most tasks?</s>\n","\n","\n","context:  NLP Tasks .  answer:  nlp tasks\n","<pad> question: What are NLP Tasks?</s>\n","\n","\n","context:  Named Entity Recognition is assigning labels to a sequence of variables .  answer:  named entity recognition\n","<pad> question: What is the process of assigning labels to a sequence of variables?</s>\n","\n","\n","context:  Named Entity Recognition is assigning labels to a sequence of variables .  answer:  entity recognition\n","<pad> question: What is the process of assigning labels to a sequence of variables?</s>\n","\n","\n","context:  Named Entity Recognition is assigning labels to a sequence of variables .  answer:  named entity\n","<pad> question: What is the term for assigning labels to a sequence of variables?</s>\n","\n","\n","context:  Named Entity Recognition is the detection and classification of named entities in a text .  answer:  named entity recognition\n","<pad> question: What is the detection and classification of named entities in a text?</s>\n","\n","\n","context:  Named Entity Recognition is the detection and classification of named entities in a text .  answer:  entity recognition\n","<pad> question: What is the detection and classification of named entities in a text?</s>\n","\n","\n","context:  Named Entity Recognition is the detection and classification of named entities in a text .  answer:  named entity\n","<pad> question: Named Entity Recognition is the detection and classification of what in a text?</s>\n","\n","\n","context:  A named entity is anything which can be referred to with a proper name e.g . , “ Boris Johnson ” , “ Pizza Hut ” , “ Brighton ” , but may also include dates , times , prices and more .  answer:  named entity\n","<pad> question: What is anything that can be referred to with a proper name?</s>\n","\n","\n","context:  Named Entity Recognition is often multi - word phrases .  answer:  named entity recognition\n","<pad> question: What is a multi - word phrase?</s>\n","\n","\n","context:  Named Entity Recognition is often multi - word phrases .  answer:  entity recognition\n","<pad> question: What is a multi - word phrase?</s>\n","\n","\n","context:  Named Entity Recognition is often multi - word phrases .  answer:  named entity\n","<pad> question: What type of recognition is often used in multi - word phrases?</s>\n","\n","\n","context:  Named Entity Recognition is often multi - word phrases .  answer:  word phrases\n","<pad> question: Named Entity Recognition is often multi - what?</s>\n","\n","\n","context:  Named Entity Recognition is semantic structured prediction . . .  answer:  named entity recognition\n","<pad> question: What is a semantic structured prediction?</s>\n","\n","\n","context:  Named Entity Recognition is semantic structured prediction . . .  answer:  entity recognition\n","<pad> question: What is a semantic structured prediction?</s>\n","\n","\n","context:  Named Entity Recognition is semantic structured prediction . . .  answer:  named entity\n","<pad> question: What type of entity recognition is used?</s>\n","\n","\n","context:  Named Entity Recognition is semantic structured prediction . . .  answer:  semantic structured prediction\n","<pad> question: What is Named Entity Recognition?</s>\n","\n","\n","context:  Named Entity Recognition is semantic structured prediction . . .  answer:  structured prediction\n","<pad> question: What is Named Entity Recognition?</s>\n","\n","\n","context:  NER is the basis for downstream NLP tasks .  answer:  nlp tasks\n","<pad> question: What is the basis for downstream NLP tasks?</s>\n","\n","\n","context:  NER is the basis for downstream NLP tasks .  answer:  downstream nlp tasks\n","<pad> question: What is NER the basis for?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is sentiment or intent regarding entities .  answer:  named entity recognition\n","<pad> question: What is it called when there is sentiment or intent regarding entities?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is sentiment or intent regarding entities .  answer:  entity recognition\n","<pad> question: What is the term for sentiment or intent regarding entities?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is sentiment or intent regarding entities .  answer:  named entity\n","<pad> question: What is the term for sentiment or intent regarding entities?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .  answer:  named entity recognition\n","<pad> question: What is the name for the relationship between entities in fact / relation extraction?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .  answer:  entity recognition\n","<pad> question: What is the name for the relationship between entities?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .  answer:  named entity\n","<pad> question: What is recognition of a relationship between entities?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is the relation between entities in fact / relation extraction .  answer:  relation extraction\n","<pad> question: What is the term for the relationship between entities?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .  answer:  named entity recognition\n","<pad> question: What is entity - linking?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .  answer:  entity recognition\n","<pad> question: What is the name for entity linking?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is entity - linking ( co - ref resolution ) and kbp .  answer:  named entity\n","<pad> question: What is entity linking?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .  answer:  named entity recognition\n","<pad> question: What is the term for a search that involves asking questions about an entity?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .  answer:  entity recognition\n","<pad> question: What is gkg?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .  answer:  named entity\n","<pad> question: What is the term for informed search?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is entity - informed search ( gkg ) and question answering regarding an entity .  answer:  question answering\n","<pad> question: What is the purpose of Named Entity Recognition?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is google / bing infobox .  answer:  named entity recognition\n","<pad> question: What is the name of the search engine that allows you to search for a specific entity?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is google / bing infobox .  answer:  entity recognition\n","<pad> question: What is the name of the search engine?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is google / bing infobox .  answer:  named entity\n","<pad> question: What is the name of the entity that is recognized by google?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is competitive / product intelligence . . .  answer:  named entity recognition\n","<pad> question: What is the name of the type of recognition that is used to identify products?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is competitive / product intelligence . . .  answer:  entity recognition\n","<pad> question: What is the name of the entity that is used to identify a product?</s>\n","\n","\n","context:  Why Named Entity Recognition ? It is competitive / product intelligence . . .  answer:  named entity\n","<pad> question: What type of entity recognition is used?</s>\n","\n","\n","context:  Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .  answer:  named entity\n","<pad> question: What type of entity is the most popular NER benchmark?</s>\n","\n","\n","context:  Types of Named EntityThe most popular NER benchmark , CoNLL-2003 , includes only these 4 entity types .  answer:  named entitythe\n","<pad> question: What type of entity is the most popular NER benchmark?</s>\n","\n","\n","context:  Types of Named Entity is temporal expressions and numerical expressions are often included .  answer:  named entity\n","<pad> question: What type of entity is temporal expressions?</s>\n","\n","\n","context:  Which entity type set might be most useful ? Types of Named EntityDifficulties : .  answer:  named entity\n","<pad> question: What type of entity is most useful?</s>\n","\n","\n","context:  Which entity type set might be most useful ? Types of Named EntityDifficulties : .  answer:  named entitydifficulties\n","<pad> question: What type of entity type is most useful?</s>\n","\n","\n","context:  Types of Named Entity is two types of ambiguity : boundary and type .  answer:  named entity\n","<pad> question: What is the name of the type of ambiguity?</s>\n","\n","\n","context:  Types of Named Entity is boundary detection ( e.g . the new york times ) – a harder problem than pos tagging .  answer:  named entity\n","<pad> question: What type of entity is boundary detection?</s>\n","\n","\n","context:  Types of Named Entity is two types of type ambiguity : entity - noun , entity - entity .  answer:  named entity\n","<pad> question: What type of entity is ambiguity?</s>\n","\n","\n","context:  Types of Named Entity is variation , even with reliable text sources ( e.g . united , utd , utd .  answer:  named entity\n","<pad> question: What type of entity is variation?</s>\n","\n","\n","context:  Types of Named Entity )  answer:  named entity\n","<pad> question: What type of entity is a named entity?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding is sequence labelling – iob encodingi  inside a chunk .  answer:  labelling\n","<pad> question: What is IOB encoding?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding is sequence labelling – iob encodingi  inside a chunk .  answer:  sequence labelling\n","<pad> question: What is IOB encoding?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding is o  outside a chunk .  answer:  labelling\n","<pad> question: What is the encoding of a sequence called?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding is o  outside a chunk .  answer:  sequence labelling\n","<pad> question: What is it called when IOB encoding is o <unk> outside a chunk?</s>\n","\n","\n","context:  B  beginning a chunkSequence Labelling – IOB encodingI  inside a chunk .  answer:  labelling\n","<pad> question: What is the name of the IOB encoding?</s>\n","\n","\n","context:  B  beginning a chunkSequence Labelling – IOB encodingI  inside a chunk .  answer:  sequence labelling\n","<pad> question: What is IOB encodingI <unk> inside a chunk?</s>\n","\n","\n","context:  B  beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .  answer:  labelling\n","<pad> question: What is the problem of starting a chunkTurn span identification into?</s>\n","\n","\n","context:  B  beginning a chunkTurn span identification into a sequence labelling problem using IOB encoding – 1 tag per token .  answer:  sequence labelling\n","<pad> question: What is the problem of starting a chunkTurn span identification?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .  answer:  labelling\n","<pad> question: What is the process of identifying entities with the correct type and exact position?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding typically entities should be identified with the correct type and exact position .  answer:  sequence labelling\n","<pad> question: What is the term for IOB encoding?</s>\n","\n","\n","context:  For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .  answer:  labelling\n","<pad> question: What is the term for Sequence?</s>\n","\n","\n","context:  For Sequence Labelling – IOB encoding , sometimes multiple scores are included including partial overlaps .  answer:  sequence labelling\n","<pad> question: What is the term for IOB encoding?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding is also known as bio encoding .  answer:  labelling\n","<pad> question: What is the name of the sequence that is used to identify a sequence?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding is also known as bio encoding .  answer:  sequence labelling\n","<pad> question: What is another name for IOB encoding?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding .  answer:  labelling\n","<pad> question: What is the term for IOB encoding?</s>\n","\n","\n","context:  Sequence Labelling – IOB encoding .  answer:  sequence labelling\n","<pad> question: What is the term for IOB encoding?</s>\n","\n","\n","context:  Feature extraction performed if necessary .  answer:  feature extraction\n","<pad> question: What is performed if necessary?</s>\n","\n","\n","context:  Classification is sequence labelling task – .  answer:  sequence labelling task\n","<pad> question: What is classification?</s>\n","\n","\n","context:  Classification is sequence labelling task – .  answer:  labelling\n","<pad> question: What is the task of sequence?</s>\n","\n","\n","context:  Classification is sequence labelling task – .  answer:  sequence labelling\n","<pad> question: What is the classification task?</s>\n","\n","\n","context:  So this might rule out simple classifiers such as Naïve Bayes and Logistic Regression / MaxEnt  answer:  simple classifiers\n","<pad> question: What type of classifiers might be excluded?</s>\n","\n","\n","context:  Named Entity Recognition Part 2 is advnlp week 5  answer:  named entity recognition\n","<pad> question: What is part 2 of advnlp week 5?</s>\n","\n","\n","context:  Named Entity Recognition Part 2 is advnlp week 5  answer:  entity recognition\n","<pad> question: What is part 2 of advnlp week 5?</s>\n","\n","\n","context:  Named Entity Recognition Part 2 is advnlp week 5  answer:  entity recognition part\n","<pad> question: What is part 2 of advnlp week 5?</s>\n","\n","\n","context:  Named Entity Recognition Part 2 is advnlp week 5  answer:  named entity\n","<pad> question: What is part 2 of advnlp week 5?</s>\n","\n","\n","context:  NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .  answer:  large language models\n","<pad> question: What type of models are NER Approaches?</s>\n","\n","\n","context:  NER Approaches is ( usually ) transformer / attention - based large language models , fine - tuned ( e.g . bert ) .  answer:  language models\n","<pad> question: What is NER Approaches based on?</s>\n","\n","\n","context:  Rule-based is heuristics , entity lookup lists ( gazeteers ) .  answer:  entity lookup lists\n","<pad> question: What are gazeteers?</s>\n","\n","\n","context:  Rule-based is varying degrees of inclusion of supervised ml .  answer:  supervised ml\n","<pad> question: What is a rule-based inclusion of?</s>\n","\n","\n","context:  Generative models are model joint probability distributions from training data .  answer:  training data\n","<pad> question: What do Generative models derive from?</s>\n","\n","\n","context:  Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .  answer:  word embeddings\n","<pad> question: What is one feature that can help with sparsity?</s>\n","\n","\n","context:  Leverage multiple ( potentially interdependent ) features ( e.g . word shape , presence in gazeteer , PoS , word embeddings ) which can improve prediction and help with sparsity .  answer:  embeddings\n","<pad> question: What is a feature that can help with sparsity?</s>\n","\n","\n","context:  Examples of discriminative models are the Maximum Entropy ( MEMM ) and the CRF .  answer:  discriminative models\n","<pad> question: What is the Maximum Entropy?</s>\n","\n","\n","context:  Discriminative models is . .  answer:  discriminative models\n","<pad> question: What is a term for a model that is not discriminatory?</s>\n","\n","\n","context:  Include features that help with unknown words ( e.g . word shape ) .  answer:  unknown words\n","<pad> question: What do features help with?</s>\n","\n","\n","context:  For CRF , a large set of predictive “ feature rules ” are generated from training data ( e.g . presence of wi in a gazetteer ) .  answer:  training data\n","<pad> question: What are the predictive features generated from?</s>\n","\n","\n","context:  When applied to training data for each step ( word ) , rule scores are aggregated for each rule and weighted , then summed to give the score for that step ( i.e . a weight exists for each global feature ) .  answer:  training data\n","<pad> question: What is applied to each step?</s>\n","\n","\n","context:  For Neural Models , vanilla rnn and gru have also been used .  answer:  neural models\n","<pad> question: What type of models have been used?</s>\n","\n","\n","context:  NNs allow word , char or other embeddings to be used ( or generated ) .  answer:  embeddings\n","<pad> question: What do NNs allow to be used?</s>\n","\n","\n","context:  NNs allow word , char or other embeddings to be used ( or generated ) .  answer:  other embeddings\n","<pad> question: What do NNs allow to be used?</s>\n","\n","\n","context:  Neural Models are sota in 2021 ) .  answer:  neural models\n","<pad> question: What is the term for a model that is not a neural model?</s>\n","\n","\n","context:  Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .  answer:  labelling\n","<pad> question: What is done via bi - directional lstm - cnns - crf?</s>\n","\n","\n","context:  Ma and Hovy ( 2016 ) is end - to - end sequence labelling via bi - directional lstm - cnns - crf .  answer:  sequence labelling\n","<pad> question: What is done via bi - directional lstm - cnns - crf?</s>\n","\n","\n","context:  End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .  answer:  word embeddings\n","<pad> question: What is the only external data that is not present in the end to end system?</s>\n","\n","\n","context:  End - to - end – no external data ( apart from word embeddings ) – this is a big deal as previous systems were feature - engineered .  answer:  embeddings\n","<pad> question: What is the only external data that is not present in the end to end system?</s>\n","\n","\n","context:  For Ma and Hovy ( 2016 ) , a char representation for each word is generated from a cnn ( 30 filters of width 3 ) based on char embeddings .  answer:  embeddings\n","<pad> question: What is the char representation for each word based on?</s>\n","\n","\n","context:  Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .  answer:  word embeddings\n","<pad> question: What is fine tuned during training?</s>\n","\n","\n","context:  Word embeddings are fine - tuned during trainingArchitecture diagrams from paper .  answer:  embeddings\n","<pad> question: What is fine tuned during training?</s>\n","\n","\n","context:  CRF shows tags from PoS task , NER task uses same config ( except for initial LR )  answer:  ner task\n","<pad> question: What uses the same config as CRF?</s>\n","\n","\n","context:  Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .  answer:  embeddings\n","<pad> question: What is the term for automated concatenation of?</s>\n","\n","\n","context:  Wang et al . ( 2021 ) is automated concatenation of embeddings for structured prediction .  answer:  structured prediction\n","<pad> question: What is the purpose of the automated concatenation of embeddings?</s>\n","\n","\n","context:  Wang et al . ( 2021 ) is automatic selection of embeddings for tasks using neural architecture search .  answer:  embeddings\n","<pad> question: What is the automatic selection of for tasks using neural architecture search?</s>\n","\n","\n","context:  It generates better word representations .  answer:  better word representations\n","<pad> question: What does it generate?</s>\n","\n","\n","context:  It generates better word representations .  answer:  word representations\n","<pad> question: What does it generate better?</s>\n","\n","\n","context:  Wang et al . ( 2021 ) is different combinations of embeddings are assessed by task accuracy .  answer:  embeddings\n","<pad> question: What is assessed by task accuracy?</s>\n","\n","\n","context:  For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .  answer:  embeddings\n","<pad> question: What is selected from a combination of contextualised, non - contextualised and character embeddings?</s>\n","\n","\n","context:  For Wang et al . ( 2021 ) , embeddings are selected from a combination of contextualised , non - contextualised and character embeddings .  answer:  character embeddings\n","<pad> question: What is the combination of contextualised, non - contextualised and?</s>\n","\n","\n","context:  The sets of embeddings used for tasks were quite variable .  answer:  embeddings\n","<pad> question: What sets of data were used for tasks?</s>\n","\n","\n","context:  The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .  answer:  semantic sequence tasks\n","<pad> question: What type of tasks were contextualised embeddings the most consistent for?</s>\n","\n","\n","context:  The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .  answer:  embeddings\n","<pad> question: What was the most consistent for semantic sequence tasks?</s>\n","\n","\n","context:  The most consistent for semantic sequence tasks ( inc . NER ) were contextualised embeddings : multi - lingual Flair ( 87 % ) and ELMo ( 80 % ) and non - contextualised fastText / GloVe ( 80 % ) .  answer:  fasttext\n","<pad> question: What embedding was non contextualised?</s>\n","\n","\n","context:  For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .  answer:  embeddings\n","<pad> question: What was selected 40 % of the time?</s>\n","\n","\n","context:  For Wang et al . ( 2021 ) , character embeddings were only selected 40 % of the time – contextualised are sufficient ? . .  answer:  character embeddings\n","<pad> question: What was selected 40 % of the time?</s>\n","\n","\n","context:  Large pre - trained language models have achieved success in many NLP tasks , including NER .  answer:  nlp tasks\n","<pad> question: Large pre trained language models have achieved success in what?</s>\n","\n","\n","context:  Large pre - trained language models have achieved success in many NLP tasks , including NER .  answer:  many nlp tasks\n","<pad> question: Large pre trained language models have achieved success in what?</s>\n","\n","\n","context:  Large pre - trained language models have achieved success in many NLP tasks , including NER .  answer:  language models\n","<pad> question: What type of model has been successful in many NLP tasks?</s>\n","\n","\n","context:  For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .  answer:  word representations\n","<pad> question: What are generated using sub - word input?</s>\n","\n","\n","context:  For Transformer-based LMs , contextualised word representations / embeddings are generated using sub - word input ( bpe in the case of bert ) .  answer:  embeddings\n","<pad> question: What is generated using sub - word input?</s>\n","\n","\n","context:  Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .  answer:  bidirectional language modelling task\n","<pad> question: What is the training task for elmo?</s>\n","\n","\n","context:  Transformer-based LMs are elmo ( peters et al . , 2018 ) 2 - layer bilstm trained on a bidirectional language modelling task .  answer:  language modelling\n","<pad> question: What task is elmo trained on?</s>\n","\n","\n","context:  Week 5 lecture summary is named entity recognition .  answer:  named entity recognition\n","<pad> question: What is the title of the week 5 lecture summary?</s>\n","\n","\n","context:  Week 5 lecture summary is named entity recognition .  answer:  entity recognition\n","<pad> question: What is the title of the week 5 lecture summary?</s>\n","\n","\n","context:  Week 5 lecture summary is named entity recognition .  answer:  named entity\n","<pad> question: What is the name of the entity that is recognized in Week 5 of the lecture?</s>\n","\n","\n","context:  Week 5 lecture summary is ne types , labelling , evaluation and features  answer:  labelling\n","<pad> question: What is one of the topics covered in the week 5 lecture summary?</s>\n","\n","\n","context:  Next time for supervised training will be covered .  answer:  supervised training\n","<pad> question: What will be covered next time?</s>\n","\n","\n","context:  Next time more efficient labelling will be covered .  answer:  efficient labelling\n","<pad> question: What will be covered next time?</s>\n","\n","\n","context:  Next time more efficient labelling will be covered .  answer:  labelling\n","<pad> question: What will be covered next time?</s>\n","\n","\n","166\n"]}]}],"metadata":{"colab":{"name":"modifieddiss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNqMGxx7D9uO7hWK163npbx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"fb6924b9a7784c8dba5d214b39d7daa8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b14fc14442646189fea6fbe98c7a4c8","IPY_MODEL_eb8ecafa1815458dadeef763442d14c5","IPY_MODEL_6b472530f19e4862a275747bf4b76390"],"layout":"IPY_MODEL_8e237cf5a2924b74a35610a103da0ab1"}},"2b14fc14442646189fea6fbe98c7a4c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8b8626fb61b45d397af0d55fffe61d0","placeholder":"​","style":"IPY_MODEL_63e342243353452b8a164a43e46fdacb","value":"Downloading: 100%"}},"eb8ecafa1815458dadeef763442d14c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80da96e838454ab8a6530f90ccb26e25","max":1175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2be845158895415487b7dda569af5295","value":1175}},"6b472530f19e4862a275747bf4b76390":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b31857607e84b56a7ab48731dcdd716","placeholder":"​","style":"IPY_MODEL_675325f87d04483dbbb62cf368fe0797","value":" 1.18k/1.18k [00:00&lt;00:00, 27.7kB/s]"}},"8e237cf5a2924b74a35610a103da0ab1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8b8626fb61b45d397af0d55fffe61d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e342243353452b8a164a43e46fdacb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80da96e838454ab8a6530f90ccb26e25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2be845158895415487b7dda569af5295":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b31857607e84b56a7ab48731dcdd716":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"675325f87d04483dbbb62cf368fe0797":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb55541efa5a4bbd84052e6304b34deb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a9c53969d6b46558edffb6d23a5dd05","IPY_MODEL_78dbfaeb2fc742f29cda6ebf57658997","IPY_MODEL_e72c12d7886e46f19d1d212900ea9317"],"layout":"IPY_MODEL_d8fe7892a4d44f66998344b529b19551"}},"4a9c53969d6b46558edffb6d23a5dd05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0436b17eed994263ada2d7ab040da88e","placeholder":"​","style":"IPY_MODEL_cc1774e3eb46406e837ed06a7c6be198","value":"Downloading: 100%"}},"78dbfaeb2fc742f29cda6ebf57658997":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_959407c5e3c94a28825fa4131a3cd7ef","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5cdd9f0f426446968054fa46d4795517","value":190}},"e72c12d7886e46f19d1d212900ea9317":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1a15caa321431e9c771e3efbbd08c5","placeholder":"​","style":"IPY_MODEL_992f4156728c4d9cb1c20742cb7481cd","value":" 190/190 [00:00&lt;00:00, 2.52kB/s]"}},"d8fe7892a4d44f66998344b529b19551":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0436b17eed994263ada2d7ab040da88e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc1774e3eb46406e837ed06a7c6be198":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"959407c5e3c94a28825fa4131a3cd7ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cdd9f0f426446968054fa46d4795517":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d1a15caa321431e9c771e3efbbd08c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"992f4156728c4d9cb1c20742cb7481cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14d6ddfb31314075bdfad0a9cb411113":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5001e678d6643538f649dba38e9697c","IPY_MODEL_12c1834f780f4d93a44010ded043b25b","IPY_MODEL_ea0540a0b5bd4703a84634475ab651a5"],"layout":"IPY_MODEL_50f0dae9da2a4add8bb2e76135c44104"}},"e5001e678d6643538f649dba38e9697c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83a55fc441c64fbab38d27536d5739ce","placeholder":"​","style":"IPY_MODEL_317b69d001e64897b237e1ff4e606330","value":"Downloading: 100%"}},"12c1834f780f4d93a44010ded043b25b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc041e1d7f5d4716b068fb2b31cdc1d9","max":10610,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e43cdb5dfcf84d33a891f4aa315be3b8","value":10610}},"ea0540a0b5bd4703a84634475ab651a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aec0670dca0f4420bfafc1f62f232c5a","placeholder":"​","style":"IPY_MODEL_9397aa6fc93040dca28419be5ab046ec","value":" 10.6k/10.6k [00:00&lt;00:00, 244kB/s]"}},"50f0dae9da2a4add8bb2e76135c44104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83a55fc441c64fbab38d27536d5739ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"317b69d001e64897b237e1ff4e606330":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc041e1d7f5d4716b068fb2b31cdc1d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e43cdb5dfcf84d33a891f4aa315be3b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aec0670dca0f4420bfafc1f62f232c5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9397aa6fc93040dca28419be5ab046ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b3076ec6ea041909014d7c58b4d2411":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d153c4c6db44e388969d2bbd4fcdbd7","IPY_MODEL_60c19dc28ac143a18f57f99364e5596e","IPY_MODEL_24aad48f541e471181b06904e8650aef"],"layout":"IPY_MODEL_1ac1035ee756436c95df1b3805ccf634"}},"6d153c4c6db44e388969d2bbd4fcdbd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bdbb40f82ed42cea78940db193cb045","placeholder":"​","style":"IPY_MODEL_075ba978358d4486a877641c8924040f","value":"Downloading: 100%"}},"60c19dc28ac143a18f57f99364e5596e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47d7c3fbfabd4ca8a312b22820fbb914","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d03852459104f8ebda97fb3786d5ed3","value":612}},"24aad48f541e471181b06904e8650aef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfcb9f5aee1f4de1ae52523f2313ed0c","placeholder":"​","style":"IPY_MODEL_ef91a4f94fb64e2eb8ab8968651d3c9c","value":" 612/612 [00:00&lt;00:00, 12.3kB/s]"}},"1ac1035ee756436c95df1b3805ccf634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bdbb40f82ed42cea78940db193cb045":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"075ba978358d4486a877641c8924040f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47d7c3fbfabd4ca8a312b22820fbb914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d03852459104f8ebda97fb3786d5ed3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfcb9f5aee1f4de1ae52523f2313ed0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef91a4f94fb64e2eb8ab8968651d3c9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a44c120e79f454094d861fe973b58ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49f897a6e2234abdad2049831051b9ca","IPY_MODEL_63cfd5bf0ef849698497f3605c549a60","IPY_MODEL_ba14ce90ae9542f3939875d0e46b4e71"],"layout":"IPY_MODEL_9f01fa9b54794218b6cf20d2ca7db361"}},"49f897a6e2234abdad2049831051b9ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6353c797931649c6aee18fb957408db9","placeholder":"​","style":"IPY_MODEL_7dd91d0512484b75bfd290ca9236a520","value":"Downloading: 100%"}},"63cfd5bf0ef849698497f3605c549a60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b1214ebf46c4eb0850e88545352a42d","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebbb022e00844172ac8f3099c5e11179","value":116}},"ba14ce90ae9542f3939875d0e46b4e71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9154b16974db4e9eaa34a12350734076","placeholder":"​","style":"IPY_MODEL_90b5392f862040c583ef5d9b382452f3","value":" 116/116 [00:00&lt;00:00, 3.04kB/s]"}},"9f01fa9b54794218b6cf20d2ca7db361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6353c797931649c6aee18fb957408db9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dd91d0512484b75bfd290ca9236a520":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b1214ebf46c4eb0850e88545352a42d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebbb022e00844172ac8f3099c5e11179":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9154b16974db4e9eaa34a12350734076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b5392f862040c583ef5d9b382452f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"235dd3efcf73455597466f586f70b573":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba656719d589470d8cbfdf3cdfa05e09","IPY_MODEL_84b55f8779cd46bbb5897f4ec9766e6b","IPY_MODEL_af5751b9d53045c29ff53050ecf7041f"],"layout":"IPY_MODEL_4207c498cb844c0bb208057abb63483a"}},"ba656719d589470d8cbfdf3cdfa05e09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2124a932c55a4ca9bae084055a3c8930","placeholder":"​","style":"IPY_MODEL_2692c01c71e541ea870dda62c825ef68","value":"Downloading: 100%"}},"84b55f8779cd46bbb5897f4ec9766e6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b1bd138df0c4c10bac94542679c500f","max":39265,"min":0,"orientation":"horizontal","style":"IPY_MODEL_017085682fa34006ac12e8d4751b82f0","value":39265}},"af5751b9d53045c29ff53050ecf7041f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b55b2a1ffd534220bb04f7f844a2dbba","placeholder":"​","style":"IPY_MODEL_1a9948b804e24add8bc976c665eac737","value":" 39.3k/39.3k [00:00&lt;00:00, 690kB/s]"}},"4207c498cb844c0bb208057abb63483a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2124a932c55a4ca9bae084055a3c8930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2692c01c71e541ea870dda62c825ef68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b1bd138df0c4c10bac94542679c500f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"017085682fa34006ac12e8d4751b82f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b55b2a1ffd534220bb04f7f844a2dbba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a9948b804e24add8bc976c665eac737":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2cda8aa16d44d24b3383c2066abd24f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52359158bfeb4d16958e35b8d27a4ee5","IPY_MODEL_ce6079a359544ea087c21a0bc3b7973f","IPY_MODEL_999f1c2e2ca04b46bb73c0dd9e165488"],"layout":"IPY_MODEL_10055895b81248c4ba07f66f70145355"}},"52359158bfeb4d16958e35b8d27a4ee5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d3c3dad30ee4418abc584f1a5f0dabc","placeholder":"​","style":"IPY_MODEL_9b973d84bd954771a57d9e7c4b3a48f7","value":"Downloading: 100%"}},"ce6079a359544ea087c21a0bc3b7973f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6388d3ace4f84cc9ad4cf6e0d108abdf","max":90888945,"min":0,"orientation":"horizontal","style":"IPY_MODEL_907067fb6b2141a19322b07094d134a4","value":90888945}},"999f1c2e2ca04b46bb73c0dd9e165488":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b4398de30964631ab12e87ded73b749","placeholder":"​","style":"IPY_MODEL_f3a80220192d41c7a8ba993bcd37ef66","value":" 90.9M/90.9M [00:03&lt;00:00, 24.1MB/s]"}},"10055895b81248c4ba07f66f70145355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d3c3dad30ee4418abc584f1a5f0dabc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b973d84bd954771a57d9e7c4b3a48f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6388d3ace4f84cc9ad4cf6e0d108abdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"907067fb6b2141a19322b07094d134a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b4398de30964631ab12e87ded73b749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3a80220192d41c7a8ba993bcd37ef66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89957df4522f426fbbb721764ef96e45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3d5546be64f44269938c7d3c8a4e0fc","IPY_MODEL_91d2c2b71bab4fcc8427296143be6b29","IPY_MODEL_a9fcd843c62b443dabe4b1f27f4fb035"],"layout":"IPY_MODEL_8748b88c9ffe484799a5492cb37b8854"}},"b3d5546be64f44269938c7d3c8a4e0fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce50ccabe20e4552ac62cc170a88546c","placeholder":"​","style":"IPY_MODEL_bec24d7c1b3c4fd29a1ed7ffe69f2825","value":"Downloading: 100%"}},"91d2c2b71bab4fcc8427296143be6b29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e2080929430444bb17e1ad2cba01d0e","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_425f7510af2a4ca08e4d22c7f3a4d0b3","value":53}},"a9fcd843c62b443dabe4b1f27f4fb035":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c649c7e81f17473d8bc2a7ff482cb5c3","placeholder":"​","style":"IPY_MODEL_9d2eaaf469c2435ca38de2b608034606","value":" 53.0/53.0 [00:00&lt;00:00, 1.34kB/s]"}},"8748b88c9ffe484799a5492cb37b8854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce50ccabe20e4552ac62cc170a88546c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec24d7c1b3c4fd29a1ed7ffe69f2825":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e2080929430444bb17e1ad2cba01d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"425f7510af2a4ca08e4d22c7f3a4d0b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c649c7e81f17473d8bc2a7ff482cb5c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d2eaaf469c2435ca38de2b608034606":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f97f4b1cd33c4a69803d5f852ea335b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9619ab168f3341e6b6760bdff41ba065","IPY_MODEL_d916a187217140a3a0c6bec2ce6a3745","IPY_MODEL_17ccc418f8b14531a3901a049b332a99"],"layout":"IPY_MODEL_0fed838faa8442a0b14bbc197f233d30"}},"9619ab168f3341e6b6760bdff41ba065":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d789547b7cd847d1ad1317c88826b29e","placeholder":"​","style":"IPY_MODEL_5d97a22f282442f181072aa1b0d350c8","value":"Downloading: 100%"}},"d916a187217140a3a0c6bec2ce6a3745":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a12adece3c7847cb85419697368a24b5","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1350291ee322460eb31f935b03e493c6","value":112}},"17ccc418f8b14531a3901a049b332a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b3d5fc8dcc8462dad527202a30da491","placeholder":"​","style":"IPY_MODEL_7ce495da3b9a48c891f26fe02320369b","value":" 112/112 [00:00&lt;00:00, 2.43kB/s]"}},"0fed838faa8442a0b14bbc197f233d30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d789547b7cd847d1ad1317c88826b29e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d97a22f282442f181072aa1b0d350c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a12adece3c7847cb85419697368a24b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1350291ee322460eb31f935b03e493c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b3d5fc8dcc8462dad527202a30da491":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ce495da3b9a48c891f26fe02320369b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09bad6cbdefd483ba36005ae08cec4d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b9def6b3f78443ea587bb6ae937ad24","IPY_MODEL_f72cc39609aa4c01ae5b8347fc49b99d","IPY_MODEL_6b5e3567c82a4550a736a10313ae3786"],"layout":"IPY_MODEL_4b17154a616f419e928bca2fa38bb494"}},"8b9def6b3f78443ea587bb6ae937ad24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b021dce5419f46138fd8d1a9117730cd","placeholder":"​","style":"IPY_MODEL_1dd6b29f1bee4f8bbcb703f70010be3c","value":"Downloading: 100%"}},"f72cc39609aa4c01ae5b8347fc49b99d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aaec3ce7ebc454297e7ef23f4ad3227","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f191d56f267d45a5aafcd6071a16ac56","value":466247}},"6b5e3567c82a4550a736a10313ae3786":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c64293537e341568d59dcb0d4546b15","placeholder":"​","style":"IPY_MODEL_1caa086fbaa945c6869f1188e7adacb3","value":" 466k/466k [00:00&lt;00:00, 1.17MB/s]"}},"4b17154a616f419e928bca2fa38bb494":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b021dce5419f46138fd8d1a9117730cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dd6b29f1bee4f8bbcb703f70010be3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6aaec3ce7ebc454297e7ef23f4ad3227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f191d56f267d45a5aafcd6071a16ac56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c64293537e341568d59dcb0d4546b15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1caa086fbaa945c6869f1188e7adacb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1adce2bfa2314181b21ccb1192285f95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_290ca991506e4fe19ae8f1462cffde61","IPY_MODEL_f1bbd6bc1a944a0d865a7009b6905474","IPY_MODEL_815d7cf1ac5c4616ab900dc84b9c0cdf"],"layout":"IPY_MODEL_a4992141459d4b69aeb7639785e63e60"}},"290ca991506e4fe19ae8f1462cffde61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e270e13901db4a9ba00af70df211d5fa","placeholder":"​","style":"IPY_MODEL_929791e47ac041f2a0e651be7e1390ae","value":"Downloading: 100%"}},"f1bbd6bc1a944a0d865a7009b6905474":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d314a87528a4fa1b231c2abd97a53f8","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0dac07275474a628ae04193232d848a","value":350}},"815d7cf1ac5c4616ab900dc84b9c0cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_595d6c743bc145b083df9f25713bd691","placeholder":"​","style":"IPY_MODEL_d1d06c7c0ebc41cc9b0d6467b8d492ab","value":" 350/350 [00:00&lt;00:00, 5.15kB/s]"}},"a4992141459d4b69aeb7639785e63e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e270e13901db4a9ba00af70df211d5fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929791e47ac041f2a0e651be7e1390ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d314a87528a4fa1b231c2abd97a53f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0dac07275474a628ae04193232d848a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"595d6c743bc145b083df9f25713bd691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1d06c7c0ebc41cc9b0d6467b8d492ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54eb351a91c94180958c0ae95d7173f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f531d79714f64219885de3fed80bd8ee","IPY_MODEL_3af84ff6a21e427ebf2c9b597511a99e","IPY_MODEL_fa3b8d6375dd4fe980fb0869101e1219"],"layout":"IPY_MODEL_8187a52010f9431a92a3c8b085f73544"}},"f531d79714f64219885de3fed80bd8ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01dd0d9c010a4a2eb58cea0abc2a9d37","placeholder":"​","style":"IPY_MODEL_83bdcd860c23414b99c4f28f51e0dead","value":"Downloading: 100%"}},"3af84ff6a21e427ebf2c9b597511a99e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aa9b753c17c42d4b4b6b295e9f3b118","max":13156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0670994dc2d342388c24ebba60ef8a6b","value":13156}},"fa3b8d6375dd4fe980fb0869101e1219":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cedd1907a459433eac9db82376e579ed","placeholder":"​","style":"IPY_MODEL_35d4a5870426420c8b4ef25eebbda2af","value":" 13.2k/13.2k [00:00&lt;00:00, 211kB/s]"}},"8187a52010f9431a92a3c8b085f73544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01dd0d9c010a4a2eb58cea0abc2a9d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83bdcd860c23414b99c4f28f51e0dead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8aa9b753c17c42d4b4b6b295e9f3b118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0670994dc2d342388c24ebba60ef8a6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cedd1907a459433eac9db82376e579ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35d4a5870426420c8b4ef25eebbda2af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9719f531e3134b179f62f5fb3f5e0feb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65a9351e11c54190b095c5908ed835c6","IPY_MODEL_96f898c708f843828c0652a82d05b8d3","IPY_MODEL_725cee007a634ad796c50c2d33fd770c"],"layout":"IPY_MODEL_e90d483f3a574d5ead3272f8ae8596de"}},"65a9351e11c54190b095c5908ed835c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24c6838015d04389a83111daf1ffb14f","placeholder":"​","style":"IPY_MODEL_9e1b711c584e4ecb9e10d3594a8d87db","value":"Downloading: 100%"}},"96f898c708f843828c0652a82d05b8d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_002c89b303ef40f5b6d8993dcc050c14","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_938dbc815fc3497f9f69f4b8d875c9e3","value":231508}},"725cee007a634ad796c50c2d33fd770c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_931b1525e2124d3dbbe9cf4d9629d1d1","placeholder":"​","style":"IPY_MODEL_7b5ff4e9fdbb4294829ca6e71df8d077","value":" 232k/232k [00:00&lt;00:00, 995kB/s]"}},"e90d483f3a574d5ead3272f8ae8596de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24c6838015d04389a83111daf1ffb14f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e1b711c584e4ecb9e10d3594a8d87db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"002c89b303ef40f5b6d8993dcc050c14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"938dbc815fc3497f9f69f4b8d875c9e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"931b1525e2124d3dbbe9cf4d9629d1d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b5ff4e9fdbb4294829ca6e71df8d077":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"113cc901e96b44a38b36e7293bdbca0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d939d5b4f82444379b6d763010872911","IPY_MODEL_cfe18c51539b4c22954e554806f7e266","IPY_MODEL_5f062d151beb4c20836ebd9af3a70cc0"],"layout":"IPY_MODEL_a94962686ef24a54ade31c0381c18f09"}},"d939d5b4f82444379b6d763010872911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96dbe97498e2457c90d50bb428ff879d","placeholder":"​","style":"IPY_MODEL_c1b626e183e9438b9f06238412c01b08","value":"Downloading: 100%"}},"cfe18c51539b4c22954e554806f7e266":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a76d75bbdbd244b698ff805c4b935749","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe4bf834359c4234b289a69b4285abf1","value":349}},"5f062d151beb4c20836ebd9af3a70cc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca882bc533934bd5a9dba6acdaa2e4ab","placeholder":"​","style":"IPY_MODEL_5be6f29fea3e453694ec6caf8804b03d","value":" 349/349 [00:00&lt;00:00, 7.87kB/s]"}},"a94962686ef24a54ade31c0381c18f09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96dbe97498e2457c90d50bb428ff879d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1b626e183e9438b9f06238412c01b08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a76d75bbdbd244b698ff805c4b935749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe4bf834359c4234b289a69b4285abf1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca882bc533934bd5a9dba6acdaa2e4ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5be6f29fea3e453694ec6caf8804b03d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbe3fc9613d6456a969b8b6c9fb7716d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e865fdc365c4d859c00862f7e6aa99d","IPY_MODEL_a058132c315847b5ad1597fa99414e3f","IPY_MODEL_087c75ae861d4827b3d08ab5da655a46"],"layout":"IPY_MODEL_8f5af00d6a4d4975a2578a4eb6630bcd"}},"9e865fdc365c4d859c00862f7e6aa99d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c53d3efab148439ca40595b4d4ac4508","placeholder":"​","style":"IPY_MODEL_a6d4f80769664b0a81011afa79bf28e4","value":"Downloading: 100%"}},"a058132c315847b5ad1597fa99414e3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1cbf6ac85f480291c695512b53b70e","max":1175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41dfdbcef8ca4ae2918847c53f64fe03","value":1175}},"087c75ae861d4827b3d08ab5da655a46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12088693939d4cb983e0b9f1c8fcfe32","placeholder":"​","style":"IPY_MODEL_60e403bcf3cf4e6a844e68fa38ab04c6","value":" 1.18k/1.18k [00:00&lt;00:00, 19.9kB/s]"}},"8f5af00d6a4d4975a2578a4eb6630bcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c53d3efab148439ca40595b4d4ac4508":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6d4f80769664b0a81011afa79bf28e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e1cbf6ac85f480291c695512b53b70e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41dfdbcef8ca4ae2918847c53f64fe03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12088693939d4cb983e0b9f1c8fcfe32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e403bcf3cf4e6a844e68fa38ab04c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"185aa29ba3ea40a99b75f4576368a65c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb569183a29d4efa93f67b2f650592eb","IPY_MODEL_795f21fa5ff646208338ba0f5c52ca01","IPY_MODEL_f15fbeb5950d4c44a6ef58a4129fd348"],"layout":"IPY_MODEL_3fd5f93c338040b48ab203af2f3aac95"}},"bb569183a29d4efa93f67b2f650592eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c02a50052c4c42d4aa4ec9e9c7217163","placeholder":"​","style":"IPY_MODEL_0412a5735c824342b5bcf8943d1a477f","value":"Downloading: 100%"}},"795f21fa5ff646208338ba0f5c52ca01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a5aeda40a1747e38e587214135ab9ce","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccd60cac10fd43de8ec62b0f2b41167e","value":190}},"f15fbeb5950d4c44a6ef58a4129fd348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72dab580e5ea4eccb9006812c775918c","placeholder":"​","style":"IPY_MODEL_790b6afa4ed048b78d1669db431b3777","value":" 190/190 [00:00&lt;00:00, 3.42kB/s]"}},"3fd5f93c338040b48ab203af2f3aac95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c02a50052c4c42d4aa4ec9e9c7217163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0412a5735c824342b5bcf8943d1a477f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a5aeda40a1747e38e587214135ab9ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccd60cac10fd43de8ec62b0f2b41167e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72dab580e5ea4eccb9006812c775918c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"790b6afa4ed048b78d1669db431b3777":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32ef281a732746d0a1144fe124404b25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a61a73ef0b964325840605e8aed77dc2","IPY_MODEL_15e5fcbb085b4a9990a142fe0c6542f3","IPY_MODEL_6fece2d1c0114e96a6df11288a34ae6b"],"layout":"IPY_MODEL_121fed69324e42169ffb7d89848d5cfa"}},"a61a73ef0b964325840605e8aed77dc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_989e435a65f5439684f5c49c39766738","placeholder":"​","style":"IPY_MODEL_8a3b6c954ec643e8a0aa31deec1479bc","value":"Downloading: 100%"}},"15e5fcbb085b4a9990a142fe0c6542f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8df6af8049a4929a2399baea360a9d2","max":10571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8a184e0ce024730ace21360a85a1b03","value":10571}},"6fece2d1c0114e96a6df11288a34ae6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dcc9588a5fa457dab37f75d901f7c4d","placeholder":"​","style":"IPY_MODEL_cc8922962ae74d9b976186d7e5403961","value":" 10.6k/10.6k [00:00&lt;00:00, 152kB/s]"}},"121fed69324e42169ffb7d89848d5cfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"989e435a65f5439684f5c49c39766738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a3b6c954ec643e8a0aa31deec1479bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8df6af8049a4929a2399baea360a9d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8a184e0ce024730ace21360a85a1b03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4dcc9588a5fa457dab37f75d901f7c4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc8922962ae74d9b976186d7e5403961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7522507849e0453b857d185ef20663dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a157748df764e55addfbd2944409df5","IPY_MODEL_a438071a59eb454482fbc1c42f30c50c","IPY_MODEL_a6454593b16a4e249789181cd2c69ce5"],"layout":"IPY_MODEL_f2adbff0b44942a982c86f9ec695c74f"}},"1a157748df764e55addfbd2944409df5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8db4424f657498493afe606859ce646","placeholder":"​","style":"IPY_MODEL_88df111373134365af9e9e837f770be6","value":"Downloading: 100%"}},"a438071a59eb454482fbc1c42f30c50c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5af6b0ad1a7b40b6bf69945ba866810d","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab82e55dc69a4683964f63a4447df5e3","value":571}},"a6454593b16a4e249789181cd2c69ce5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_902778ab46e841d5971470751e54c90b","placeholder":"​","style":"IPY_MODEL_38ae83c360154b679c65536502b62e02","value":" 571/571 [00:00&lt;00:00, 11.1kB/s]"}},"f2adbff0b44942a982c86f9ec695c74f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8db4424f657498493afe606859ce646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88df111373134365af9e9e837f770be6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5af6b0ad1a7b40b6bf69945ba866810d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab82e55dc69a4683964f63a4447df5e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"902778ab46e841d5971470751e54c90b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38ae83c360154b679c65536502b62e02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55c86bf2d7e147dba57863e00e7e5767":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f9442fa9b24403d977b66aa534b2754","IPY_MODEL_209168365f354a9fa256c9889bc2c1ad","IPY_MODEL_22d6434b305a466f89e5c0cc85a3388e"],"layout":"IPY_MODEL_d6b4aaeca1d24a25b4b007ffb4583b4a"}},"0f9442fa9b24403d977b66aa534b2754":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b65268a3e2d44908fb0cd80f1e6bf05","placeholder":"​","style":"IPY_MODEL_0a5206f25cdf442c9377a25fb24b7df0","value":"Downloading: 100%"}},"209168365f354a9fa256c9889bc2c1ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6585e6c11bcb4987841aedf9ee18e19b","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1641174bcc9b4abfaf92bf0a5fb7a162","value":116}},"22d6434b305a466f89e5c0cc85a3388e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61127e02f19140f2af451114f1dded92","placeholder":"​","style":"IPY_MODEL_ae575f6267d746be923e02138f7159d1","value":" 116/116 [00:00&lt;00:00, 3.07kB/s]"}},"d6b4aaeca1d24a25b4b007ffb4583b4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b65268a3e2d44908fb0cd80f1e6bf05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a5206f25cdf442c9377a25fb24b7df0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6585e6c11bcb4987841aedf9ee18e19b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1641174bcc9b4abfaf92bf0a5fb7a162":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61127e02f19140f2af451114f1dded92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae575f6267d746be923e02138f7159d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10dd178ebdbf4adcb671d71701841290":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c096c627f8945ca9da7192b37a5c2d8","IPY_MODEL_ab06c0f51c4145d6926ae64fda3289ef","IPY_MODEL_64e469e8a5f04d1289d316de9c930fd9"],"layout":"IPY_MODEL_84090c6f3f1546278a65bd7aee320177"}},"9c096c627f8945ca9da7192b37a5c2d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_642a87be8805485aae48442ababc49f8","placeholder":"​","style":"IPY_MODEL_9ab1ed26c35a4398951a235ff74bf8fd","value":"Downloading: 100%"}},"ab06c0f51c4145d6926ae64fda3289ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ad12ccecfba43ad969d2c30799a2f41","max":39265,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8db140ac8bf24b198f0a37aabfc7823f","value":39265}},"64e469e8a5f04d1289d316de9c930fd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afc7a746079241bcbd3e03f2d9544875","placeholder":"​","style":"IPY_MODEL_77f38c224d134133b6a7fa5a2e02c1dc","value":" 39.3k/39.3k [00:00&lt;00:00, 905kB/s]"}},"84090c6f3f1546278a65bd7aee320177":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642a87be8805485aae48442ababc49f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ab1ed26c35a4398951a235ff74bf8fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ad12ccecfba43ad969d2c30799a2f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8db140ac8bf24b198f0a37aabfc7823f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afc7a746079241bcbd3e03f2d9544875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77f38c224d134133b6a7fa5a2e02c1dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94aab0e1a9bb43d6800ea0ab6657ff5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb5cb2cdc29e401caf963e3add6d0cf0","IPY_MODEL_0b0e89848cf64c8287983e6d5caae058","IPY_MODEL_1d68d12ee4bb488eb7765e0d2957a75a"],"layout":"IPY_MODEL_cc1b018195a946a49f9e82c75f4603b2"}},"cb5cb2cdc29e401caf963e3add6d0cf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf12e062e52e407c85c05de2cd634c91","placeholder":"​","style":"IPY_MODEL_b7519f225c7541bea564db8dc8e52c5d","value":"Downloading: 100%"}},"0b0e89848cf64c8287983e6d5caae058":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a787868411c24456b3bb75b99c07d2ab","max":438011953,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2513cb7f7ebf4f0b8b51880cb106912d","value":438011953}},"1d68d12ee4bb488eb7765e0d2957a75a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3872f4d6711a4db89cd8cbec50dfdb41","placeholder":"​","style":"IPY_MODEL_343bdec5a3784c92ad5e7dbe2f227016","value":" 438M/438M [00:11&lt;00:00, 35.5MB/s]"}},"cc1b018195a946a49f9e82c75f4603b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf12e062e52e407c85c05de2cd634c91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7519f225c7541bea564db8dc8e52c5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a787868411c24456b3bb75b99c07d2ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2513cb7f7ebf4f0b8b51880cb106912d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3872f4d6711a4db89cd8cbec50dfdb41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"343bdec5a3784c92ad5e7dbe2f227016":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff6fa3be4b234b338311c839a7783834":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c05199d39c0453d86abca7049b4d1a3","IPY_MODEL_e2f3eb3170684de38a46e2e8e3eef45d","IPY_MODEL_13f983aa03a542fdb3f7eddd97a40d02"],"layout":"IPY_MODEL_35c997503c6949a8aa044e8eabacbb8e"}},"2c05199d39c0453d86abca7049b4d1a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d7153f6f00641d3b81b09ea2f2c16eb","placeholder":"​","style":"IPY_MODEL_60b1745d45154591b808aba19f3d9363","value":"Downloading: 100%"}},"e2f3eb3170684de38a46e2e8e3eef45d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecfde292f5664d47b9f68e014fbe1a49","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efc607ade7a34b35a538e0b68dbdff08","value":53}},"13f983aa03a542fdb3f7eddd97a40d02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d131190ed6604dc690e995c732bad162","placeholder":"​","style":"IPY_MODEL_77db5210f2fd4b8c8b07fb3361f7689d","value":" 53.0/53.0 [00:00&lt;00:00, 521B/s]"}},"35c997503c6949a8aa044e8eabacbb8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d7153f6f00641d3b81b09ea2f2c16eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60b1745d45154591b808aba19f3d9363":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecfde292f5664d47b9f68e014fbe1a49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc607ade7a34b35a538e0b68dbdff08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d131190ed6604dc690e995c732bad162":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77db5210f2fd4b8c8b07fb3361f7689d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90668ec3279c48b19cc91a748a56114f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f56fc87bf084110843b34e07685f2a6","IPY_MODEL_5f0584ac4e4d466e8f63339b8ea4b401","IPY_MODEL_ef66f90d020b45ceab1ff058f43a7bc8"],"layout":"IPY_MODEL_04ed87da142946b09f6c1401e9c4ed92"}},"7f56fc87bf084110843b34e07685f2a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ffa8fa7757f49fcb71244a0fae85b0b","placeholder":"​","style":"IPY_MODEL_e46e042035594f9a889b8ab674a6f2d7","value":"Downloading: 100%"}},"5f0584ac4e4d466e8f63339b8ea4b401":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75e9ff44625f4afe9a5c6ef6c6be29a4","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_690871cf95244626a222517bbd1c4cd1","value":239}},"ef66f90d020b45ceab1ff058f43a7bc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd5bf135705248f8b7d885eca30e138e","placeholder":"​","style":"IPY_MODEL_d63ffc0def7748a4bfae01ba3488c67d","value":" 239/239 [00:00&lt;00:00, 6.14kB/s]"}},"04ed87da142946b09f6c1401e9c4ed92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ffa8fa7757f49fcb71244a0fae85b0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e46e042035594f9a889b8ab674a6f2d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75e9ff44625f4afe9a5c6ef6c6be29a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"690871cf95244626a222517bbd1c4cd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd5bf135705248f8b7d885eca30e138e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d63ffc0def7748a4bfae01ba3488c67d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1859b0f242d0417c96cccdc6738f90e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a68f52b7c1b43caad8662ca4bf0b6eb","IPY_MODEL_5d095089c021462b8fa93cb7af1b02ce","IPY_MODEL_0dbec8e2f3ed46d8bc1a593dfdb4b39e"],"layout":"IPY_MODEL_89cadd032e3f4a989ca8486afe9ac033"}},"9a68f52b7c1b43caad8662ca4bf0b6eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18036f5b2c364e8f9a68de68efcb1423","placeholder":"​","style":"IPY_MODEL_9c061d9394094f9fbda3f4c8b4d7efe1","value":"Downloading: 100%"}},"5d095089c021462b8fa93cb7af1b02ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_995d4cdb68724f61ad12551457fd4484","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0057ebb9ca9b4de7a165440d97beb525","value":466021}},"0dbec8e2f3ed46d8bc1a593dfdb4b39e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df393f9c214a4d159b0062c160119600","placeholder":"​","style":"IPY_MODEL_5791c544ad594b5fa4c6ba116f51bfaf","value":" 466k/466k [00:00&lt;00:00, 1.09MB/s]"}},"89cadd032e3f4a989ca8486afe9ac033":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18036f5b2c364e8f9a68de68efcb1423":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c061d9394094f9fbda3f4c8b4d7efe1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"995d4cdb68724f61ad12551457fd4484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0057ebb9ca9b4de7a165440d97beb525":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df393f9c214a4d159b0062c160119600":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5791c544ad594b5fa4c6ba116f51bfaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4adb4ede55040a28cf2a6a5476172fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b56db3ea42df4558836c4ca7ba9bc6eb","IPY_MODEL_8fd1fce2fb0049538540fd18de29796b","IPY_MODEL_33c0130999b449f294c170c98b3350f5"],"layout":"IPY_MODEL_b60ea11d2a7441bb8d29fea48ec5aaa3"}},"b56db3ea42df4558836c4ca7ba9bc6eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73672e78bd1a4b5ba652cabe093a82d5","placeholder":"​","style":"IPY_MODEL_35120be898064f54a6f5388d44d2a2d0","value":"Downloading: 100%"}},"8fd1fce2fb0049538540fd18de29796b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_230f1a38cd4142f2ac7b600dcb92fa6d","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_035c21897720458ebb38d70cdd32e7bd","value":363}},"33c0130999b449f294c170c98b3350f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9f2d5e78e7f4311aed1f864e8f9cfbd","placeholder":"​","style":"IPY_MODEL_599baef74d40488b8f3018454c1ca87e","value":" 363/363 [00:00&lt;00:00, 4.68kB/s]"}},"b60ea11d2a7441bb8d29fea48ec5aaa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73672e78bd1a4b5ba652cabe093a82d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35120be898064f54a6f5388d44d2a2d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"230f1a38cd4142f2ac7b600dcb92fa6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"035c21897720458ebb38d70cdd32e7bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9f2d5e78e7f4311aed1f864e8f9cfbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"599baef74d40488b8f3018454c1ca87e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54e9482793054117aec511f50888de74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc2b9fb503484dd39fe5e805c54649bc","IPY_MODEL_2d6142a2a404446e855a3302bd7d5c2e","IPY_MODEL_1ad891beb54545c08bfa2f6120e8f835"],"layout":"IPY_MODEL_7cb012ccfe8841aab9f82db4fa8a5dbf"}},"dc2b9fb503484dd39fe5e805c54649bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af558d286fe1475e908a2eff2a89abd4","placeholder":"​","style":"IPY_MODEL_4041c9ea936a4c5da475f83f5e192b71","value":"Downloading: 100%"}},"2d6142a2a404446e855a3302bd7d5c2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0433b49a8f004d418efb3891aadcf438","max":13123,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46440e7ef24c487a97ce9498ffafaf75","value":13123}},"1ad891beb54545c08bfa2f6120e8f835":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bfee4732e854202bef3a8a7561e1e71","placeholder":"​","style":"IPY_MODEL_6b596cc65cdb4336a718d5042878ddc5","value":" 13.1k/13.1k [00:00&lt;00:00, 220kB/s]"}},"7cb012ccfe8841aab9f82db4fa8a5dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af558d286fe1475e908a2eff2a89abd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4041c9ea936a4c5da475f83f5e192b71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0433b49a8f004d418efb3891aadcf438":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46440e7ef24c487a97ce9498ffafaf75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bfee4732e854202bef3a8a7561e1e71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b596cc65cdb4336a718d5042878ddc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a788cca93c74eabb238ad9c2de01dc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0bd27c2a07846cb9a538ca568a5cd53","IPY_MODEL_878ff1eff7a14b08a6fbee388e4314d5","IPY_MODEL_1ee58314acea470091856200348789e8"],"layout":"IPY_MODEL_5531b8430e544b4ab4e0b877cd9754ee"}},"e0bd27c2a07846cb9a538ca568a5cd53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_469270d18f19426293583fb852c1b944","placeholder":"​","style":"IPY_MODEL_93558a67a92f493aabb58d1e36c6ee27","value":"Downloading: 100%"}},"878ff1eff7a14b08a6fbee388e4314d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e321f4b553d4a328d8c8c3d4104a083","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_599a2e15f8cb4610859a92f90cdbc4e9","value":231536}},"1ee58314acea470091856200348789e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08bb8a59bef74259be78cb2a4382aa79","placeholder":"​","style":"IPY_MODEL_52d209e79dc545e8bce09991d8877f2e","value":" 232k/232k [00:00&lt;00:00, 20.5kB/s]"}},"5531b8430e544b4ab4e0b877cd9754ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"469270d18f19426293583fb852c1b944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93558a67a92f493aabb58d1e36c6ee27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e321f4b553d4a328d8c8c3d4104a083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"599a2e15f8cb4610859a92f90cdbc4e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08bb8a59bef74259be78cb2a4382aa79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52d209e79dc545e8bce09991d8877f2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"294749c87a494a1bb3a4f9d993677c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_011618c3f28d42959d072025076b17bc","IPY_MODEL_933cfb4c3ee046ffa867711aacee847f","IPY_MODEL_21b16a0c9a064f6fa4a5667b6c1aa1b8"],"layout":"IPY_MODEL_f2acc566937a44e89fb1fbca7565e25f"}},"011618c3f28d42959d072025076b17bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85cc6d0571d94598a3a38dc1defc666c","placeholder":"​","style":"IPY_MODEL_4ea44ac8f2b44219b2000d5dea138402","value":"Downloading: 100%"}},"933cfb4c3ee046ffa867711aacee847f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b8519bdc7724540bb4602b166cc4310","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96e0995080664c2e97606ddc67106ed8","value":349}},"21b16a0c9a064f6fa4a5667b6c1aa1b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8c22de8be6845f9b73ea8f78d68bb23","placeholder":"​","style":"IPY_MODEL_d33d696cc1e24234882a330159f9183f","value":" 349/349 [00:00&lt;00:00, 7.22kB/s]"}},"f2acc566937a44e89fb1fbca7565e25f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85cc6d0571d94598a3a38dc1defc666c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ea44ac8f2b44219b2000d5dea138402":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b8519bdc7724540bb4602b166cc4310":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e0995080664c2e97606ddc67106ed8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8c22de8be6845f9b73ea8f78d68bb23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d33d696cc1e24234882a330159f9183f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d14a3576947345ab88457bb5b58f3176":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05c60ff716184db9a2caa91c787a31a6","IPY_MODEL_df99bfdd606b405f830c59aecb887dd1","IPY_MODEL_8ffbc8798b534c199dd3b2890a34ff98"],"layout":"IPY_MODEL_0f0b48588745464a91a9c85b1ad5c537"}},"05c60ff716184db9a2caa91c787a31a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af14d8f175e446528c12b43431aff16a","placeholder":"​","style":"IPY_MODEL_02d198c01cba4fe3a4c4105a7105c758","value":"Downloading tokenizer_config.json: 100%"}},"df99bfdd606b405f830c59aecb887dd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d14e1491588d4377af223213e08246d1","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cb038a7b187422fbe77293b82c0cc8c","value":25}},"8ffbc8798b534c199dd3b2890a34ff98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe86d7d814b04e5fb403c9d7d4f455ff","placeholder":"​","style":"IPY_MODEL_2caf0928b5b14cd99cf54c1fd60357f8","value":" 25.0/25.0 [00:00&lt;00:00, 601B/s]"}},"0f0b48588745464a91a9c85b1ad5c537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af14d8f175e446528c12b43431aff16a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02d198c01cba4fe3a4c4105a7105c758":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d14e1491588d4377af223213e08246d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cb038a7b187422fbe77293b82c0cc8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe86d7d814b04e5fb403c9d7d4f455ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2caf0928b5b14cd99cf54c1fd60357f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebf1afc50eae4fc285735405c8d0f4bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_074d315d90e1497f8910e42911025476","IPY_MODEL_8780426a3ee840acb1f8184875937d0e","IPY_MODEL_f08cea0d09544870819c5e5505719e56"],"layout":"IPY_MODEL_62fb13ab19034282b80b6c163f55b26f"}},"074d315d90e1497f8910e42911025476":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68ad1ed380ff413badc564b7daac38de","placeholder":"​","style":"IPY_MODEL_8ccdc31f960d4590979d782a8ce7728a","value":"Downloading config.json: 100%"}},"8780426a3ee840acb1f8184875937d0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f669e3adca744f58ae8b253ddd4b1c7","max":1230,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8836f048cd004a3a9b7196a6d810083a","value":1230}},"f08cea0d09544870819c5e5505719e56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb1755dd3bfa4c548526a2aa4c73e632","placeholder":"​","style":"IPY_MODEL_4e24475b57934338a1280007536d3f4e","value":" 1.20k/1.20k [00:00&lt;00:00, 23.9kB/s]"}},"62fb13ab19034282b80b6c163f55b26f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ad1ed380ff413badc564b7daac38de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ccdc31f960d4590979d782a8ce7728a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f669e3adca744f58ae8b253ddd4b1c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8836f048cd004a3a9b7196a6d810083a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb1755dd3bfa4c548526a2aa4c73e632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e24475b57934338a1280007536d3f4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49517b4053814cfa9646e6ac60bc116f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35084566f8144300b29c24c2ec5c0c65","IPY_MODEL_680e8266bd2e4a2ab392d59b4cd5eeb6","IPY_MODEL_dbfd8d5d630640ab871f3ab8303aba82"],"layout":"IPY_MODEL_9ae3a61864c949e499a6dda21e300f44"}},"35084566f8144300b29c24c2ec5c0c65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b65d674b138a4b5888bf78ef227c0253","placeholder":"​","style":"IPY_MODEL_027c6a2518d14b99afeaf5de90ca7a05","value":"Downloading spiece.model: 100%"}},"680e8266bd2e4a2ab392d59b4cd5eeb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c24a2e4e015141c89053074bd34f20af","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81aa561f26c54861a78c1f0414a41e5f","value":791656}},"dbfd8d5d630640ab871f3ab8303aba82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdf27c92b6c444ffb3632be55dba2403","placeholder":"​","style":"IPY_MODEL_4bcabc6d47104ea6833f6e647f3acb2a","value":" 773k/773k [00:00&lt;00:00, 1.12MB/s]"}},"9ae3a61864c949e499a6dda21e300f44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b65d674b138a4b5888bf78ef227c0253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"027c6a2518d14b99afeaf5de90ca7a05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c24a2e4e015141c89053074bd34f20af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81aa561f26c54861a78c1f0414a41e5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdf27c92b6c444ffb3632be55dba2403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bcabc6d47104ea6833f6e647f3acb2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4557bb1aae74e94907fbf79c9c6fa2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_adf934ecc676477e9982a4d6e9eee171","IPY_MODEL_d39e56cdd6d9432c90facb60ec8ddc7a","IPY_MODEL_ff571841dd45439b8dff4aac68dd2e7b"],"layout":"IPY_MODEL_d1cefef4da10418db54d2cb6e57a0121"}},"adf934ecc676477e9982a4d6e9eee171":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e84260fe28d40a591d68cac3e0cf984","placeholder":"​","style":"IPY_MODEL_04da800b0b754eaf8b19b782ff6145ac","value":"Downloading special_tokens_map.json: 100%"}},"d39e56cdd6d9432c90facb60ec8ddc7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0b281ce86c74f9a8249effa3d3bcd13","max":1786,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90a69f945c814233aa0b19b204dc2a22","value":1786}},"ff571841dd45439b8dff4aac68dd2e7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e501479807145788b74394c33667d47","placeholder":"​","style":"IPY_MODEL_23e870ba8c324d54a7b5066b62f33cda","value":" 1.74k/1.74k [00:00&lt;00:00, 43.1kB/s]"}},"d1cefef4da10418db54d2cb6e57a0121":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e84260fe28d40a591d68cac3e0cf984":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04da800b0b754eaf8b19b782ff6145ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0b281ce86c74f9a8249effa3d3bcd13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90a69f945c814233aa0b19b204dc2a22":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e501479807145788b74394c33667d47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23e870ba8c324d54a7b5066b62f33cda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b29c2d6d32c443193d6ca8563bd5a1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19632bc10ed649c7942f62c3f92cbc02","IPY_MODEL_814dae56d503400aad540dcc3526c054","IPY_MODEL_42a8be2e583846a68fd3ac2937eb9511"],"layout":"IPY_MODEL_87896d6c618e4dc590e20013cb0bc812"}},"19632bc10ed649c7942f62c3f92cbc02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fa395043b9343a882854722b63bced9","placeholder":"​","style":"IPY_MODEL_2e79d97a57774c8a8b5e17d2f07d999d","value":"Downloading pytorch_model.bin: 100%"}},"814dae56d503400aad540dcc3526c054":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eab285c52a494ba9b0dfb272c0f99575","max":1187795641,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d961652312584c739ccf316024e2e620","value":1187795641}},"42a8be2e583846a68fd3ac2937eb9511":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d38a960ee1647038a703eed7de54d92","placeholder":"​","style":"IPY_MODEL_78a02627b28641b18d048fbed75f15ed","value":" 1.11G/1.11G [00:43&lt;00:00, 24.8MB/s]"}},"87896d6c618e4dc590e20013cb0bc812":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa395043b9343a882854722b63bced9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e79d97a57774c8a8b5e17d2f07d999d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eab285c52a494ba9b0dfb272c0f99575":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d961652312584c739ccf316024e2e620":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d38a960ee1647038a703eed7de54d92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78a02627b28641b18d048fbed75f15ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}